<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: Using the Virtual Analysis Facility</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Using the Virtual Analysis Facility </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Introduction </h2>
<p>The Virtual Analysis Facility can be easily used by having installed on your client the following software:</p>
<ul>
<li><a href="http://root.cern.ch/">ROOT</a></li>
<li><a href="http://pod.gsi.de/">PROOF on Demand</a></li>
<li>The VAF client *(see below)*: a convenience tool that sets up the environment for your experiment's software both on your client and on the PROOF worker nodes</li>
</ul>
<blockquote class="doxtable">
<p>If you are the end user, you'll probably might skip the part that concerns how to configure the VAF client: your system administrator has probably and conveniently set it up for you. </p>
</blockquote>
<h2>The Virtual Analysis Facility client </h2>
<p>The Virtual Analysis Facility client takes care of setting the environment for the end user required by your software's experiment. The environment will both be set on the client and on each PROOF node.</p>
<p>Technically it is a Bash shell script which provides shortcuts for PROOF on Demand commands and ensures local and remote environment consistency: by executing it you enter a new clean environment where all your software dependencies have already been set up.</p>
<p>Local and remote environment configuration is split into a series of files, which give the possibility to:</p>
<ul>
<li>have a system-wide, sysadmin-provided experiment configuration</li>
<li>execute user actions either <em>before</em> or <em>after</em> the execution of the system-wide script (for instance, choosing the preferred version of the experiment's software)</li>
<li>transfer a custom user <b>payload</b> on each PROOF worker (for instance, user's client-generated Grid credentials to make PROOF workers capable of accessing a remote authenticated storage)</li>
</ul>
<p>Configuration files are searched for in two different locations:</p>
<ul>
<li>a system-wide directory: <code>&lt;client_install_dir&gt;/etc</code></li>
<li>user's home directory: <code>~/.vaf</code></li>
</ul>
<blockquote class="doxtable">
<p>A system-wide configuration file always has precedence over user's configuration. It is thus possible for the sysadmin to enforce a policy where some scripts cannot ever be overridden. </p>
</blockquote>
<p>Thanks to this separation, users can maintain an uncluttered directory with very simple configuration files that contain only what really needs or is allowed to be customized: for instance, user might specify a single line containing the needed <a class="el" href="namespaceROOT.html" title="Namespace for new ROOT classes and functions. ">ROOT</a> version, while all the technicalities to set up the environment are taken care of inside system-installed scripts, leaving the user's configuration directory clean and uncluttered.</p>
<h3>Local environment configuration</h3>
<p>All the local environment files are loaded at the time of the client's startup following a certain order</p>
<ul>
<li><code>common.before</code></li>
<li><code>local.before</code></li>
<li><code>local.conf</code></li>
<li><code>$VafConf_LocalPodLocation/PoD_env.sh</code></li>
<li><code>common.after</code></li>
<li><code>local.after</code></li>
</ul>
<p>The <code>common.*</code> files are sourced both for the local and the remote environment. This might be convenient to avoid repeating the same configuration in different places.</p>
<p>Each file is looked for first in the system-wide directory and then in the user's directory. If a configuration file does not exist, it is silently skipped.</p>
<p>The <code>$VafConf_LocalPodLocation/PoD_env.sh</code> environment script, provided with each PROOF on Demand installation, <em>must exist</em>: without this file, the VAF client won't start.</p>
<h3>List of VAF-specific variables</h3>
<p>There are some special variables that need to be set in one of the above configuration files.</p>
<p><code>$VafConf_LocalPodLocation</code> : Full path to the PoD installation on the client. </p><pre class="fragment">&gt; The `$VafConf_LocalPodLocation` variable must be set before the
&gt; `PoD_env.sh` script gets sourced, so set it either in
&gt; `common.before`, `local.before` or `local.conf`. Since PoD is
&gt; usually system-wide installed, its location is normally
&gt; system-wide set in either the `local.conf` file by the system
&gt; administrator.
</pre><p><code>$VafConf_RemotePodLocation</code> : Full path to the PoD installation on the VAF master node. </p><pre class="fragment">*Note: this variable should be set in the configuration files for
the local environment despite it refers to a software present on the
remote nodes.*
</pre><p><code>$VafConf_PodRms</code> *(optional)* : Name of the Resource Management System used for submitting PoD jobs. Run <code>pod-submit -l</code> to see the possible values.</p>
<p>If not set, defaults to <code>condor</code>.</p>
<p><code>$VafConf_PodQueue</code> *(optional)* : Queue name where to submit PoD jobs. </p><pre class="fragment">If no queue has been given, the default one configured on your RMS
will be used.
</pre><h3>Remote environment configuration</h3>
<p>All the PoD commands sent to the VAF master will live in the environment loaded via using the following scripts.</p>
<p>Similarly to the local environment, configuration is split in different files to allow for a system-wide configuration, which has precedence over user's configuration in the home directory. If a script cannot be found, it will be silently skipped.</p>
<ul>
<li><code>&lt;output_of_payload&gt;</code></li>
<li><code>common.before</code></li>
<li><code>remote.before</code></li>
<li><code>remote.conf</code></li>
<li><code>common.after</code></li>
<li><code>remote.after</code></li>
</ul>
<p>For an explanation on how to pass extra data to the workers safely through the payload, see below.</p>
<h3>Payload: sending local files to the remote nodes</h3>
<p>In many cases it is necessary to send some local data to the remote workers: it is very common, for instance, to distribute a local Grid authentication proxy on the remote workers to let them authenticate to access a data storage.</p>
<p>The <code>payload</code> file must be an executable generating some output that will be prepended to the remote environment preparation. Differently than the other environment scripts, it is not executed: instead, it is first run, then <em>the output it produces will be executed</em>.</p>
<p>Let's see a practical example to better understand how it works. We need to send our Grid proxy to the master node.</p>
<p>This is our <code>payload</code> executable script:</p>
<div class="fragment"><div class="line">#!/bin/bash</div><div class="line">echo &quot;echo &#39;`cat /tmp/x509up_u$UID | base64 | tr -d &#39;\r\n&#39;`&#39;&quot; \</div><div class="line">  &quot;| base64 -d &gt; /tmp/x509up_u\$UID&quot;</div></div><!-- fragment --><p>This script will be executed locally, providing another "script line" as output:</p>
<div class="fragment"><div class="line">echo &#39;VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==&#39; | base64 -d &gt; /tmp/x509up_u$UID</div></div><!-- fragment --><p>This line will be prepended to the remote environment script and will be executed before anything else on the remote node: it will effectively decode the Base64 string back to the proxy file and write it into the <code>/tmp</code> directory. Note also that the first <code>$UID</code> is not escaped and will be substituted <em>locally</em> with your user ID <em>on your client machine</em>, while the second one has the dollar escaped (<code>\$UID</code>) and will be substituted <em>remotely</em> with your user ID <em>on the remote node</em>.</p>
<blockquote class="doxtable">
<p>It is worth noting that the remote environment scripts will be sent to the remote node using a secure connection (SSH), thus there is no concern in placing sensitive user data there. </p>
</blockquote>
<h2>Installing the Virtual Analysis Facility client </h2>
<h3>Download the client from Git</h3>
<p>The Virtual Analysis Facility client is available on <a href="https://github.com/dberzano/virtual-analysis-facility">GitHub</a>:</p>
<div class="fragment"><div class="line">git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir</div></div><!-- fragment --><p>The client will be found in <code>/dest/dir/client/bin/vaf-enter</code>: it is convenient to add it to the <code>$PATH</code> so that the users might simply start it by typing <code>vaf-enter</code>.</p>
<h3>Install the experiment's configuration files system-wide</h3>
<p>A system administrator might find convenient to install the experiment environment scripts system-wide.</p>
<p>Configuration scripts for LHC experiments are shipped with the VAF client and can be found in <code>/dest/dir/client/config-samples/&lt;experiment_name&gt;</code>. To make them used by default by the VAF client, place them in the <code>/dest/dir/etc</code> directory like this:</p>
<div class="fragment"><div class="line">rsync -a /dest/dir/client/config-samples/&lt;experiment_name&gt;/ /dest/dir/etc/</div></div><!-- fragment --><p>Remember that the trailing slash in the source directory name has a meaning in <code>rsync</code> and must not be omitted.</p>
<blockquote class="doxtable">
<p>Remember that system-wide configuration files will always have precedence over user's configuration files, so <em>don't place there files that are supposed to be provided by the user!</em> </p>
</blockquote>
<h2>Entering the Virtual Analysis Facility environment </h2>
<p>The Virtual Analysis Facility client is a wrapper around commands sent to the remote host by means of PROOF on Demand's <code>pod-remote</code>. The VAF client takes care of setting up passwordless SSH from your client node to the VAF master.</p>
<h3>Getting the credentials</h3>
<blockquote class="doxtable">
<p>You can skip this paragraph if the remote server wasn't configured for HTTPS+SSH authentication. </p>
</blockquote>
<p>In our example we will assume that the remote server's name is <code>cloud-gw-213.to.infn.it</code>: substitute it with your remote endpoint.</p>
<p>First, check that you have your Grid certificate and private key installed both in your browser and in the home directory of your client.</p>
<p>Point your browser to <code><a href="https://cloud-gw-213.to.infn.it/auth/">https://cloud-gw-213.to.infn.it/auth/</a></code>: you'll probably be asked for a certificate to choose for authentication. Pick one and you'll be presented with the following web page:</p>
<div class="image">
<img src="img/sshcertauth-web.png" alt="Web authentication with sshcertauth"/>
</div>
<p>The webpage clearly explains you what to do next.</p>
<h3>Customizing user's configuration</h3>
<p>Before entering the VAF environment, you should customize the user's configuration. How to do so depends on your experiment, but usually you should essentially specify the version of the experiment's software you need.</p>
<p>For instance, in the CMS use case, only one file is needed: <code>~/.vaf/common.before</code>, which contains something like:</p>
<div class="fragment"><div class="line"># Version of CMSSW (as reported by &quot;scram list&quot;)</div><div class="line">export VafCmsswVersion=&#39;CMSSW_5_3_9_sherpa2beta2&#39;</div></div><!-- fragment --><h3>Entering the VAF environment</h3>
<p>Open a terminal on your client machine (can be either your local computer or a remote user interface) and type: </p><pre class="fragment">vaf-enter &lt;username&gt;@cloud-gw-213.to.infn.it
</pre><p>You'll substitute <code>&lt;username&gt;</code> with the username that either your system administrator or the web authentication (if you used it) provided you.</p>
<p>You'll be presented with a neat shell which looks like the following: </p><pre class="fragment">Entering VAF environment: dberzano@cloud-gw-213.to.infn.it
Remember: you are still in a shell on your local computer!
pod://dberzano@cloud-gw-213.to.infn.it [~] &gt;
</pre><p>This shell runs on your local computer and it has the environment properly set up.</p>
<h2>PoD and PROOF workflow </h2>
<blockquote class="doxtable">
<p>The following operations are valid inside the <code>vaf-enter</code> environment. </p>
</blockquote>
<h3>Start your PoD server</h3>
<p>With PROOF on Demand, each user has the control of its own personal PROOF cluster. The first thing to do is to start the PoD server and the PROOF master like this: </p><pre class="fragment">vafctl --start
</pre><p>A successful output will be similar to: </p><pre class="fragment">**    Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53
**  Server is started. Use "pod-info -sd" to check the status of the server.
</pre><h3>Request and wait for workers</h3>
<p>Now the server is started but you don't have any worker available. To request for <code>&lt;n&gt;</code> workers, do: </p><pre class="fragment">vafreq &lt;n&gt;
</pre><p>To check how many workers became available for use: </p><pre class="fragment">pod-info -n
</pre><p>To continuously update the check (<code>Ctrl-C</code> to terminate): </p><pre class="fragment">vafcount
</pre><p>Example of output: </p><pre class="fragment">Updating every 5 seconds. Press Ctrl-C to stop monitoring...
[20130411-172235] 0
[20130411-172240] 0
[20130411-172245] 12
[20130411-172250] 12
...
</pre><p>To execute a command after a certain number of workers is available (in the example we wait for 5 workers then start <a class="el" href="namespaceROOT.html" title="Namespace for new ROOT classes and functions. ">ROOT</a>): </p><pre class="fragment">vafwait 5 &amp;&amp; root -l
</pre><blockquote class="doxtable">
<p>Workers take some time before becoming available. Also, it is possible that not all the requested workers will be satisfied. </p>
</blockquote>
<h3>Start <a class="el" href="namespaceROOT.html" title="Namespace for new ROOT classes and functions. ">ROOT</a> and use PROOF</h3>
<p>When you are satisfied with the available number of active workers, you may start your PROOF analysis. Start <a class="el" href="namespaceROOT.html" title="Namespace for new ROOT classes and functions. ">ROOT</a>, and from its prompt connect to PROOF like this: </p><pre class="fragment">root [0] TProof::Open("pod://");
</pre><p>Example of output: </p><pre class="fragment">Starting master: opening connection ...
Starting master: OK
Opening connections to workers: OK (12 workers)
Setting up worker servers: OK (12 workers)
PROOF set to parallel mode (12 workers)
</pre><h3>Stop or restart your PoD cluster</h3>
<p>At the end of your session, remember to free the workers by stopping your PoD server: </p><pre class="fragment">vafctl --stop
</pre><blockquote class="doxtable">
<p>PoD will stop the PROOF master and the workers after detecting they've been idle for a certain amount of time anyway, but it is a good habit to stop it for yourself when you're finished using it, so that you are immediately freeing resources and let them be available for other users. </p>
</blockquote>
<p>In case of a major PROOF failure (i.e., crash), you can simply restart your personal PROOF cluster by running: </p><pre class="fragment">vafctl --start
</pre><p>PoD will stop and restart the PROOF master. You'll need to request the workers again at this point. </p>
</div></div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:10:40 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
