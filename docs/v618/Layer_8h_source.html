<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: tmva/tmva/inc/TMVA/DNN/Layer.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a647c3f16b21786eaaa28427c9c80e3e.html">tmva</a></li><li class="navelem"><a class="el" href="dir_ed3dab6383bd5f321850908cd5a1281f.html">tmva</a></li><li class="navelem"><a class="el" href="dir_e5f324a990c4e53e87e3a4847f1d2164.html">inc</a></li><li class="navelem"><a class="el" href="dir_b2d93ebd3f51b5d9cf703b0851621985.html">TMVA</a></li><li class="navelem"><a class="el" href="dir_d9e07824f297128826b01e2ad3fd4d49.html">DNN</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Layer.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="Layer_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// @(#)root/tmva/tmva/dnn:$Id$</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Author: Simon Pfreundschuh 20/06/16</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">/*************************************************************************</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * Copyright (C) 2016, Simon Pfreundschuh                                *</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * All rights reserved.                                                  *</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> *                                                                       *</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * For the licensing terms see $ROOTSYS/LICENSE.                         *</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> * For the list of contributors see $ROOTSYS/README/CREDITS.             *</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *************************************************************************/</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">//////////////////////////////////////////////////////////////////////</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"></span><span class="comment">// Contains Layer and SharedLayer classes, that represent layers in //</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// neural networks.                                                 //</span><span class="comment"></span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">//////////////////////////////////////////////////////////////////////</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#ifndef TMVA_DNN_LAYER</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#define TMVA_DNN_LAYER</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="TMatrix_8h.html">TMatrix.h</a>&quot;</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h.html">Functions.h</a>&quot;</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceTMVA.html">TMVA</a></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;{</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="keyword">namespace </span>DNN</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;{</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">//  The Layer Class</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">/** \class TLayer</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment">    Generic layer class.</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment">    This generic layer class represents a layer of a neural network with</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment">    a given width n and activation function f. The activation</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment">    function of each layer is given by \f$\mathbf{u} =</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment">    \mathbf{W}\mathbf{x} + \boldsymbol{\theta}\f$.</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="comment">    In addition to the weight and bias matrices, each layer allocates memory</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="comment">    for its activations and the corresponding first partial fDerivatives of</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="comment">    the activation function as well as the gradients of the fWeights and fBiases.</span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="comment">    The layer provides member functions for the forward propagation of</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="comment">    activations through the given layer.</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="comment">*/</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00052"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html">   52</a></span>&#160;   <span class="keyword">class </span><a class="code" href="classTMVA_1_1DNN_1_1TLayer.html">TLayer</a></div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;{</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00056"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">   56</a></span>&#160;   <span class="keyword">using</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a> = <span class="keyword">typename</span> Architecture_t::Scalar_t;</div><div class="line"><a name="l00057"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">   57</a></span>&#160;   <span class="keyword">using</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> = <span class="keyword">typename</span> Architecture_t::Matrix_t;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#aacfd9cebe978f116dddf9327af9aada1">   61</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#aacfd9cebe978f116dddf9327af9aada1">fBatchSize</a>;  <span class="comment">///&lt; Batch size used for training and evaluation.</span></div><div class="line"><a name="l00062"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a32f461095918e579682aa0e30aee12b3">   62</a></span>&#160;<span class="comment"></span>   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a32f461095918e579682aa0e30aee12b3">fInputWidth</a>; <span class="comment">///&lt; Number of neurons of the previous layer.</span></div><div class="line"><a name="l00063"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a751dd3852367b7fc3fe41d4db8ac610d">   63</a></span>&#160;<span class="comment"></span>   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a751dd3852367b7fc3fe41d4db8ac610d">fWidth</a>;      <span class="comment">///&lt; Number of neurons of this layer.</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00065"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a71ae97293c4019b17186d6ee0691ee20">   65</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a71ae97293c4019b17186d6ee0691ee20">fDropoutProbability</a>;  <span class="comment">///&lt; Probability that an input is active.</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00067"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#ab8de2ae6fffcf431a10cad1cefc7bec3">   67</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab8de2ae6fffcf431a10cad1cefc7bec3">fWeights</a>;             <span class="comment">///&lt; The fWeights of this layer.</span></div><div class="line"><a name="l00068"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a72fe1a8cd0e407aece41e6448e5d183e">   68</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a72fe1a8cd0e407aece41e6448e5d183e">fBiases</a>;              <span class="comment">///&lt; The bias values of this layer.</span></div><div class="line"><a name="l00069"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a53f3cfb336eb13a5299978c307e0b7b2">   69</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a53f3cfb336eb13a5299978c307e0b7b2">fOutput</a>;              <span class="comment">///&lt; Activations of this layer.</span></div><div class="line"><a name="l00070"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#ad4ccd32bf8a939245c9fb89009402bc4">   70</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ad4ccd32bf8a939245c9fb89009402bc4">fDerivatives</a>;         <span class="comment">///&lt; First fDerivatives of the activations of this layer.</span></div><div class="line"><a name="l00071"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#aa9a44e9a8e0fe42aa937cc67adb26c4b">   71</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#aa9a44e9a8e0fe42aa937cc67adb26c4b">fWeightGradients</a>;     <span class="comment">///&lt; Gradients w.r.t. the weigths of this layer.</span></div><div class="line"><a name="l00072"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a32f72b841008c65ec3dc7bc012e34a8a">   72</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a32f72b841008c65ec3dc7bc012e34a8a">fBiasGradients</a>;       <span class="comment">///&lt; Gradients w.r.t. the bias values of this layer.</span></div><div class="line"><a name="l00073"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a2d8006fbc5ab4dfcf7184647933fbfe9">   73</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a2d8006fbc5ab4dfcf7184647933fbfe9">fActivationGradients</a>; <span class="comment">///&lt; Gradients w.r.t. the activations of this layer.</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a1da3619b1b593fdab4c6a653a0487c94">   75</a></span>&#160;   <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a1da3619b1b593fdab4c6a653a0487c94">fF</a>; <span class="comment">///&lt; Activation function of the layer.</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a31a7461dc950992a2326b5bbf53715d4">TLayer</a>(<span class="keywordtype">size_t</span>             BatchSize,</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;          <span class="keywordtype">size_t</span>             InputWidth,</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;          <span class="keywordtype">size_t</span>             Width,</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;          <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>,</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;          <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a>           dropoutProbability);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a31a7461dc950992a2326b5bbf53715d4">TLayer</a>(<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html">TLayer</a> &amp;);</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">   /*! Initialize fWeights according to the given initialization</span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">    *  method. */</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;   <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab37018cf9def8849754b243caa60aeca">Initialize</a>(<a class="code" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a> <a class="code" href="textangle_8C.html#a15eed939eb6efebfc935e895368c847a">m</a>);<span class="comment"></span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="comment">   /*! Compute activation of the layer for the given input. The input</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="comment">    * must be in matrix form with the different rows corresponding to</span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="comment">    * different events in the batch. Computes activations as well as</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="comment">    * the first partial derivative of the activation function at those</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment">    * activations. */</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;   <span class="keywordtype">void</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#af75bcc21a942d3a36b771f82b82eca13">Forward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; input, <span class="keywordtype">bool</span> applyDropout = <span class="keyword">false</span>);<span class="comment"></span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="comment">   /*! Compute weight, bias and activation gradients. Uses the precomputed</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="comment">    *  first partial derviatives of the activation function computed during</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;<span class="comment">    *  forward propagation and modifies them. Must only be called directly</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="comment">    *  a the corresponding call to Forward(...). */</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;   <span class="keywordtype">void</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a00dc5fb3b86711cc1c1fcfe1543fbe7c">Backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; gradients_backward,</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; activations_backward,</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;                        <a class="code" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="code" href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a>,</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a> <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>);</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;   <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a9b374e979211a9607f852833a09ab5ea">Print</a>() <span class="keyword">const</span>;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a5e8dad0a0c4b0ffd00a737f4c6636a72">  106</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a5e8dad0a0c4b0ffd00a737f4c6636a72">GetBatchSize</a>()<span class="keyword">          const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#aacfd9cebe978f116dddf9327af9aada1">fBatchSize</a>;}</div><div class="line"><a name="l00107"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a698e714a2bd93638d8b73bee9733c7fc">  107</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a698e714a2bd93638d8b73bee9733c7fc">GetInputWidth</a>()<span class="keyword">         const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a32f461095918e579682aa0e30aee12b3">fInputWidth</a>;}</div><div class="line"><a name="l00108"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#ada893a8d8a8986e913dae28d2c21eff5">  108</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ada893a8d8a8986e913dae28d2c21eff5">GetWidth</a>()<span class="keyword">              const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a751dd3852367b7fc3fe41d4db8ac610d">fWidth</a>;}</div><div class="line"><a name="l00109"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a91327b7db79179cfb43c449778be8605">  109</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a91327b7db79179cfb43c449778be8605">GetDropoutProbability</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a71ae97293c4019b17186d6ee0691ee20">fDropoutProbability</a>;}</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div><div class="line"><a name="l00111"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a06c3a194a43fca8ca555c0b1c9795ef8">  111</a></span>&#160;   <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a06c3a194a43fca8ca555c0b1c9795ef8">SetDropoutProbability</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a> p) {<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a71ae97293c4019b17186d6ee0691ee20">fDropoutProbability</a> = p;}</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a59570627e8f146205c7181079fa074dd">  113</a></span>&#160;   <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a59570627e8f146205c7181079fa074dd">GetActivationFunction</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a1da3619b1b593fdab4c6a653a0487c94">fF</a>;}</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;</div><div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a7ab0f9ac32cebd85886ad0ad3797affe">  115</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a7ab0f9ac32cebd85886ad0ad3797affe">GetOutput</a>()        {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a53f3cfb336eb13a5299978c307e0b7b2">fOutput</a>;}</div><div class="line"><a name="l00116"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a6991ec6151aa9e1ee90d10f71da48728">  116</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a6991ec6151aa9e1ee90d10f71da48728">GetOutput</a>()<span class="keyword"> const  </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a53f3cfb336eb13a5299978c307e0b7b2">fOutput</a>;}</div><div class="line"><a name="l00117"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a702cf8e17de767b17eaa21e23b1ee6b8">  117</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a702cf8e17de767b17eaa21e23b1ee6b8">GetWeights</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab8de2ae6fffcf431a10cad1cefc7bec3">fWeights</a>;}</div><div class="line"><a name="l00118"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#aeb7cc8d813ab530109dd3974fc158238">  118</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#aeb7cc8d813ab530109dd3974fc158238">GetWeights</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab8de2ae6fffcf431a10cad1cefc7bec3">fWeights</a>;}</div><div class="line"><a name="l00119"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#abe7e237d899352e1ef4462068516455f">  119</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#abe7e237d899352e1ef4462068516455f">GetBiases</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a72fe1a8cd0e407aece41e6448e5d183e">fBiases</a>;}</div><div class="line"><a name="l00120"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#acf4f0b067f35fa806fd8d46472bfac2b">  120</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#acf4f0b067f35fa806fd8d46472bfac2b">GetBiases</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a72fe1a8cd0e407aece41e6448e5d183e">fBiases</a>;}</div><div class="line"><a name="l00121"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a097852476c78d1faff69bbc62be40a89">  121</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a097852476c78d1faff69bbc62be40a89">GetActivationGradients</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a2d8006fbc5ab4dfcf7184647933fbfe9">fActivationGradients</a>;}</div><div class="line"><a name="l00122"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a46c61123424cda62c91170391649ca67">  122</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a46c61123424cda62c91170391649ca67">GetActivationGradients</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a2d8006fbc5ab4dfcf7184647933fbfe9">fActivationGradients</a>;}</div><div class="line"><a name="l00123"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a8cd8e44cf6074f5f08ddc07335e83cd3">  123</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cd8e44cf6074f5f08ddc07335e83cd3">GetBiasGradients</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a32f72b841008c65ec3dc7bc012e34a8a">fBiasGradients</a>;}</div><div class="line"><a name="l00124"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#ab396f0c39ec3e5e0e4ecc50c5231757c">  124</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab396f0c39ec3e5e0e4ecc50c5231757c">GetBiasGradients</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a32f72b841008c65ec3dc7bc012e34a8a">fBiasGradients</a>;}</div><div class="line"><a name="l00125"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#ac9526af256b9f8f76a2a37714c13d2fd">  125</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ac9526af256b9f8f76a2a37714c13d2fd">GetWeightGradients</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#aa9a44e9a8e0fe42aa937cc67adb26c4b">fWeightGradients</a>;}</div><div class="line"><a name="l00126"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a3268338c605b79859fa1913b25c4553f">  126</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a3268338c605b79859fa1913b25c4553f">GetWeightGradients</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#aa9a44e9a8e0fe42aa937cc67adb26c4b">fWeightGradients</a>;}</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;};</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="comment">//  The Shared Layer Class</span></div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;<span class="comment">/** \class TSharedLayer</span></div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment">    Layer class width shared weight and bias layers.</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment">    Like the Layer class only that weight matrices are shared between</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment">    different instances of the net, which can be used to implement</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment">    multithreading &#39;Hogwild&#39; style.</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment">*/</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00145"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html">  145</a></span>&#160;<span class="keyword">class </span><a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html">TSharedLayer</a></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;{</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;</div><div class="line"><a name="l00150"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">  150</a></span>&#160;   <span class="keyword">using</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">Scalar_t</a> = <span class="keyword">typename</span> Architecture_t::Scalar_t;</div><div class="line"><a name="l00151"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">  151</a></span>&#160;   <span class="keyword">using</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> = <span class="keyword">typename</span> Architecture_t::Matrix_t;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;</div><div class="line"><a name="l00155"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a85660231b8a713438aa1d39e43265f98">  155</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a85660231b8a713438aa1d39e43265f98">fBatchSize</a>;  <span class="comment">///&lt; Batch size used for training and evaluation.</span></div><div class="line"><a name="l00156"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4c712d1e8db7733c2932e084bff0b7fa">  156</a></span>&#160;<span class="comment"></span>   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4c712d1e8db7733c2932e084bff0b7fa">fInputWidth</a>; <span class="comment">///&lt; Number of neurons of the previous layer.</span></div><div class="line"><a name="l00157"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a6b36998f85371f600b3d99739c4b2a94">  157</a></span>&#160;<span class="comment"></span>   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a6b36998f85371f600b3d99739c4b2a94">fWidth</a>;      <span class="comment">///&lt; Number of neurons of this layer.</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00159"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abf47e1e5b76c47a303a1600b014c5ada">  159</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">Scalar_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abf47e1e5b76c47a303a1600b014c5ada">fDropoutProbability</a>;  <span class="comment">///&lt; Probability that an input is active.</span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1d3c6ba16efaf7b0fa66abd74b71e489">  161</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1d3c6ba16efaf7b0fa66abd74b71e489">fWeights</a>;           <span class="comment">///&lt; Reference to the weight matrix of this layer.</span></div><div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a058d57c13d9b4a3fbba00d063e58ae4e">  162</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a058d57c13d9b4a3fbba00d063e58ae4e">fBiases</a>;            <span class="comment">///&lt; Reference to the bias vectors of this layer.</span></div><div class="line"><a name="l00163"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a069c290fd61150c22da4bb3e9f7f2eb3">  163</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a069c290fd61150c22da4bb3e9f7f2eb3">fOutput</a>;              <span class="comment">///&lt; Activations of this layer.</span></div><div class="line"><a name="l00164"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a3f23cdc3a2ad5baaaa179773d88655e5">  164</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a3f23cdc3a2ad5baaaa179773d88655e5">fDerivatives</a>;         <span class="comment">///&lt; First fDerivatives of the activations of this layer.</span></div><div class="line"><a name="l00165"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a87e433880b8429b73362b580db5421b7">  165</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a87e433880b8429b73362b580db5421b7">fWeightGradients</a>;     <span class="comment">///&lt; Gradients w.r.t. the weigths of this layer.</span></div><div class="line"><a name="l00166"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d4567cb440d261980ecc55e9cc15ae5">  166</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d4567cb440d261980ecc55e9cc15ae5">fBiasGradients</a>;       <span class="comment">///&lt; Gradients w.r.t. the bias values of this layer.</span></div><div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8f8e00699e099480bab81109604cc21a">  167</a></span>&#160;<span class="comment"></span>   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8f8e00699e099480bab81109604cc21a">fActivationGradients</a>; <span class="comment">///&lt; Gradients w.r.t. the activations of this layer.</span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abb1aef0108ef8f0f9baead77715429a5">  169</a></span>&#160;   <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abb1aef0108ef8f0f9baead77715429a5">fF</a>; <span class="comment">///&lt; Activation function of the layer.</span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1a4489e3fe800f78ebbbfc84c6d24d16">TSharedLayer</a>(<span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a85660231b8a713438aa1d39e43265f98">fBatchSize</a>,</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;                <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html">TLayer&lt;Architecture_t&gt;</a> &amp; layer);</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1a4489e3fe800f78ebbbfc84c6d24d16">TSharedLayer</a>(<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html">TSharedLayer</a> &amp; layer);</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment">   /*! Compute activation of the layer for the given input. The input</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment">    * must be in matrix form with the different rows corresponding to</span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment">    * different events in the batch. Computes activations as well as</span></div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment">    * the first partial derivative of the activation function at those</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">    * activations. */</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;   <span class="keywordtype">void</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#aabdc28c54158720cb14c7f59ed53f7ed">Forward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; input, <span class="keywordtype">bool</span> applyDropout = <span class="keyword">false</span>);<span class="comment"></span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment">   /*! Compute weight, bias and activation gradients. Uses the precomputed</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">    *  first partial derviatives of the activation function computed during</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">    *  forward propagation and modifies them. Must only be called directly</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment">    *  a the corresponding call to Forward(...). */</span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;   <span class="keywordtype">void</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af7109dc83f9f7aeb17cd87d1d72aea9a">Backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; gradients_backward,</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; activations_backward,</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;                        <a class="code" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="code" href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a>,</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">Scalar_t</a> <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>);</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;   <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9c3add0dce60ec8111f09f90d7b12904">Print</a>() <span class="keyword">const</span>;</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;</div><div class="line"><a name="l00194"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9d2e92b1852127300f0bf360e8160c1c">  194</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9d2e92b1852127300f0bf360e8160c1c">GetBatchSize</a>()<span class="keyword">          const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a85660231b8a713438aa1d39e43265f98">fBatchSize</a>;}</div><div class="line"><a name="l00195"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a97f3796826b70587c98743c5fe785481">  195</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a97f3796826b70587c98743c5fe785481">GetInputWidth</a>()<span class="keyword">         const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4c712d1e8db7733c2932e084bff0b7fa">fInputWidth</a>;}</div><div class="line"><a name="l00196"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d27f641f5229f579719b52ebb7dc14c">  196</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d27f641f5229f579719b52ebb7dc14c">GetWidth</a>()<span class="keyword">              const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a6b36998f85371f600b3d99739c4b2a94">fWidth</a>;}</div><div class="line"><a name="l00197"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9562b8696f8b758bdae24b281ac45bd2">  197</a></span>&#160;   <span class="keywordtype">size_t</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9562b8696f8b758bdae24b281ac45bd2">GetDropoutProbability</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abf47e1e5b76c47a303a1600b014c5ada">fDropoutProbability</a>;}</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;</div><div class="line"><a name="l00199"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af0acca3b810af5e6bcc7d19823c621f5">  199</a></span>&#160;   <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af0acca3b810af5e6bcc7d19823c621f5">SetDropoutProbability</a>(<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">Scalar_t</a> p) {<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abf47e1e5b76c47a303a1600b014c5ada">fDropoutProbability</a> = p;}</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;</div><div class="line"><a name="l00201"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8a5900b3121ee0f1c529afe5e2dd2ccb">  201</a></span>&#160;   <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8a5900b3121ee0f1c529afe5e2dd2ccb">GetActivationFunction</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#abb1aef0108ef8f0f9baead77715429a5">fF</a>;}</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;</div><div class="line"><a name="l00203"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a78e8398e49b7a51b38d9e76f7740ff41">  203</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a78e8398e49b7a51b38d9e76f7740ff41">GetOutput</a>()        {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a069c290fd61150c22da4bb3e9f7f2eb3">fOutput</a>;}</div><div class="line"><a name="l00204"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af95f65da6b3e662089bb89b552f7af07">  204</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af95f65da6b3e662089bb89b552f7af07">GetOutput</a>()<span class="keyword"> const  </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a069c290fd61150c22da4bb3e9f7f2eb3">fOutput</a>;}</div><div class="line"><a name="l00205"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a28adac9fe38a1404c2c86880f9cd72c9">  205</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a28adac9fe38a1404c2c86880f9cd72c9">GetWeights</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1d3c6ba16efaf7b0fa66abd74b71e489">fWeights</a>;}</div><div class="line"><a name="l00206"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a65d7c9c974a35da4cb27eb59b67226b2">  206</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a65d7c9c974a35da4cb27eb59b67226b2">GetBiases</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a058d57c13d9b4a3fbba00d063e58ae4e">fBiases</a>;}</div><div class="line"><a name="l00207"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af596566350f379903a1d00e66ec551c7">  207</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af596566350f379903a1d00e66ec551c7">GetBiases</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a058d57c13d9b4a3fbba00d063e58ae4e">fBiases</a>;}</div><div class="line"><a name="l00208"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a753949b54402ed2bea4d08b464632a3a">  208</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a753949b54402ed2bea4d08b464632a3a">GetActivationGradients</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8f8e00699e099480bab81109604cc21a">fActivationGradients</a>;}</div><div class="line"><a name="l00209"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4e3891e18fd770c4fb4e58fbb9a866e1">  209</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4e3891e18fd770c4fb4e58fbb9a866e1">GetActivationGradients</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8f8e00699e099480bab81109604cc21a">fActivationGradients</a>;}</div><div class="line"><a name="l00210"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#aee1936c277f5ff9d0ceec86015d1b35b">  210</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#aee1936c277f5ff9d0ceec86015d1b35b">GetBiasGradients</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d4567cb440d261980ecc55e9cc15ae5">fBiasGradients</a>;}</div><div class="line"><a name="l00211"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2e89808fb4c206730394717c37c7182a">  211</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2e89808fb4c206730394717c37c7182a">GetBiasGradients</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d4567cb440d261980ecc55e9cc15ae5">fBiasGradients</a>;}</div><div class="line"><a name="l00212"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9f1fdc2371e65ed0f61f0ee93d59a4e3">  212</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a>       &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9f1fdc2371e65ed0f61f0ee93d59a4e3">GetWeightGradients</a>()       {<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a87e433880b8429b73362b580db5421b7">fWeightGradients</a>;}</div><div class="line"><a name="l00213"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a00f26f6066332d4aece5260e91607aea">  213</a></span>&#160;   <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a00f26f6066332d4aece5260e91607aea">GetWeightGradients</a>()<span class="keyword"> const </span>{<span class="keywordflow">return</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a87e433880b8429b73362b580db5421b7">fWeightGradients</a>;}</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;};</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="comment">//  The Layer Class - Implementation</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00223"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a31a7461dc950992a2326b5bbf53715d4">  223</a></span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a31a7461dc950992a2326b5bbf53715d4">TLayer&lt;Architecture_t&gt;::TLayer</a>(<span class="keywordtype">size_t</span> batchSize,</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                                  <span class="keywordtype">size_t</span> inputWidth,</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                                  <span class="keywordtype">size_t</span> <a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>,</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                                  <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>,</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;                                  <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a> dropoutProbability)</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;   : fBatchSize(batchSize), fInputWidth(inputWidth), fWidth(<a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>),</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;     fDropoutProbability(dropoutProbability), fWeights(<a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, fInputWidth),</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;     fBiases(<a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, 1), fOutput(fBatchSize, <a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>), fDerivatives(fBatchSize, <a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>),</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;     fWeightGradients(<a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, fInputWidth), fBiasGradients(<a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, 1),</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;     fActivationGradients(fBatchSize, <a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>), fF(<a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>)</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;{</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;   <span class="comment">// Nothing to do here.</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;}</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00239"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a2605b0c731ba9459e815bd48c67e1e63">  239</a></span>&#160;<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a31a7461dc950992a2326b5bbf53715d4">TLayer&lt;Architecture_t&gt;::TLayer</a>(<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html">TLayer</a> &amp;layer)</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;    : fBatchSize(layer.fBatchSize), fInputWidth(layer.fInputWidth),</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;    fWidth(layer.fWidth), fDropoutProbability(layer.fDropoutProbability),</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;    fWeights(layer.fWidth, layer.fInputWidth), fBiases(layer.fWidth, 1),</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;    fOutput(layer.fBatchSize, layer.fWidth),</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;    fDerivatives(layer.fBatchSize, layer.fWidth),</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;    fWeightGradients(layer.fWidth, layer.fInputWidth),</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    fBiasGradients(layer.fWidth, 1),</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;    fActivationGradients(layer.fBatchSize, layer.fWidth),</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;    fF(layer.fF)</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;{</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;   <a class="code" href="namespaceROOT_1_1Math_1_1GSLSimAn.html#a4f40b1163d80135a8fa14dd77e2c8f09">Architecture_t::Copy</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab8de2ae6fffcf431a10cad1cefc7bec3">fWeights</a>, layer.<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a702cf8e17de767b17eaa21e23b1ee6b8">GetWeights</a>());</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;   <a class="code" href="namespaceROOT_1_1Math_1_1GSLSimAn.html#a4f40b1163d80135a8fa14dd77e2c8f09">Architecture_t::Copy</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a72fe1a8cd0e407aece41e6448e5d183e">fBiases</a>,  layer.<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#abe7e237d899352e1ef4462068516455f">GetBiases</a>());</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;}</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00256"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#ab37018cf9def8849754b243caa60aeca">  256</a></span>&#160;<span class="keyword">auto</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#ab37018cf9def8849754b243caa60aeca">TLayer&lt;Architecture_t&gt;::Initialize</a>(<a class="code" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a> <a class="code" href="textangle_8C.html#a15eed939eb6efebfc935e895368c847a">m</a>)</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;-&gt; <span class="keywordtype">void</span></div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;{</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;   initialize&lt;Architecture_t&gt;(fWeights, <a class="code" href="textangle_8C.html#a15eed939eb6efebfc935e895368c847a">m</a>);</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;   initialize&lt;Architecture_t&gt;(fBiases,  <a class="code" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279a941d5a341a6f6a7a3986952dda4e9445">EInitialization::kZero</a>);</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;}</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00265"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#af75bcc21a942d3a36b771f82b82eca13">  265</a></span>&#160;<span class="keyword">auto</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#af75bcc21a942d3a36b771f82b82eca13">TLayer&lt;Architecture_t&gt;::Forward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; input,</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;                                            <span class="keywordtype">bool</span> applyDropout)</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;-&gt; <span class="keywordtype">void</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;{</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;   <span class="keywordflow">if</span> (applyDropout &amp;&amp; (fDropoutProbability != 1.0)) {</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;      Architecture_t::Dropout(input, fDropoutProbability);</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;   }</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;   Architecture_t::MultiplyTranspose(fOutput, input, fWeights);</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;   Architecture_t::AddRowWise(fOutput, fBiases);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;   evaluateDerivative&lt;Architecture_t&gt;(fDerivatives, fF, fOutput);</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;   evaluate&lt;Architecture_t&gt;(fOutput, fF);</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;}</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00280"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a00dc5fb3b86711cc1c1fcfe1543fbe7c">  280</a></span>&#160;<span class="keyword">auto</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a00dc5fb3b86711cc1c1fcfe1543fbe7c">TLayer&lt;Architecture_t&gt;::Backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; gradients_backward,</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                                    <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">Matrix_t</a> &amp; activations_backward,</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                                    <a class="code" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="code" href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a>,</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;                                    <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">Scalar_t</a> <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>)</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;-&gt; <span class="keywordtype">void</span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;{</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;   Architecture_t::Backward(gradients_backward,</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;                            fWeightGradients,</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;                            fBiasGradients,</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;                            fDerivatives,</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;                            fActivationGradients,</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;                            fWeights,</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;                            activations_backward);</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;   addRegularizationGradients&lt;Architecture_t&gt;(fWeightGradients,</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;                                              fWeights,</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;                                              <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>, <a class="code" href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a>);</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;}</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00300"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TLayer.html#a9b374e979211a9607f852833a09ab5ea">  300</a></span>&#160;   <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html#a9b374e979211a9607f852833a09ab5ea">TLayer&lt;Architecture_t&gt;::Print</a>()<span class="keyword"> const</span></div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="keyword"></span>{</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;   std::cout &lt;&lt; <span class="stringliteral">&quot;Width = &quot;</span> &lt;&lt; fWeights.GetNrows();</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;   std::cout &lt;&lt; <span class="stringliteral">&quot;, Activation Function = &quot;</span>;</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;   std::cout &lt;&lt; static_cast&lt;int&gt;(fF) &lt;&lt; std::endl;</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;}</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;<span class="comment">//  The Shared Layer Class - Implementation</span></div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00314"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1a4489e3fe800f78ebbbfc84c6d24d16">  314</a></span>&#160;<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1a4489e3fe800f78ebbbfc84c6d24d16">TSharedLayer&lt;Architecture_t&gt;::TSharedLayer</a>(<span class="keywordtype">size_t</span> BatchSize,</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;                                         <a class="code" href="classTMVA_1_1DNN_1_1TLayer.html">TLayer&lt;Architecture_t&gt;</a> &amp;layer)</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;: fBatchSize(BatchSize),</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;fInputWidth(layer.GetInputWidth()), fWidth(layer.GetWidth()),</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;fDropoutProbability(layer.GetDropoutProbability()),</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;fWeights(layer.GetWeights()), fBiases(layer.GetBiases()),</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;fOutput(fBatchSize, fWidth), fDerivatives(fBatchSize, fWidth),</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;fWeightGradients(fWidth, fInputWidth), fBiasGradients(fWidth, 1),</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;fActivationGradients(fBatchSize, fWidth), fF(layer.GetActivationFunction())</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;{</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;   <span class="comment">// Nothing to do here.</span></div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;}</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00329"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a08e571ea24267ea44b40971bdaa66dc0">  329</a></span>&#160;<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1a4489e3fe800f78ebbbfc84c6d24d16">TSharedLayer&lt;Architecture_t&gt;::TSharedLayer</a>(<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html">TSharedLayer</a> &amp;layer)</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;    : fBatchSize(layer.fBatchSize),</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;    fInputWidth(layer.GetInputWidth()), fWidth(layer.GetWidth()),</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;    fDropoutProbability(layer.fDropoutProbability), fWeights(layer.fWeights),</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;    fBiases(layer.fBiases), fOutput(layer.fBatchSize, fWidth),</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;    fDerivatives(layer.fBatchSize, fWidth), fWeightGradients(fWidth, fInputWidth),</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;    fBiasGradients(fWidth, 1), fActivationGradients(layer.fBatchSize, fWidth),</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;    fF(layer.fF)</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;{</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;}</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00342"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#aabdc28c54158720cb14c7f59ed53f7ed">  342</a></span>&#160;<span class="keyword">auto</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#aabdc28c54158720cb14c7f59ed53f7ed">TSharedLayer&lt;Architecture_t&gt;::Forward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; input,</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;                                                  <span class="keywordtype">bool</span> applyDropout)</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;-&gt; <span class="keywordtype">void</span></div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;{</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;   <span class="keywordflow">if</span> (applyDropout &amp;&amp; (fDropoutProbability != 1.0)) {</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;      Architecture_t::Dropout(input, fDropoutProbability);</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;   }</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;   Architecture_t::MultiplyTranspose(fOutput, input, fWeights);</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;   Architecture_t::AddRowWise(fOutput, fBiases);</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;   evaluateDerivative&lt;Architecture_t&gt;(fDerivatives, fF, fOutput);</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;   evaluate&lt;Architecture_t&gt;(fOutput, fF);</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;}</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00357"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af7109dc83f9f7aeb17cd87d1d72aea9a">  357</a></span>&#160;<span class="keyword">auto</span> <span class="keyword">inline</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#af7109dc83f9f7aeb17cd87d1d72aea9a">TSharedLayer&lt;Architecture_t&gt;::Backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; gradients_backward,</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;                                                 <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">Matrix_t</a> &amp; activations_backward,</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;                                                 <a class="code" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="code" href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a>,</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;                                                 <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">Scalar_t</a> <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>)</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;-&gt; <span class="keywordtype">void</span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;{</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;   Architecture_t::Backward(gradients_backward,</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;                            fWeightGradients,</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;                            fBiasGradients,</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;                            fDerivatives,</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;                            fActivationGradients,</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;                            fWeights,</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;                            activations_backward);</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;   addRegularizationGradients&lt;Architecture_t&gt;(fWeightGradients,</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;                                              fWeights,</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;                                              <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>, <a class="code" href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a>);</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;}</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Architecture_t&gt;</div><div class="line"><a name="l00377"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9c3add0dce60ec8111f09f90d7b12904">  377</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9c3add0dce60ec8111f09f90d7b12904">TSharedLayer&lt;Architecture_t&gt;::Print</a>()<span class="keyword"> const</span></div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;<span class="keyword"></span>{</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;   std::cout &lt;&lt; <span class="stringliteral">&quot;Width = &quot;</span> &lt;&lt; fWeights.GetNrows();</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;   std::cout &lt;&lt; <span class="stringliteral">&quot;, Activation Function = &quot;</span>;</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;   std::cout &lt;&lt; static_cast&lt;int&gt;(fF) &lt;&lt; std::endl;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;}</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;} <span class="comment">// namespace DNN</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;} <span class="comment">// namespace TMVA</span></div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_af75bcc21a942d3a36b771f82b82eca13"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#af75bcc21a942d3a36b771f82b82eca13">TMVA::DNN::TLayer::Forward</a></div><div class="ttdeci">void Forward(Matrix_t &amp;input, bool applyDropout=false)</div><div class="ttdoc">Compute activation of the layer for the given input. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00265">Layer.h:265</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_abb1aef0108ef8f0f9baead77715429a5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#abb1aef0108ef8f0f9baead77715429a5">TMVA::DNN::TSharedLayer::fF</a></div><div class="ttdeci">EActivationFunction fF</div><div class="ttdoc">Activation function of the layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00169">Layer.h:169</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_aa9a44e9a8e0fe42aa937cc67adb26c4b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#aa9a44e9a8e0fe42aa937cc67adb26c4b">TMVA::DNN::TLayer::fWeightGradients</a></div><div class="ttdeci">Matrix_t fWeightGradients</div><div class="ttdoc">Gradients w.r.t. the weigths of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00071">Layer.h:71</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a9c3add0dce60ec8111f09f90d7b12904"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9c3add0dce60ec8111f09f90d7b12904">TMVA::DNN::TSharedLayer::Print</a></div><div class="ttdeci">void Print() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00377">Layer.h:377</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_af0acca3b810af5e6bcc7d19823c621f5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#af0acca3b810af5e6bcc7d19823c621f5">TMVA::DNN::TSharedLayer::SetDropoutProbability</a></div><div class="ttdeci">void SetDropoutProbability(Scalar_t p)</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00199">Layer.h:199</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a702cf8e17de767b17eaa21e23b1ee6b8"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a702cf8e17de767b17eaa21e23b1ee6b8">TMVA::DNN::TLayer::GetWeights</a></div><div class="ttdeci">Matrix_t &amp; GetWeights()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00117">Layer.h:117</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a78e8398e49b7a51b38d9e76f7740ff41"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a78e8398e49b7a51b38d9e76f7740ff41">TMVA::DNN::TSharedLayer::GetOutput</a></div><div class="ttdeci">Matrix_t &amp; GetOutput()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00203">Layer.h:203</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a31a7461dc950992a2326b5bbf53715d4"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a31a7461dc950992a2326b5bbf53715d4">TMVA::DNN::TLayer::TLayer</a></div><div class="ttdeci">TLayer(size_t BatchSize, size_t InputWidth, size_t Width, EActivationFunction f, Scalar_t dropoutProbability)</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00223">Layer.h:223</a></div></div>
<div class="ttc" id="textangle_8C_html_a15eed939eb6efebfc935e895368c847a"><div class="ttname"><a href="textangle_8C.html#a15eed939eb6efebfc935e895368c847a">m</a></div><div class="ttdeci">auto * m</div><div class="ttdef"><b>Definition:</b> <a href="textangle_8C_source.html#l00008">textangle.C:8</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a8a5900b3121ee0f1c529afe5e2dd2ccb"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8a5900b3121ee0f1c529afe5e2dd2ccb">TMVA::DNN::TSharedLayer::GetActivationFunction</a></div><div class="ttdeci">EActivationFunction GetActivationFunction() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00201">Layer.h:201</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a32f461095918e579682aa0e30aee12b3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a32f461095918e579682aa0e30aee12b3">TMVA::DNN::TLayer::fInputWidth</a></div><div class="ttdeci">size_t fInputWidth</div><div class="ttdoc">Number of neurons of the previous layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00062">Layer.h:62</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_aacfd9cebe978f116dddf9327af9aada1"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#aacfd9cebe978f116dddf9327af9aada1">TMVA::DNN::TLayer::fBatchSize</a></div><div class="ttdeci">size_t fBatchSize</div><div class="ttdoc">Batch size used for training and evaluation. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00061">Layer.h:61</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a00dc5fb3b86711cc1c1fcfe1543fbe7c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a00dc5fb3b86711cc1c1fcfe1543fbe7c">TMVA::DNN::TLayer::Backward</a></div><div class="ttdeci">void Backward(Matrix_t &amp;gradients_backward, const Matrix_t &amp;activations_backward, ERegularization r, Scalar_t weightDecay)</div><div class="ttdoc">Compute weight, bias and activation gradients. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00280">Layer.h:280</a></div></div>
<div class="ttc" id="RSha256_8hxx_html_a357394e0f6f88c8a57bd893ab28dc8f8"><div class="ttname"><a href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a></div><div class="ttdeci">#define f(i)</div><div class="ttdef"><b>Definition:</b> <a href="RSha256_8hxx_source.html#l00104">RSha256.hxx:104</a></div></div>
<div class="ttc" id="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_html"><div class="ttname"><a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h.html">Functions.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a1a4489e3fe800f78ebbbfc84c6d24d16"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1a4489e3fe800f78ebbbfc84c6d24d16">TMVA::DNN::TSharedLayer::TSharedLayer</a></div><div class="ttdeci">TSharedLayer(size_t fBatchSize, TLayer&lt; Architecture_t &gt; &amp;layer)</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00314">Layer.h:314</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a91327b7db79179cfb43c449778be8605"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a91327b7db79179cfb43c449778be8605">TMVA::DNN::TLayer::GetDropoutProbability</a></div><div class="ttdeci">size_t GetDropoutProbability() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00109">Layer.h:109</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a28adac9fe38a1404c2c86880f9cd72c9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a28adac9fe38a1404c2c86880f9cd72c9">TMVA::DNN::TSharedLayer::GetWeights</a></div><div class="ttdeci">Matrix_t &amp; GetWeights() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00205">Layer.h:205</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a9562b8696f8b758bdae24b281ac45bd2"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9562b8696f8b758bdae24b281ac45bd2">TMVA::DNN::TSharedLayer::GetDropoutProbability</a></div><div class="ttdeci">size_t GetDropoutProbability() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00197">Layer.h:197</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a069c290fd61150c22da4bb3e9f7f2eb3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a069c290fd61150c22da4bb3e9f7f2eb3">TMVA::DNN::TSharedLayer::fOutput</a></div><div class="ttdeci">Matrix_t fOutput</div><div class="ttdoc">Activations of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00163">Layer.h:163</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_af95f65da6b3e662089bb89b552f7af07"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#af95f65da6b3e662089bb89b552f7af07">TMVA::DNN::TSharedLayer::GetOutput</a></div><div class="ttdeci">const Matrix_t &amp; GetOutput() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00204">Layer.h:204</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a2e89808fb4c206730394717c37c7182a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2e89808fb4c206730394717c37c7182a">TMVA::DNN::TSharedLayer::GetBiasGradients</a></div><div class="ttdeci">const Matrix_t &amp; GetBiasGradients() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00211">Layer.h:211</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_ac9526af256b9f8f76a2a37714c13d2fd"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#ac9526af256b9f8f76a2a37714c13d2fd">TMVA::DNN::TLayer::GetWeightGradients</a></div><div class="ttdeci">Matrix_t &amp; GetWeightGradients()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00125">Layer.h:125</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a1da3619b1b593fdab4c6a653a0487c94"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a1da3619b1b593fdab4c6a653a0487c94">TMVA::DNN::TLayer::fF</a></div><div class="ttdeci">EActivationFunction fF</div><div class="ttdoc">Activation function of the layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00075">Layer.h:75</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a3f23cdc3a2ad5baaaa179773d88655e5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a3f23cdc3a2ad5baaaa179773d88655e5">TMVA::DNN::TSharedLayer::fDerivatives</a></div><div class="ttdeci">Matrix_t fDerivatives</div><div class="ttdoc">First fDerivatives of the activations of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00164">Layer.h:164</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_af596566350f379903a1d00e66ec551c7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#af596566350f379903a1d00e66ec551c7">TMVA::DNN::TSharedLayer::GetBiases</a></div><div class="ttdeci">const Matrix_t &amp; GetBiases() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00207">Layer.h:207</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_acf4f0b067f35fa806fd8d46472bfac2b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#acf4f0b067f35fa806fd8d46472bfac2b">TMVA::DNN::TLayer::GetBiases</a></div><div class="ttdeci">const Matrix_t &amp; GetBiases() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00120">Layer.h:120</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a049d2f0cfa299ef98834e42202151279"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">TMVA::DNN::EInitialization</a></div><div class="ttdeci">EInitialization</div><div class="ttdef"><b>Definition:</b> <a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_source.html#l00070">Functions.h:70</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a32f72b841008c65ec3dc7bc012e34a8a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a32f72b841008c65ec3dc7bc012e34a8a">TMVA::DNN::TLayer::fBiasGradients</a></div><div class="ttdeci">Matrix_t fBiasGradients</div><div class="ttdoc">Gradients w.r.t. the bias values of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00072">Layer.h:72</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a058d57c13d9b4a3fbba00d063e58ae4e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a058d57c13d9b4a3fbba00d063e58ae4e">TMVA::DNN::TSharedLayer::fBiases</a></div><div class="ttdeci">Matrix_t &amp; fBiases</div><div class="ttdoc">Reference to the bias vectors of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00162">Layer.h:162</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a87e433880b8429b73362b580db5421b7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a87e433880b8429b73362b580db5421b7">TMVA::DNN::TSharedLayer::fWeightGradients</a></div><div class="ttdeci">Matrix_t fWeightGradients</div><div class="ttdoc">Gradients w.r.t. the weigths of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00165">Layer.h:165</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html">TMVA::DNN::TLayer</a></div><div class="ttdoc">Generic layer class. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00052">Layer.h:52</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_ab8de2ae6fffcf431a10cad1cefc7bec3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#ab8de2ae6fffcf431a10cad1cefc7bec3">TMVA::DNN::TLayer::fWeights</a></div><div class="ttdeci">Matrix_t fWeights</div><div class="ttdoc">The fWeights of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00067">Layer.h:67</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a492993d5217855869e20508313007305"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">TMVA::DNN::weightDecay</a></div><div class="ttdeci">double weightDecay(double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization)</div><div class="ttdoc">compute the weight decay for regularization (L1 or L2) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00496">NeuralNet.icc:496</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a4c712d1e8db7733c2932e084bff0b7fa"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4c712d1e8db7733c2932e084bff0b7fa">TMVA::DNN::TSharedLayer::fInputWidth</a></div><div class="ttdeci">size_t fInputWidth</div><div class="ttdoc">Number of neurons of the previous layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00156">Layer.h:156</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a8cd8e44cf6074f5f08ddc07335e83cd3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a8cd8e44cf6074f5f08ddc07335e83cd3">TMVA::DNN::TLayer::GetBiasGradients</a></div><div class="ttdeci">Matrix_t &amp; GetBiasGradients()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00123">Layer.h:123</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a9f1fdc2371e65ed0f61f0ee93d59a4e3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9f1fdc2371e65ed0f61f0ee93d59a4e3">TMVA::DNN::TSharedLayer::GetWeightGradients</a></div><div class="ttdeci">Matrix_t &amp; GetWeightGradients()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00212">Layer.h:212</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a46c61123424cda62c91170391649ca67"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a46c61123424cda62c91170391649ca67">TMVA::DNN::TLayer::GetActivationGradients</a></div><div class="ttdeci">const Matrix_t &amp; GetActivationGradients() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00122">Layer.h:122</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_ab541868363be6fed14f48064dec1859f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#ab541868363be6fed14f48064dec1859f">TMVA::DNN::TSharedLayer::Scalar_t</a></div><div class="ttdeci">typename Architecture_t::Scalar_t Scalar_t</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00150">Layer.h:150</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a8cb3356df4af8d71f76fd1f85bfabdb3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a8cb3356df4af8d71f76fd1f85bfabdb3">TMVA::DNN::TLayer::Scalar_t</a></div><div class="ttdeci">typename Architecture_t::Scalar_t Scalar_t</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00056">Layer.h:56</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a72fe1a8cd0e407aece41e6448e5d183e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a72fe1a8cd0e407aece41e6448e5d183e">TMVA::DNN::TLayer::fBiases</a></div><div class="ttdeci">Matrix_t fBiases</div><div class="ttdoc">The bias values of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00068">Layer.h:68</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_ada893a8d8a8986e913dae28d2c21eff5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#ada893a8d8a8986e913dae28d2c21eff5">TMVA::DNN::TLayer::GetWidth</a></div><div class="ttdeci">size_t GetWidth() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00108">Layer.h:108</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a2d4567cb440d261980ecc55e9cc15ae5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d4567cb440d261980ecc55e9cc15ae5">TMVA::DNN::TSharedLayer::fBiasGradients</a></div><div class="ttdeci">Matrix_t fBiasGradients</div><div class="ttdoc">Gradients w.r.t. the bias values of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00166">Layer.h:166</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a698e714a2bd93638d8b73bee9733c7fc"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a698e714a2bd93638d8b73bee9733c7fc">TMVA::DNN::TLayer::GetInputWidth</a></div><div class="ttdeci">size_t GetInputWidth() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00107">Layer.h:107</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a7ab0f9ac32cebd85886ad0ad3797affe"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a7ab0f9ac32cebd85886ad0ad3797affe">TMVA::DNN::TLayer::GetOutput</a></div><div class="ttdeci">Matrix_t &amp; GetOutput()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00115">Layer.h:115</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a753949b54402ed2bea4d08b464632a3a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a753949b54402ed2bea4d08b464632a3a">TMVA::DNN::TSharedLayer::GetActivationGradients</a></div><div class="ttdeci">Matrix_t &amp; GetActivationGradients()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00208">Layer.h:208</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a59570627e8f146205c7181079fa074dd"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a59570627e8f146205c7181079fa074dd">TMVA::DNN::TLayer::GetActivationFunction</a></div><div class="ttdeci">EActivationFunction GetActivationFunction() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00113">Layer.h:113</a></div></div>
<div class="ttc" id="Object_8C_html_ac15f01b9c6407e1312dfc196ad4e0870"><div class="ttname"><a href="Object_8C.html#ac15f01b9c6407e1312dfc196ad4e0870">r</a></div><div class="ttdeci">ROOT::R::TRInterface &amp; r</div><div class="ttdef"><b>Definition:</b> <a href="Object_8C_source.html#l00004">Object.C:4</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a097852476c78d1faff69bbc62be40a89"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a097852476c78d1faff69bbc62be40a89">TMVA::DNN::TLayer::GetActivationGradients</a></div><div class="ttdeci">Matrix_t &amp; GetActivationGradients()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00121">Layer.h:121</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a43fb2a282517efd7c90634936ace9982"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a43fb2a282517efd7c90634936ace9982">TMVA::DNN::TSharedLayer::Matrix_t</a></div><div class="ttdeci">typename Architecture_t::Matrix_t Matrix_t</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00151">Layer.h:151</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a97f3796826b70587c98743c5fe785481"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a97f3796826b70587c98743c5fe785481">TMVA::DNN::TSharedLayer::GetInputWidth</a></div><div class="ttdeci">size_t GetInputWidth() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00195">Layer.h:195</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a5e8dad0a0c4b0ffd00a737f4c6636a72"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a5e8dad0a0c4b0ffd00a737f4c6636a72">TMVA::DNN::TLayer::GetBatchSize</a></div><div class="ttdeci">size_t GetBatchSize() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00106">Layer.h:106</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a53f3cfb336eb13a5299978c307e0b7b2"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a53f3cfb336eb13a5299978c307e0b7b2">TMVA::DNN::TLayer::fOutput</a></div><div class="ttdeci">Matrix_t fOutput</div><div class="ttdoc">Activations of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00069">Layer.h:69</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_abf47e1e5b76c47a303a1600b014c5ada"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#abf47e1e5b76c47a303a1600b014c5ada">TMVA::DNN::TSharedLayer::fDropoutProbability</a></div><div class="ttdeci">Scalar_t fDropoutProbability</div><div class="ttdoc">Probability that an input is active. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00159">Layer.h:159</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a1d3c6ba16efaf7b0fa66abd74b71e489"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a1d3c6ba16efaf7b0fa66abd74b71e489">TMVA::DNN::TSharedLayer::fWeights</a></div><div class="ttdeci">Matrix_t &amp; fWeights</div><div class="ttdoc">Reference to the weight matrix of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00161">Layer.h:161</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_aee1936c277f5ff9d0ceec86015d1b35b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#aee1936c277f5ff9d0ceec86015d1b35b">TMVA::DNN::TSharedLayer::GetBiasGradients</a></div><div class="ttdeci">Matrix_t &amp; GetBiasGradients()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00210">Layer.h:210</a></div></div>
<div class="ttc" id="TDocParser_8cxx_html_a728a0b17511d9239de0b9bb40ad60600"><div class="ttname"><a href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a></div><div class="ttdeci">include TDocParser_001 C image html pict1_TDocParser_001 png width</div><div class="ttdef"><b>Definition:</b> <a href="TDocParser_8cxx_source.html#l00121">TDocParser.cxx:121</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a6991ec6151aa9e1ee90d10f71da48728"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a6991ec6151aa9e1ee90d10f71da48728">TMVA::DNN::TLayer::GetOutput</a></div><div class="ttdeci">const Matrix_t &amp; GetOutput() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00116">Layer.h:116</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a00f26f6066332d4aece5260e91607aea"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a00f26f6066332d4aece5260e91607aea">TMVA::DNN::TSharedLayer::GetWeightGradients</a></div><div class="ttdeci">const Matrix_t &amp; GetWeightGradients() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00213">Layer.h:213</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a85660231b8a713438aa1d39e43265f98"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a85660231b8a713438aa1d39e43265f98">TMVA::DNN::TSharedLayer::fBatchSize</a></div><div class="ttdeci">size_t fBatchSize</div><div class="ttdoc">Batch size used for training and evaluation. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00155">Layer.h:155</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_aabdc28c54158720cb14c7f59ed53f7ed"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#aabdc28c54158720cb14c7f59ed53f7ed">TMVA::DNN::TSharedLayer::Forward</a></div><div class="ttdeci">void Forward(Matrix_t &amp;input, bool applyDropout=false)</div><div class="ttdoc">Compute activation of the layer for the given input. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00342">Layer.h:342</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_ab37018cf9def8849754b243caa60aeca"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#ab37018cf9def8849754b243caa60aeca">TMVA::DNN::TLayer::Initialize</a></div><div class="ttdeci">void Initialize(EInitialization m)</div><div class="ttdoc">Initialize fWeights according to the given initialization method. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00256">Layer.h:256</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a06c3a194a43fca8ca555c0b1c9795ef8"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a06c3a194a43fca8ca555c0b1c9795ef8">TMVA::DNN::TLayer::SetDropoutProbability</a></div><div class="ttdeci">void SetDropoutProbability(Scalar_t p)</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00111">Layer.h:111</a></div></div>
<div class="ttc" id="namespaceROOT_1_1Math_1_1GSLSimAn_html_a4f40b1163d80135a8fa14dd77e2c8f09"><div class="ttname"><a href="namespaceROOT_1_1Math_1_1GSLSimAn.html#a4f40b1163d80135a8fa14dd77e2c8f09">ROOT::Math::GSLSimAn::Copy</a></div><div class="ttdeci">void Copy(void *source, void *dest)</div><div class="ttdef"><b>Definition:</b> <a href="GSLSimAnnealing_8cxx_source.html#l00149">GSLSimAnnealing.cxx:149</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_abe7e237d899352e1ef4462068516455f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#abe7e237d899352e1ef4462068516455f">TMVA::DNN::TLayer::GetBiases</a></div><div class="ttdeci">Matrix_t &amp; GetBiases()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00119">Layer.h:119</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a049d2f0cfa299ef98834e42202151279a941d5a341a6f6a7a3986952dda4e9445"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279a941d5a341a6f6a7a3986952dda4e9445">TMVA::DNN::EInitialization::kZero</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html">TMVA::DNN::TSharedLayer</a></div><div class="ttdoc">Layer class width shared weight and bias layers. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00145">Layer.h:145</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_ad4ccd32bf8a939245c9fb89009402bc4"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#ad4ccd32bf8a939245c9fb89009402bc4">TMVA::DNN::TLayer::fDerivatives</a></div><div class="ttdeci">Matrix_t fDerivatives</div><div class="ttdoc">First fDerivatives of the activations of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00070">Layer.h:70</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a4e3891e18fd770c4fb4e58fbb9a866e1"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a4e3891e18fd770c4fb4e58fbb9a866e1">TMVA::DNN::TSharedLayer::GetActivationGradients</a></div><div class="ttdeci">const Matrix_t &amp; GetActivationGradients() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00209">Layer.h:209</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a751dd3852367b7fc3fe41d4db8ac610d"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a751dd3852367b7fc3fe41d4db8ac610d">TMVA::DNN::TLayer::fWidth</a></div><div class="ttdeci">size_t fWidth</div><div class="ttdoc">Number of neurons of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00063">Layer.h:63</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a65d7c9c974a35da4cb27eb59b67226b2"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a65d7c9c974a35da4cb27eb59b67226b2">TMVA::DNN::TSharedLayer::GetBiases</a></div><div class="ttdeci">Matrix_t &amp; GetBiases()</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00206">Layer.h:206</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a2d8006fbc5ab4dfcf7184647933fbfe9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a2d8006fbc5ab4dfcf7184647933fbfe9">TMVA::DNN::TLayer::fActivationGradients</a></div><div class="ttdeci">Matrix_t fActivationGradients</div><div class="ttdoc">Gradients w.r.t. the activations of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00073">Layer.h:73</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a71ae97293c4019b17186d6ee0691ee20"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a71ae97293c4019b17186d6ee0691ee20">TMVA::DNN::TLayer::fDropoutProbability</a></div><div class="ttdeci">Scalar_t fDropoutProbability</div><div class="ttdoc">Probability that an input is active. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00065">Layer.h:65</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a86c67cb9b1e1f41b784c450c05f2945e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a86c67cb9b1e1f41b784c450c05f2945e">TMVA::DNN::TLayer::Matrix_t</a></div><div class="ttdeci">typename Architecture_t::Matrix_t Matrix_t</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00057">Layer.h:57</a></div></div>
<div class="ttc" id="namespaceTMVA_html"><div class="ttname"><a href="namespaceTMVA.html">TMVA</a></div><div class="ttdoc">create variable transformations </div><div class="ttdef"><b>Definition:</b> <a href="GeneticMinimizer_8h_source.html#l00021">GeneticMinimizer.h:21</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a8f8e00699e099480bab81109604cc21a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a8f8e00699e099480bab81109604cc21a">TMVA::DNN::TSharedLayer::fActivationGradients</a></div><div class="ttdeci">Matrix_t fActivationGradients</div><div class="ttdoc">Gradients w.r.t. the activations of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00167">Layer.h:167</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a9d2e92b1852127300f0bf360e8160c1c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a9d2e92b1852127300f0bf360e8160c1c">TMVA::DNN::TSharedLayer::GetBatchSize</a></div><div class="ttdeci">size_t GetBatchSize() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00194">Layer.h:194</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a64325c2ac191062b28a7da62a3f63a21"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">TMVA::DNN::ERegularization</a></div><div class="ttdeci">ERegularization</div><div class="ttdoc">Enum representing the regularization type applied for a given layer. </div><div class="ttdef"><b>Definition:</b> <a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_source.html#l00062">Functions.h:62</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_aeb7cc8d813ab530109dd3974fc158238"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#aeb7cc8d813ab530109dd3974fc158238">TMVA::DNN::TLayer::GetWeights</a></div><div class="ttdeci">const Matrix_t &amp; GetWeights() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00118">Layer.h:118</a></div></div>
<div class="ttc" id="TMatrix_8h_html"><div class="ttname"><a href="TMatrix_8h.html">TMatrix.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_ab396f0c39ec3e5e0e4ecc50c5231757c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#ab396f0c39ec3e5e0e4ecc50c5231757c">TMVA::DNN::TLayer::GetBiasGradients</a></div><div class="ttdeci">const Matrix_t &amp; GetBiasGradients() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00124">Layer.h:124</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a74e33dcb050697064c231b88b51866c4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">TMVA::DNN::EActivationFunction</a></div><div class="ttdeci">EActivationFunction</div><div class="ttdoc">Enum that represents layer activation functions. </div><div class="ttdef"><b>Definition:</b> <a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_source.html#l00031">Functions.h:31</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_af7109dc83f9f7aeb17cd87d1d72aea9a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#af7109dc83f9f7aeb17cd87d1d72aea9a">TMVA::DNN::TSharedLayer::Backward</a></div><div class="ttdeci">void Backward(Matrix_t &amp;gradients_backward, const Matrix_t &amp;activations_backward, ERegularization r, Scalar_t weightDecay)</div><div class="ttdoc">Compute weight, bias and activation gradients. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00357">Layer.h:357</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a6b36998f85371f600b3d99739c4b2a94"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a6b36998f85371f600b3d99739c4b2a94">TMVA::DNN::TSharedLayer::fWidth</a></div><div class="ttdeci">size_t fWidth</div><div class="ttdoc">Number of neurons of this layer. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00157">Layer.h:157</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a3268338c605b79859fa1913b25c4553f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a3268338c605b79859fa1913b25c4553f">TMVA::DNN::TLayer::GetWeightGradients</a></div><div class="ttdeci">const Matrix_t &amp; GetWeightGradients() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00126">Layer.h:126</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TSharedLayer_html_a2d27f641f5229f579719b52ebb7dc14c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TSharedLayer.html#a2d27f641f5229f579719b52ebb7dc14c">TMVA::DNN::TSharedLayer::GetWidth</a></div><div class="ttdeci">size_t GetWidth() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00196">Layer.h:196</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TLayer_html_a9b374e979211a9607f852833a09ab5ea"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TLayer.html#a9b374e979211a9607f852833a09ab5ea">TMVA::DNN::TLayer::Print</a></div><div class="ttdeci">void Print() const</div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00300">Layer.h:300</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:09:44 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
