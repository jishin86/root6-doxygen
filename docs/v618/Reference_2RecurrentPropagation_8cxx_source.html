<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: tmva/tmva/src/DNN/Architectures/Reference/RecurrentPropagation.cxx Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a647c3f16b21786eaaa28427c9c80e3e.html">tmva</a></li><li class="navelem"><a class="el" href="dir_ed3dab6383bd5f321850908cd5a1281f.html">tmva</a></li><li class="navelem"><a class="el" href="dir_fa043daba8c93a66cb43f1b81507d7c7.html">src</a></li><li class="navelem"><a class="el" href="dir_df7c32e2fe17754e3ce1c30d2c5e26f7.html">DNN</a></li><li class="navelem"><a class="el" href="dir_8d602a0373dbb3b30f0de52bdc58b0a7.html">Architectures</a></li><li class="navelem"><a class="el" href="dir_f84f4e204271598043a6882ed9448908.html">Reference</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">RecurrentPropagation.cxx</div>  </div>
</div><!--header-->
<div class="contents">
<a href="Reference_2RecurrentPropagation_8cxx.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// @(#)root/tmva/tmva/dnn:$Id$ </span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Author: Saurav Shekhar 23/06/17</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">/*************************************************************************</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * Copyright (C) 2017, Saurav Shekhar                                    *</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * All rights reserved.                                                  *</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> *                                                                       *</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * For the licensing terms see $ROOTSYS/LICENSE.                         *</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> * For the list of contributors see $ROOTSYS/README/CREDITS.             *</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *************************************************************************/</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">/////////////////////////////////////////////////////////////////////</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"></span><span class="comment">// Implementation of the functions required for the forward and    //</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// backward propagation of activations through a recurrent neural  //</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">// network in the reference implementation.                        //</span><span class="comment"></span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">/////////////////////////////////////////////////////////////////////</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Reference_8h.html">TMVA/DNN/Architectures/Reference.h</a>&quot;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceTMVA.html">TMVA</a> {</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">namespace </span>DNN  {</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;  </div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment">//______________________________________________________________________________</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Scalar_t&gt;</div><div class="line"><a name="l00026"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#afd0c99b8895d2de2fba7381b2e3b6871">   26</a></span>&#160;<span class="keyword">auto</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#afd0c99b8895d2de2fba7381b2e3b6871">TReference&lt;Scalar_t&gt;::RecurrentLayerBackward</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; state_gradients_backward, <span class="comment">// BxH</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;                                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; input_weight_gradients,</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;                                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; state_weight_gradients,</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;                                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; bias_gradients,</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;                                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; df, <span class="comment">//BxH</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;                                                  <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; state, <span class="comment">// BxH</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;                                                  <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; weights_input, <span class="comment">// HxD </span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;                                                  <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; weights_state, <span class="comment">// HxH</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;                                                  <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; input,  <span class="comment">// BxD</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;                                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; input_gradient)</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;-&gt; <a class="code" href="classTMatrixT.html">Matrix_t</a> &amp;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;{</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;Reference Recurrent Propo&quot; &lt;&lt; std::endl;</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;df\n&quot;;</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;   <span class="comment">// df.Print();</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;state gradient\n&quot;;</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;   <span class="comment">// state_gradients_backward.Print();</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;inputw gradient\n&quot;;</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;   <span class="comment">// input_weight_gradients.Print(); </span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;state\n&quot;;</span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;   <span class="comment">// state.Print();</span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;input\n&quot;;</span></div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;   <span class="comment">// input.Print();</span></div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;   </div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;   <span class="comment">// Compute element-wise product.</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; (size_t) df.GetNrows(); i++) {</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;      <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; (size_t) df.GetNcols(); j++) {</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;         df(i,j) *= state_gradients_backward(i,j);      <span class="comment">// B x H</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;      }</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;   }</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;   </div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;   <span class="comment">// Input gradients.</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;   <span class="keywordflow">if</span> (input_gradient.GetNoElements() &gt; 0) {</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;      input_gradient.Mult(df, weights_input);     <span class="comment">// B x H . H x D = B x D</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;   }</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;   <span class="comment">// State gradients</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;   <span class="keywordflow">if</span> (state_gradients_backward.GetNoElements() &gt; 0) {</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;      state_gradients_backward.Mult(df, weights_state);  <span class="comment">// B x H . H x H = B x H</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;   }</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;   </div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;   <span class="comment">// Weights gradients.</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;   <span class="keywordflow">if</span> (input_weight_gradients.GetNoElements() &gt; 0) {</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;      <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> tmp(input_weight_gradients);</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;      input_weight_gradients.TMult(df, input);             <span class="comment">// H x B . B x D</span></div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;      input_weight_gradients += tmp;</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;   }</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;   <span class="keywordflow">if</span> (state_weight_gradients.GetNoElements() &gt; 0) {</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;      <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> tmp(state_weight_gradients);</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;      state_weight_gradients.TMult(df, state);             <span class="comment">// H x B . B x H</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;      state_weight_gradients += tmp;</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;   }</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;   </div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;   <span class="comment">// Bias gradients. B x H -&gt; H x 1</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;   <span class="keywordflow">if</span> (bias_gradients.GetNoElements() &gt; 0) {</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;      <span class="comment">// this loops on state size</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;      <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; (size_t) df.GetNcols(); j++) {</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;         <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">Scalar_t</a> <a class="code" href="tmva_2tmva_2src_2Factory_8cxx.html#a73e5b6a37db0af518793b45eba2bbe8e">sum</a> = 0.0;</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;         <span class="comment">// this loops on batch size summing all gradient contributions in a batch</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;         <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; (size_t) df.GetNrows(); i++) {</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;            <a class="code" href="tmva_2tmva_2src_2Factory_8cxx.html#a73e5b6a37db0af518793b45eba2bbe8e">sum</a> += df(i,j);</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;         }</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;         bias_gradients(j,0) += <a class="code" href="tmva_2tmva_2src_2Factory_8cxx.html#a73e5b6a37db0af518793b45eba2bbe8e">sum</a>;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;      }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;   }</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;RecurrentPropo: end &quot; &lt;&lt; std::endl;</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;state gradient\n&quot;;</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;   <span class="comment">// state_gradients_backward.Print();</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;inputw gradient\n&quot;;</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;   <span class="comment">// input_weight_gradients.Print(); </span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;bias gradient\n&quot;;</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;   <span class="comment">// bias_gradients.Print(); </span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;   <span class="comment">// std::cout &lt;&lt; &quot;input gradient\n&quot;;</span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;   <span class="comment">// input_gradient.Print(); </span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;   </div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;   <span class="keywordflow">return</span> input_gradient;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;}</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;} <span class="comment">// namespace DNN</span></div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;} <span class="comment">// namespace TMVA</span></div><div class="ttc" id="tmva_2tmva_2src_2Factory_8cxx_html_a73e5b6a37db0af518793b45eba2bbe8e"><div class="ttname"><a href="tmva_2tmva_2src_2Factory_8cxx.html#a73e5b6a37db0af518793b45eba2bbe8e">sum</a></div><div class="ttdeci">static long int sum(long int i)</div><div class="ttdef"><b>Definition:</b> <a href="tmva_2tmva_2src_2Factory_8cxx_source.html#l02258">Factory.cxx:2258</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_afd0c99b8895d2de2fba7381b2e3b6871"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#afd0c99b8895d2de2fba7381b2e3b6871">TMVA::DNN::TReference::RecurrentLayerBackward</a></div><div class="ttdeci">static Matrix_t &amp; RecurrentLayerBackward(TMatrixT&lt; Scalar_t &gt; &amp;state_gradients_backward, TMatrixT&lt; Scalar_t &gt; &amp;input_weight_gradients, TMatrixT&lt; Scalar_t &gt; &amp;state_weight_gradients, TMatrixT&lt; Scalar_t &gt; &amp;bias_gradients, TMatrixT&lt; Scalar_t &gt; &amp;df, const TMatrixT&lt; Scalar_t &gt; &amp;state, const TMatrixT&lt; Scalar_t &gt; &amp;weights_input, const TMatrixT&lt; Scalar_t &gt; &amp;weights_state, const TMatrixT&lt; Scalar_t &gt; &amp;input, TMatrixT&lt; Scalar_t &gt; &amp;input_gradient)</div><div class="ttdoc">Backpropagation step for a Recurrent Neural Network. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2RecurrentPropagation_8cxx_source.html#l00026">RecurrentPropagation.cxx:26</a></div></div>
<div class="ttc" id="Reference_8h_html"><div class="ttname"><a href="Reference_8h.html">Reference.h</a></div></div>
<div class="ttc" id="classTMatrixT_html"><div class="ttname"><a href="classTMatrixT.html">TMatrixT</a></div><div class="ttdoc">TMatrixT. </div><div class="ttdef"><b>Definition:</b> <a href="TMatrixDfwd_8h_source.html#l00022">TMatrixDfwd.h:22</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a8de41bb6bf802a42a8bf99d5b6dfe3a3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">TMVA::DNN::TReference::Scalar_t</a></div><div class="ttdeci">AReal Scalar_t</div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00050">Reference.h:50</a></div></div>
<div class="ttc" id="namespaceTMVA_html"><div class="ttname"><a href="namespaceTMVA.html">TMVA</a></div><div class="ttdoc">create variable transformations </div><div class="ttdef"><b>Definition:</b> <a href="GeneticMinimizer_8h_source.html#l00021">GeneticMinimizer.h:21</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:09:46 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
