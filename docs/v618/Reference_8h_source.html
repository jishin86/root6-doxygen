<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: tmva/tmva/inc/TMVA/DNN/Architectures/Reference.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a647c3f16b21786eaaa28427c9c80e3e.html">tmva</a></li><li class="navelem"><a class="el" href="dir_ed3dab6383bd5f321850908cd5a1281f.html">tmva</a></li><li class="navelem"><a class="el" href="dir_e5f324a990c4e53e87e3a4847f1d2164.html">inc</a></li><li class="navelem"><a class="el" href="dir_b2d93ebd3f51b5d9cf703b0851621985.html">TMVA</a></li><li class="navelem"><a class="el" href="dir_d9e07824f297128826b01e2ad3fd4d49.html">DNN</a></li><li class="navelem"><a class="el" href="dir_6ba023fe58ba4048e65989f766ef6c93.html">Architectures</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Reference.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="Reference_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// @(#)root/tmva/tmva/dnn:$Id$</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Author: Simon Pfreundschuh 20/06/16</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">/*************************************************************************</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * Copyright (C) 2016, Simon Pfreundschuh                                *</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * All rights reserved.                                                  *</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> *                                                                       *</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * For the licensing terms see $ROOTSYS/LICENSE.                         *</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> * For the list of contributors see $ROOTSYS/README/CREDITS.             *</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *************************************************************************/</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">///////////////////////////////////////////////////////////////////////</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"></span><span class="comment">// Declaration of the TReference architecture, which provides a      //</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// reference implementation of the low-level interface for the DNN   //</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">// implementation based on ROOT&#39;s TMatrixT matrix type.              //</span><span class="comment"></span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">///////////////////////////////////////////////////////////////////////</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#ifndef TMVA_DNN_ARCHITECTURES_REFERENCE</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#define TMVA_DNN_ARCHITECTURES_REFERENCE</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="TMatrix_8h.html">TMatrix.h</a>&quot;</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h.html">TMVA/DNN/Functions.h</a>&quot;</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="ConvLayer_8h.html">TMVA/DNN/CNN/ConvLayer.h</a>&quot;</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="DNN_2Architectures_2Reference_2DataLoader_8h.html">TMVA/DNN/Architectures/Reference/DataLoader.h</a>&quot;</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Architectures_2Reference_2TensorDataLoader_8h.html">TMVA/DNN/Architectures/Reference/TensorDataLoader.h</a>&quot;</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="keyword">class </span><a class="code" href="classTRandom.html">TRandom</a>;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceTMVA.html">TMVA</a></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;{</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">namespace </span>DNN</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;{</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">/*! The reference architecture class.</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment">*</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment">* Class template that contains the reference implementation of the low-level</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment">* interface for the DNN implementation. The reference implementation uses the</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment">* TMatrixT class template to represent matrices.</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment">*</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment">* \tparam AReal The floating point type used to represent scalars.</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment">*/</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> AReal&gt;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="keyword">class </span>TReference</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;{</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00047"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a8d19b34ca1e6edc8fbcf8df418a23d02">   47</a></span>&#160;   <span class="keyword">static</span> <a class="code" href="classTRandom.html">TRandom</a> * <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8d19b34ca1e6edc8fbcf8df418a23d02">fgRandomGen</a>;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">   50</a></span>&#160;   <span class="keyword">using</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">Scalar_t</a>     = AReal;</div><div class="line"><a name="l00051"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a019348b48fe66b390aad2b288fb55921">   51</a></span>&#160;   <span class="keyword">using</span> <a class="code" href="classTMatrixT.html">Matrix_t</a>     = <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>;</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;   <span class="comment">// Propagation</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">   /** @name Forward Propagation</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment">    * Low-level functions required for the forward propagation of activations</span></div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment">    * through the network.</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment"></span><span class="comment">   /** Matrix-multiply \p input with the transpose of \pweights and</span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">    *  write the results into \p output. */</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a11fc4ac4e11a2e0553004787ab57160d">MultiplyTranspose</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp;input,</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp;weights);<span class="comment"></span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">   /** Add the vectors biases row-wise to the matrix output */</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a33968e5cbf79be3dff67c1956724d3f7">AddRowWise</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;                          <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp;biases);<span class="comment"></span></div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">   /** @name Backward Propagation</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">    * Low-level functions required for the forward propagation of activations</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">    * through the network.</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment"></span><span class="comment">   /** Perform the complete backward propagation step. If the provided</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="comment">    *  \p activationGradientsBackward matrix is not empty, compute the</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="comment">    *  gradients of the objective function with respect to the activations</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment">    *  of the previous layer (backward direction).</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment">    *  Also compute the weight and the bias gradients. Modifies the values</span></div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment">    *  in \p df and thus produces only a valid result, if it is applied the</span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment">    *  first time after the corresponding forward propagation has been per-</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment">    *  formed. */</span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a6ec8151d92e8bafae94b7b0d5d36b86b">Backward</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; activationGradientsBackward,</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;                        <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; weightGradients,</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;                        <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; biasGradients,</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;                        <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; df,</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; activationGradients,</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; weights,</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; activationBackward);<span class="comment"></span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment">   /** Backpropagation step for a Recurrent Neural Network */</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;   <span class="keyword">static</span> <a class="code" href="classTMatrixT.html">Matrix_t</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#afd0c99b8895d2de2fba7381b2e3b6871">RecurrentLayerBackward</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; state_gradients_backward, <span class="comment">// BxH</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;                                            <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; input_weight_gradients,</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;                                            <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; state_weight_gradients,</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                                            <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; bias_gradients,</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;                                            <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; df, <span class="comment">//DxH</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; state, <span class="comment">// BxH</span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; weights_input, <span class="comment">// HxD</span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; weights_state, <span class="comment">// HxH</span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; input,  <span class="comment">// BxD</span></div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;                                            <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; input_gradient);<span class="comment"></span></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;<span class="comment">   /** Adds a the elements in matrix B scaled by c to the elements in</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment">    *  the matrix A. This is required for the weight update in the gradient</span></div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;<span class="comment">    *  descent step.*/</span></div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9b7007a78cd8fddb9a6f26f4c782b7de">ScaleAdd</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">Scalar_t</a> <a class="code" href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">beta</a> = 1.0);</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ac7137f9d1369daa39e3e8cde2272449b">Copy</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                    <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;   <span class="comment">// copy from another type of matrix</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;   <span class="keyword">template</span>&lt;<span class="keyword">typename</span> AMatrix_t&gt;</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9c3a6efb1d7f0f51ff5126d67ff8f333">CopyDiffArch</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> AMatrix_t &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="comment">   /** Above functions extended to vectors */</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9b7007a78cd8fddb9a6f26f4c782b7de">ScaleAdd</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a>&gt; &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;                        <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a>&gt; &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">Scalar_t</a> <a class="code" href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">beta</a> = 1.0);</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ac7137f9d1369daa39e3e8cde2272449b">Copy</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a>&gt; &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a>&gt; &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;   <span class="comment">// copy from another architecture</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;   <span class="keyword">template</span>&lt;<span class="keyword">typename</span> AMatrix_t&gt;</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9c3a6efb1d7f0f51ff5126d67ff8f333">CopyDiffArch</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &gt; &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> std::vector&lt;AMatrix_t&gt; &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;   <span class="comment">// Activation Functions</span></div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment">   /** @name Activation Functions</span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment">    * For each activation function, the low-level interface contains two routines.</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment">    * One that applies the acitvation function to a matrix and one that evaluate</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment">    * the derivatives of the activation function at the elements of a given matrix</span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment">    * and writes the results into the result matrix.</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment"></span>   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ab0b8d758aba8d5bd85ac7bf94a1366e5">Identity</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a4ba4f2378958700c496e6f64a38b59d7">IdentityDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;                                  <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a1efefcce6d75e95b7a202d9cc095aa6e">Relu</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#adb3e54caba0ca96dc7e8ebfb85234709">ReluDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;                              <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9bad6656de3c2096aec4f48e1f7bd0c5">Sigmoid</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a5eca9a1525b76a9c2cef4cf87097e208">SigmoidDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a631fef11cc093af2bd52ddf9b7b6da77">Tanh</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a3f53da5ddbec7cf4dc756e5cf0ebf63a">TanhDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;                              <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a0818708ca6b5011c1543a95c396cfaf2">SymmetricRelu</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#aad401b9e42b65667a770b6bd5ad9eec3">SymmetricReluDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;                                       <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a6445c66466d3108c199b4df8da782a85">SoftSign</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a5f5d059bf26033c548dfca99d8060cb7">SoftSignDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;                                  <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a5b0670559d8c12b6d93cf4a30444858a">Gauss</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a25e1a2972ce2c4ff488b0a8e2a0dd69e">GaussDerivative</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;                               <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;   <span class="comment">// Loss Functions</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment">   /** @name Loss Functions</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">    * Loss functions compute a scalar value given the \p output of the network</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="comment">    * for a given training input and the expected network prediction \p Y that</span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment">    * quantifies the quality of the prediction. For each function also a routing</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">    * that computes the gradients (suffixed by Gradients) must be provided for</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">    * the starting of the backpropagation algorithm.</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;   <span class="keyword">static</span> AReal <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ad4ebd5909722b89b1c12c46732398baa">MeanSquaredError</a>(<span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Y, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights);</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8ca5531242a723ba0d50dc4b05060e91">MeanSquaredErrorGradients</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;dY, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Y, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;                                         <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights);</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="comment">   /** Sigmoid transformation is implicitly applied, thus \p output should</span></div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="comment">    *  hold the linear activations of the last layer in the net. */</span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;   <span class="keyword">static</span> AReal <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a62b6e1ebc4dfa9d13b992ee97f5815f4">CrossEntropy</a>(<span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Y, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights);</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a33b86aaf4fd7c95d98a7492a585bd08c">CrossEntropyGradients</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;dY, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Y, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;                                     <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights);</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="comment">   /** Softmax transformation is implicitly applied, thus \p output should</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="comment">    *  hold the linear activations of the last layer in the net. */</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;   <span class="keyword">static</span> AReal <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a4ec95263f2dee98083a8e177ac24be8b">SoftmaxCrossEntropy</a>(<span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Y, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;                                    <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights);</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ab5d12cb4ed6a71383ec40e7986bae311">SoftmaxCrossEntropyGradients</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;dY, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Y,</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights);<span class="comment"></span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;   <span class="comment">// Output Functions</span></div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="comment">   /** @name Output Functions</span></div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment">    * Output functions transform the activations \p output of the</span></div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="comment">    * output layer in the network to a valid prediction \p YHat for</span></div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment">    * the desired usage of the network, e.g.  the identity function</span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="comment">    * for regression or the sigmoid transformation for two-class</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="comment">    * classification.</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment"></span>   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9bad6656de3c2096aec4f48e1f7bd0c5">Sigmoid</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;YHat,</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;                       <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; );</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a665788087e54383ef5465d99123ad0e3">Softmax</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;YHat,</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                       <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; );<span class="comment"></span></div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;   <span class="comment">// Regularization</span></div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment">   /** @name Regularization</span></div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment">    * For each regularization type two functions are required, one named</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment">    * &lt;tt&gt;&lt;Type&gt;Regularization&lt;/tt&gt; that evaluates the corresponding</span></div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment">    * regularization functional for a given weight matrix and the</span></div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment">    * &lt;tt&gt;Add&lt;Type&gt;RegularizationGradients&lt;/tt&gt;, that adds the regularization</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment">    * component in the gradients to the provided matrix.</span></div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;   <span class="keyword">static</span> AReal <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ab6186c135e05f7ce439ac41ecf0e4570">L1Regularization</a>(<span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; W);</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a319a02de29ad0b6ca005937018f8f636">AddL1RegularizationGradients</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; W,</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;                                            AReal <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>);</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;   <span class="keyword">static</span> AReal <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a49075564f1365e6bd6e53208f9887649">L2Regularization</a>(<span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; W);</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ac6976880d3f576a7be0d6ca94af34eae">AddL2RegularizationGradients</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; W,</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;                                            AReal <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>);<span class="comment"></span></div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;   <span class="comment">// Initialization</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="comment">   /** @name Initialization</span></div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;<span class="comment">    * For each initialization method, one function in the low-level interface</span></div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment">    * is provided. The naming scheme is &lt;p&gt;Initialize&lt;Type&gt;&lt;/p&gt; for a given</span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment">    * initialization method Type.</span></div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#acf0444fde3155665d70fa6cfe7ed65ab">InitializeGauss</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#afd53828de202c7f31de66162a8d26a4f">InitializeUniform</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a0cfb8f7321a4448f28296e5885a069fa">InitializeIdentity</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a63182f0a60d90e8f0d3983e44440268b">InitializeZero</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#aded0f27787ff806cffd0ee65d2699f5b">InitializeGlorotUniform</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a14fe078f8033df7601c77fb841634fb9">InitializeGlorotNormal</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;   <span class="comment">// return static instance of random generator used for initialization</span></div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;   <span class="comment">// if generator does not exist it is created the first time with a random seed (e.g. seed = 0)</span></div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;   <span class="keyword">static</span> <a class="code" href="classTRandom.html">TRandom</a> &amp; <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#af49a2102d6e1318fdcbd088e3c789101">GetRandomGenerator</a>();</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;   <span class="comment">// set random seed for the static geenrator</span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;   <span class="comment">// if the static geneerator does not exists it is created</span></div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a5dfa3bd30b418116a5ebc043c84a4b49">SetRandomSeed</a>(<span class="keywordtype">size_t</span> seed);</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;   <span class="comment">// Dropout</span></div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;<span class="comment">   /** @name Dropout</span></div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;<span class="comment">   /** Apply dropout with activation probability \p p to the given</span></div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment">    *  matrix \p A and scale the result by reciprocal of \p p. */</span></div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a47c5328ac49097dc5d34dd70f6417b8d">Dropout</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, AReal dropoutProbability);</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;   <span class="comment">//  Convolutional Layer Propagation</span></div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;<span class="comment">   /** @name Forward Propagation in Convolutional Layer</span></div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment">   /** Transform the matrix \p B in local view format, suitable for</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment">    *  convolution, and store it in matrix \p A. */</span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a954cf73be854ff7b3c7b47f1b04a209b">Im2col</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;                      <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>,</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;                      <span class="keywordtype">size_t</span> imgHeight,</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;                      <span class="keywordtype">size_t</span> imgWidth,</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;                      <span class="keywordtype">size_t</span> fltHeight,</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;                      <span class="keywordtype">size_t</span> fltWidth,</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                      <span class="keywordtype">size_t</span> strideRows,</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                      <span class="keywordtype">size_t</span> strideCols,</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                      <span class="keywordtype">size_t</span> zeroPaddingHeight,</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                      <span class="keywordtype">size_t</span> zeroPaddingWidth);</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;</div><div class="line"><a name="l00325"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a496314e8f2d554660ea2fab7e31f9b1b">  325</a></span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a496314e8f2d554660ea2fab7e31f9b1b">Im2colIndices</a>(std::vector&lt;int&gt; &amp;, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;, <span class="keywordtype">size_t</span>, <span class="keywordtype">size_t</span>, <span class="keywordtype">size_t</span>, <span class="keywordtype">size_t</span> ,</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                      <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> ,<span class="keywordtype">size_t</span> ) {</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;      <a class="code" href="TError_8h.html#af6227adce2ac658a2418f618f4ec4202">Fatal</a>(<span class="stringliteral">&quot;Im2ColIndices&quot;</span>,<span class="stringliteral">&quot;This function is not implemented for ref architectures&quot;</span>);</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;   }</div><div class="line"><a name="l00329"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a33e90ed3ab0022aa5a09b72b397d47ae">  329</a></span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a33e90ed3ab0022aa5a09b72b397d47ae">Im2colFast</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;, <span class="keyword">const</span> std::vector&lt;int&gt; &amp; ) {</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;       <a class="code" href="TError_8h.html#af6227adce2ac658a2418f618f4ec4202">Fatal</a>(<span class="stringliteral">&quot;Im2ColFast&quot;</span>,<span class="stringliteral">&quot;This function is not implemented for ref architectures&quot;</span>);</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;   }</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="comment">   /** Rotates the matrix \p B, which is representing a weights,</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;<span class="comment">    *  and stores them in the matrix \p A. */</span></div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8e5f818de22e9867c6106b982e1ba139">RotateWeights</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, <span class="keywordtype">size_t</span> filterDepth, <span class="keywordtype">size_t</span> filterHeight,</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;                             <span class="keywordtype">size_t</span> filterWidth, <span class="keywordtype">size_t</span> numFilters);</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;<span class="comment">   /** Add the biases in the Convolutional Layer.  */</span></div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ab9a59df775fa3a0dc6b96b0028df3fae">AddConvBiases</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;biases);<span class="comment"></span></div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;<span class="comment">   /** Dummy placeholder - preparation is currently only required for the CUDA architecture. */</span></div><div class="line"><a name="l00343"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#ab8091f38020dc1d63fc2c272cd2126b8">  343</a></span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ab8091f38020dc1d63fc2c272cd2126b8">PrepareInternals</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;) {}</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;<span class="comment">   /** Forward propagation in the Convolutional layer */</span></div><div class="line"><a name="l00346"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a0560782d97c0e7c83699dee70f4ea528">  346</a></span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a0560782d97c0e7c83699dee70f4ea528">ConvLayerForward</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp; <span class="comment">/*output*/</span>,</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                                std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp; <span class="comment">/*derivatives*/</span>,</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;                                <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp; <span class="comment">/*input*/</span>,</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                                <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <span class="comment">/*weights*/</span>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <span class="comment">/*biases*/</span>,</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                                <span class="keyword">const</span> <a class="code" href="structTMVA_1_1DNN_1_1CNN_1_1TConvParams.html">DNN::CNN::TConvParams</a> &amp; <span class="comment">/*params*/</span>, <a class="code" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <span class="comment">/*activFunc*/</span>,</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;                                std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp; <span class="comment">/*inputPrime*/</span>) {</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;      <a class="code" href="TError_8h.html#af6227adce2ac658a2418f618f4ec4202">Fatal</a>(<span class="stringliteral">&quot;ConvLayerForward&quot;</span>,<span class="stringliteral">&quot;This function is not implemented for ref architectures&quot;</span>);</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;   }</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;<span class="comment">   /** @name Backward Propagation in Convolutional Layer</span></div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;<span class="comment">   /** Perform the complete backward propagation step in a Convolutional Layer.</span></div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;<span class="comment">    *  If the provided \p activationGradientsBackward matrix is not empty, compute the</span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;<span class="comment">    *  gradients of the objective function with respect to the activations</span></div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;<span class="comment">    *  of the previous layer (backward direction).</span></div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;<span class="comment">    *  Also compute the weight and the bias gradients. Modifies the values</span></div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;<span class="comment">    *  in \p df and thus produces only a valid result, if it is applied the</span></div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="comment">    *  first time after the corresponding forward propagation has been per-</span></div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;<span class="comment">    *  formed. */</span></div><div class="line"><a name="l00368"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a8ad0f7fe63ec15ac93028a64420b29b9">  368</a></span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a8ad0f7fe63ec15ac93028a64420b29b9">ConvLayerBackward</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;,</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;                                 <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;,</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;                                 std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;,</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;                                 <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;,</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;,</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;                                 <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span>,</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;                                 <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span> , <span class="keywordtype">size_t</span>) {</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;      <a class="code" href="TError_8h.html#af6227adce2ac658a2418f618f4ec4202">Fatal</a>(<span class="stringliteral">&quot;ConvLayerBackward&quot;</span>,<span class="stringliteral">&quot;This function is not implemented for ref architectures&quot;</span>);</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;   }</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;<span class="preprocessor">#ifdef HAVE_CNN_REFERENCE</span></div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;<span class="comment">   /** Utility function for calculating the activation gradients of the layer</span></div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;<span class="comment">    *  before the convolutional layer. */</span></div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> CalculateConvActivationGradients(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;activationGradientsBackward,</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;                                                <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;df, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weights,</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;                                                <span class="keywordtype">size_t</span> batchSize, <span class="keywordtype">size_t</span> inputHeight, <span class="keywordtype">size_t</span> inputWidth, <span class="keywordtype">size_t</span> depth,</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;                                                <span class="keywordtype">size_t</span> height, <span class="keywordtype">size_t</span> <a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, <span class="keywordtype">size_t</span> filterDepth, <span class="keywordtype">size_t</span> filterHeight,</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;                                                <span class="keywordtype">size_t</span> filterWidth);</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;<span class="comment">   /** Utility function for calculating the weight gradients of the convolutional</span></div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;<span class="comment">    *  layer. */</span></div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> CalculateConvWeightGradients(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;weightGradients, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;df,</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;                                            <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;activationBackward, <span class="keywordtype">size_t</span> batchSize,</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;                                            <span class="keywordtype">size_t</span> inputHeight, <span class="keywordtype">size_t</span> inputWidth, <span class="keywordtype">size_t</span> depth, <span class="keywordtype">size_t</span> height,</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;                                            <span class="keywordtype">size_t</span> <a class="code" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, <span class="keywordtype">size_t</span> filterDepth, <span class="keywordtype">size_t</span> filterHeight, <span class="keywordtype">size_t</span> filterWidth,</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;                                            <span class="keywordtype">size_t</span> nLocalViews);</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;<span class="comment">   /** Utility function for calculating the bias gradients of the convolutional</span></div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;<span class="comment">    *  layer. */</span></div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> CalculateConvBiasGradients(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;biasGradients, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;df,</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;                                          <span class="keywordtype">size_t</span> batchSize, <span class="keywordtype">size_t</span> depth, <span class="keywordtype">size_t</span> nLocalViews);<span class="comment"></span></div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;<span class="preprocessor">#endif</span></div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;   <span class="comment">//  Max Pooling Layer Propagation</span></div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;   <span class="comment">//____________________________________________________________________________</span><span class="comment"></span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;<span class="comment">   /** @name Forward Propagation in Max Pooling Layer</span></div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;<span class="comment">  /** Downsample the matrix \p C to the matrix \p A, using max</span></div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;<span class="comment">    *  operation, such that the winning indices are stored in matrix</span></div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;<span class="comment">    *  \p B. */</span></div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a3a8a5a344999491c7c24623f1a268915">Downsample</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#ae4a80ce521bd09f94f06eec25c975c0e">C</a>, <span class="keywordtype">size_t</span> imgHeight,</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;                          <span class="keywordtype">size_t</span> imgWidth, <span class="keywordtype">size_t</span> fltHeight, <span class="keywordtype">size_t</span> fltWidth, <span class="keywordtype">size_t</span> strideRows, <span class="keywordtype">size_t</span> strideCols);</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;<span class="comment">   /** @name Backward Propagation in Max Pooling Layer</span></div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="comment">   /** Perform the complete backward propagation step in a Max Pooling Layer. Based on the</span></div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment">    *  winning idices stored in the index matrix, it just forwards the actiovation</span></div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment">    *  gradients to the previous layer. */</span></div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a2361769bfe3aaeabdf3990fa0c7a9e24">MaxPoolLayerBackward</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;activationGradientsBackward,</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                                    <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;activationGradients,</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;                                    <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;indexMatrix,</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;                                    <span class="keywordtype">size_t</span> imgHeight,</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;                                    <span class="keywordtype">size_t</span> imgWidth,</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;                                    <span class="keywordtype">size_t</span> fltHeight,</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;                                    <span class="keywordtype">size_t</span> fltWidth,</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;                                    <span class="keywordtype">size_t</span> strideRows,</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;                                    <span class="keywordtype">size_t</span> strideCol,</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;                                    <span class="keywordtype">size_t</span> nLocalViews);<span class="comment"></span></div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;<span class="comment"></span>   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;   <span class="comment">//  Reshape Layer Propagation</span></div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;   <span class="comment">//____________________________________________________________________________</span><span class="comment"></span></div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="comment">   /** @name Forward and Backward Propagation in Reshape Layer</span></div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;<span class="comment">    */</span><span class="comment"></span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;<span class="comment">   ///@{</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="comment"></span><span class="comment"></span></div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;<span class="comment">   /** Transform the matrix \p B to a matrix with different dimensions \p A */</span></div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ae47a559a34fdbb79a25293a4d62c3606">Reshape</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="comment">   /** Flattens the tensor \p B, such that each matrix, is stretched in one row, resulting with a matrix \p A. */</span></div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#abd716e8b5841623e4baef78e37f2401f">Flatten</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, <span class="keywordtype">size_t</span> size, <span class="keywordtype">size_t</span> nRows,</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;                       <span class="keywordtype">size_t</span> nCols);</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;<span class="comment">   /** Transforms each row of \p B to a matrix and stores it in the tensor \p B. */</span></div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#aca102f90d2c9c8e0490135321eff8cf7">Deflatten</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;Scalar_t&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, <span class="keywordtype">size_t</span> index, <span class="keywordtype">size_t</span> nRows,</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;                         <span class="keywordtype">size_t</span> nCols);<span class="comment"></span></div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;<span class="comment">   /** Rearrage data accoring to time fill B x T x D out with T x B x D matrix in*/</span></div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a4e0a44f00b7e7251306632c7575f3f48">Rearrange</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;out, <span class="keyword">const</span> std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;in);</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;<span class="comment">   ///@}</span></div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;   <span class="comment">// Additional Arithmetic Functions</span></div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;<span class="comment">   /** Sum columns of (m x n) matrixx \p A and write the results into the first</span></div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;<span class="comment">    * m elements in \p A.</span></div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ad8bc6073b03280e6a175e107d6661f02">SumColumns</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;<span class="comment">   /** In-place Hadamard (element-wise) product of matrices \p A and \p B</span></div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;<span class="comment">    *  with the result being written into \p A.</span></div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a973fda80e880147e12bd6dfe0723fb9e">Hadamard</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>);</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;<span class="comment">   /** Add the constant \p beta to all the elements of matrix \p A and write the</span></div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;<span class="comment">    * result into \p A.</span></div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a5514a2203330815754854230017e43d5">ConstAdd</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, AReal <a class="code" href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">beta</a>);</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;<span class="comment">   /** Multiply the constant \p beta to all the elements of matrix \p A and write the</span></div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;<span class="comment">    * result into \p A.</span></div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#adc140692283eff0a1f9520ed13450ee7">ConstMult</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, AReal <a class="code" href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">beta</a>);</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;<span class="comment">   /** Reciprocal each element of the matrix \p A and write the result into</span></div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;<span class="comment">    * \p A</span></div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a6a56044e4fff320c79d663b64b6dd852">ReciprocalElementWise</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;<span class="comment">   /** Square each element of the matrix \p A and write the result into</span></div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;<span class="comment">    * \p A</span></div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a78432c7bd6e437b1c14bda2e29d24fad">SquareElementWise</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;<span class="comment">   /** Square root each element of the matrix \p A and write the result into</span></div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;<span class="comment">    * \p A</span></div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;<span class="comment">    */</span></div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ad677da7bc7d5857c519814343c796290">SqrtElementWise</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;   <span class="comment">// optimizer update functions</span></div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;<span class="comment">   /// Update functions for ADAM optimizer</span></div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;<span class="comment"></span>   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a016754a9d74139e6c4185d451de18325">AdamUpdate</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; M, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; V, AReal alpha, AReal eps);</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a15b9fb3711bc5c30a632c7185a8c7415">AdamUpdateFirstMom</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, AReal <a class="code" href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">beta</a>);</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a02c6587ff963237d80a6645778549f3c">AdamUpdateSecondMom</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>, AReal <a class="code" href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">beta</a>);</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;   <span class="comment">//</span></div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;   <span class="comment">// AutoEncoder Propagation</span></div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;   <span class="comment">//____________________________________________________________________________</span></div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;   <span class="comment">// Add Biases to the output</span></div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#af172618e6454a2fa901f9cdea2677dbf">AddBiases</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>,</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;                         <span class="keyword">const</span> <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;biases);</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;   <span class="comment">// Updating parameters after every backward pass. Weights and biases are</span></div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;   <span class="comment">// updated.</span></div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span></div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;   <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9b0933f18c8d2d8076e46e91a80b5c7e">UpdateParams</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="legend1_8C.html#a13c6713ae496caa8195647f76887f926">x</a>, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;tildeX, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="legend1_8C.html#a1380cd153a0fc78015dd604dbcb6c841">y</a>,</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;                <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="TRolke_8cxx.html#a89a026883dd7df087bf16c8c176caeed">z</a>, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fVBiases,</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;                <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fHBiases, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fWeights,</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;                <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;VBiasError, <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;HBiasError,</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;                AReal learningRate, <span class="keywordtype">size_t</span> fBatchSize);</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;   <span class="comment">// Softmax functions redifined</span></div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a26b7904d418de785d77cf639ea0bc6d5">SoftmaxAE</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>);</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;   <span class="comment">// Corrupt the input values randomly on corruption Level.</span></div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;   <span class="comment">//Basically inputs are masked currently.</span></div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#acc0661daf8434f16bb7a618b7a97b592">CorruptInput</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; input,</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;                            <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; corruptedInput,</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;                            AReal corruptionLevel);</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;   <span class="comment">//Encodes the input Values in the compressed form.</span></div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a3c95a0e60090f94b7b244fe91a850db7">EncodeInput</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;input,</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;                           <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;compressedInput,</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;                           <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;Weights);</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;   <span class="comment">// reconstructs the input. The reconstructed Input has same dimensions as that</span></div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;   <span class="comment">// of the input.</span></div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a426dc25bfe9ec17405c753a04fe9f689">ReconstructInput</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; compressedInput,</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;                                <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp; reconstructedInput,</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;                                <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fWeights);</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#adb6351013defbc8b3cbda449bae85132">ForwardLogReg</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;input,</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;                             <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;p,</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;                             <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fWeights);</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;   <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#ab1ef32ebc9ee65f3cd1fb428fc2c5ca7">UpdateParamsLogReg</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;input,</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>,</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;difference,</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;p,</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fWeights,</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;                                  <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;fBiases,</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;                                  AReal learningRate,</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;                                  <span class="keywordtype">size_t</span> fBatchSize);</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;};</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;<span class="comment">// implement the templated member functions</span></div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> AReal&gt;</div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> AMatrix_t&gt;</div><div class="line"><a name="l00569"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a9c3a6efb1d7f0f51ff5126d67ff8f333">  569</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9c3a6efb1d7f0f51ff5126d67ff8f333">TReference&lt;AReal&gt;::CopyDiffArch</a>(<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> AMatrix_t &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>)</div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;{</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;   <a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a> tmp = <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>;</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;   <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a> = tmp;</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;}</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> AReal&gt;</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> AMatrix_t&gt;</div><div class="line"><a name="l00577"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1TReference.html#a8a100c7a0d513ed4354f48dee02fcbfd">  577</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1TReference.html#a9c3a6efb1d7f0f51ff5126d67ff8f333">TReference&lt;AReal&gt;::CopyDiffArch</a>(std::vector&lt;<a class="code" href="classTMatrixT.html">TMatrixT&lt;AReal&gt;</a>&gt; &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>, <span class="keyword">const</span> std::vector&lt;AMatrix_t&gt; &amp;<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>)</div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;{</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>.size(); ++i) {</div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;      CopyDiffArch(<a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">A</a>[i], <a class="code" href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">B</a>[i]);</div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;   }</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;}</div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;</div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;</div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;} <span class="comment">// namespace DNN</span></div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;} <span class="comment">// namespace TMVA</span></div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="namespaceROOT_1_1Math_1_1Cephes_html_a13a02463decc00f44325f3fc3fa326fd"><div class="ttname"><a href="namespaceROOT_1_1Math_1_1Cephes.html#a13a02463decc00f44325f3fc3fa326fd">ROOT::Math::Cephes::B</a></div><div class="ttdeci">static double B[]</div><div class="ttdef"><b>Definition:</b> <a href="SpecFuncCephes_8cxx_source.html#l00178">SpecFuncCephes.cxx:178</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a5dfa3bd30b418116a5ebc043c84a4b49"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a5dfa3bd30b418116a5ebc043c84a4b49">TMVA::DNN::TReference::SetRandomSeed</a></div><div class="ttdeci">static void SetRandomSeed(size_t seed)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00029">Initialization.cxx:29</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_aded0f27787ff806cffd0ee65d2699f5b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#aded0f27787ff806cffd0ee65d2699f5b">TMVA::DNN::TReference::InitializeGlorotUniform</a></div><div class="ttdeci">static void InitializeGlorotUniform(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdoc">Sample from a uniform distribution in range [ -lim,+lim] where lim = sqrt(6/N_in+N_out). </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00110">Initialization.cxx:110</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a3f53da5ddbec7cf4dc756e5cf0ebf63a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a3f53da5ddbec7cf4dc756e5cf0ebf63a">TMVA::DNN::TReference::TanhDerivative</a></div><div class="ttdeci">static void TanhDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00125">ActivationFunctions.cxx:125</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a4ba4f2378958700c496e6f64a38b59d7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a4ba4f2378958700c496e6f64a38b59d7">TMVA::DNN::TReference::IdentityDerivative</a></div><div class="ttdeci">static void IdentityDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00027">ActivationFunctions.cxx:27</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ab9a59df775fa3a0dc6b96b0028df3fae"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ab9a59df775fa3a0dc6b96b0028df3fae">TMVA::DNN::TReference::AddConvBiases</a></div><div class="ttdeci">static void AddConvBiases(TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;biases)</div><div class="ttdoc">Add the biases in the Convolutional Layer. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00159">Propagation.cxx:159</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a631fef11cc093af2bd52ddf9b7b6da77"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a631fef11cc093af2bd52ddf9b7b6da77">TMVA::DNN::TReference::Tanh</a></div><div class="ttdeci">static void Tanh(TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00109">ActivationFunctions.cxx:109</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_adb6351013defbc8b3cbda449bae85132"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#adb6351013defbc8b3cbda449bae85132">TMVA::DNN::TReference::ForwardLogReg</a></div><div class="ttdeci">static void ForwardLogReg(TMatrixT&lt; AReal &gt; &amp;input, TMatrixT&lt; AReal &gt; &amp;p, TMatrixT&lt; AReal &gt; &amp;fWeights)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00171">DenoisePropagation.cxx:171</a></div></div>
<div class="ttc" id="TError_8h_html_af6227adce2ac658a2418f618f4ec4202"><div class="ttname"><a href="TError_8h.html#af6227adce2ac658a2418f618f4ec4202">Fatal</a></div><div class="ttdeci">void Fatal(const char *location, const char *msgfmt,...)</div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_afd0c99b8895d2de2fba7381b2e3b6871"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#afd0c99b8895d2de2fba7381b2e3b6871">TMVA::DNN::TReference::RecurrentLayerBackward</a></div><div class="ttdeci">static Matrix_t &amp; RecurrentLayerBackward(TMatrixT&lt; Scalar_t &gt; &amp;state_gradients_backward, TMatrixT&lt; Scalar_t &gt; &amp;input_weight_gradients, TMatrixT&lt; Scalar_t &gt; &amp;state_weight_gradients, TMatrixT&lt; Scalar_t &gt; &amp;bias_gradients, TMatrixT&lt; Scalar_t &gt; &amp;df, const TMatrixT&lt; Scalar_t &gt; &amp;state, const TMatrixT&lt; Scalar_t &gt; &amp;weights_input, const TMatrixT&lt; Scalar_t &gt; &amp;weights_state, const TMatrixT&lt; Scalar_t &gt; &amp;input, TMatrixT&lt; Scalar_t &gt; &amp;input_gradient)</div><div class="ttdoc">Backpropagation step for a Recurrent Neural Network. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2RecurrentPropagation_8cxx_source.html#l00026">RecurrentPropagation.cxx:26</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a2361769bfe3aaeabdf3990fa0c7a9e24"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a2361769bfe3aaeabdf3990fa0c7a9e24">TMVA::DNN::TReference::MaxPoolLayerBackward</a></div><div class="ttdeci">static void MaxPoolLayerBackward(TMatrixT&lt; AReal &gt; &amp;activationGradientsBackward, const TMatrixT&lt; AReal &gt; &amp;activationGradients, const TMatrixT&lt; AReal &gt; &amp;indexMatrix, size_t imgHeight, size_t imgWidth, size_t fltHeight, size_t fltWidth, size_t strideRows, size_t strideCol, size_t nLocalViews)</div><div class="ttdoc">Perform the complete backward propagation step in a Max Pooling Layer. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00367">Propagation.cxx:367</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a496314e8f2d554660ea2fab7e31f9b1b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a496314e8f2d554660ea2fab7e31f9b1b">TMVA::DNN::TReference::Im2colIndices</a></div><div class="ttdeci">static void Im2colIndices(std::vector&lt; int &gt; &amp;, const TMatrixT&lt; AReal &gt; &amp;, size_t, size_t, size_t, size_t, size_t, size_t, size_t, size_t, size_t)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00325">Reference.h:325</a></div></div>
<div class="ttc" id="structTMVA_1_1DNN_1_1CNN_1_1TConvParams_html"><div class="ttname"><a href="structTMVA_1_1DNN_1_1CNN_1_1TConvParams.html">TMVA::DNN::CNN::TConvParams</a></div><div class="ttdef"><b>Definition:</b> <a href="ConvLayer_8h_source.html#l00155">ConvLayer.h:155</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_adc140692283eff0a1f9520ed13450ee7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#adc140692283eff0a1f9520ed13450ee7">TMVA::DNN::TReference::ConstMult</a></div><div class="ttdeci">static void ConstMult(TMatrixT&lt; AReal &gt; &amp;A, AReal beta)</div><div class="ttdoc">Multiply the constant beta to all the elements of matrix A and write the result into A...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00059">Arithmetic.cxx:59</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a954cf73be854ff7b3c7b47f1b04a209b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a954cf73be854ff7b3c7b47f1b04a209b">TMVA::DNN::TReference::Im2col</a></div><div class="ttdeci">static void Im2col(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;B, size_t imgHeight, size_t imgWidth, size_t fltHeight, size_t fltWidth, size_t strideRows, size_t strideCols, size_t zeroPaddingHeight, size_t zeroPaddingWidth)</div><div class="ttdoc">Transform the matrix B in local view format, suitable for convolution, and store it in matrix A...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00109">Propagation.cxx:109</a></div></div>
<div class="ttc" id="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_html"><div class="ttname"><a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h.html">Functions.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a4ec95263f2dee98083a8e177ac24be8b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a4ec95263f2dee98083a8e177ac24be8b">TMVA::DNN::TReference::SoftmaxCrossEntropy</a></div><div class="ttdeci">static AReal SoftmaxCrossEntropy(const TMatrixT&lt; AReal &gt; &amp;Y, const TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;weights)</div><div class="ttdoc">Softmax transformation is implicitly applied, thus output should hold the linear activations of the l...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2LossFunctions_8cxx_source.html#l00107">LossFunctions.cxx:107</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a9bad6656de3c2096aec4f48e1f7bd0c5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a9bad6656de3c2096aec4f48e1f7bd0c5">TMVA::DNN::TReference::Sigmoid</a></div><div class="ttdeci">static void Sigmoid(TMatrixT&lt; AReal &gt; &amp;B)</div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a62b6e1ebc4dfa9d13b992ee97f5815f4"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a62b6e1ebc4dfa9d13b992ee97f5815f4">TMVA::DNN::TReference::CrossEntropy</a></div><div class="ttdeci">static AReal CrossEntropy(const TMatrixT&lt; AReal &gt; &amp;Y, const TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;weights)</div><div class="ttdoc">Sigmoid transformation is implicitly applied, thus output should hold the linear activations of the l...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2LossFunctions_8cxx_source.html#l00064">LossFunctions.cxx:64</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a5eca9a1525b76a9c2cef4cf87097e208"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a5eca9a1525b76a9c2cef4cf87097e208">TMVA::DNN::TReference::SigmoidDerivative</a></div><div class="ttdeci">static void SigmoidDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00092">ActivationFunctions.cxx:92</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ad677da7bc7d5857c519814343c796290"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ad677da7bc7d5857c519814343c796290">TMVA::DNN::TReference::SqrtElementWise</a></div><div class="ttdeci">static void SqrtElementWise(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdoc">Square root each element of the matrix A and write the result into A. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00092">Arithmetic.cxx:92</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a6445c66466d3108c199b4df8da782a85"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a6445c66466d3108c199b4df8da782a85">TMVA::DNN::TReference::SoftSign</a></div><div class="ttdeci">static void SoftSign(TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00173">ActivationFunctions.cxx:173</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ab0b8d758aba8d5bd85ac7bf94a1366e5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ab0b8d758aba8d5bd85ac7bf94a1366e5">TMVA::DNN::TReference::Identity</a></div><div class="ttdeci">static void Identity(TMatrixT&lt; AReal &gt; &amp;B)</div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_aad401b9e42b65667a770b6bd5ad9eec3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#aad401b9e42b65667a770b6bd5ad9eec3">TMVA::DNN::TReference::SymmetricReluDerivative</a></div><div class="ttdeci">static void SymmetricReluDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00157">ActivationFunctions.cxx:157</a></div></div>
<div class="ttc" id="namespaceROOT_1_1Math_1_1Cephes_html_a96aa5ae65c196960b1b7cf2ab4d487f3"><div class="ttname"><a href="namespaceROOT_1_1Math_1_1Cephes.html#a96aa5ae65c196960b1b7cf2ab4d487f3">ROOT::Math::Cephes::A</a></div><div class="ttdeci">static double A[]</div><div class="ttdef"><b>Definition:</b> <a href="SpecFuncCephes_8cxx_source.html#l00170">SpecFuncCephes.cxx:170</a></div></div>
<div class="ttc" id="group__SpecFunc_html_ga2e8e07d8b34ecc9d76106eba4d6d9f8d"><div class="ttname"><a href="group__SpecFunc.html#ga2e8e07d8b34ecc9d76106eba4d6d9f8d">ROOT::Math::beta</a></div><div class="ttdeci">double beta(double x, double y)</div><div class="ttdoc">Calculates the beta function. </div><div class="ttdef"><b>Definition:</b> <a href="SpecFuncMathCore_8cxx_source.html#l00111">SpecFuncMathCore.cxx:111</a></div></div>
<div class="ttc" id="classTMatrixT_html"><div class="ttname"><a href="classTMatrixT.html">TMatrixT&lt; AReal &gt;</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a33e90ed3ab0022aa5a09b72b397d47ae"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a33e90ed3ab0022aa5a09b72b397d47ae">TMVA::DNN::TReference::Im2colFast</a></div><div class="ttdeci">static void Im2colFast(TMatrixT&lt; AReal &gt; &amp;, const TMatrixT&lt; AReal &gt; &amp;, const std::vector&lt; int &gt; &amp;)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00329">Reference.h:329</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ac6976880d3f576a7be0d6ca94af34eae"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ac6976880d3f576a7be0d6ca94af34eae">TMVA::DNN::TReference::AddL2RegularizationGradients</a></div><div class="ttdeci">static void AddL2RegularizationGradients(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;W, AReal weightDecay)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Regularization_8cxx_source.html#l00082">Regularization.cxx:82</a></div></div>
<div class="ttc" id="legend1_8C_html_a13c6713ae496caa8195647f76887f926"><div class="ttname"><a href="legend1_8C.html#a13c6713ae496caa8195647f76887f926">x</a></div><div class="ttdeci">Double_t x[n]</div><div class="ttdef"><b>Definition:</b> <a href="legend1_8C_source.html#l00017">legend1.C:17</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a492993d5217855869e20508313007305"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">TMVA::DNN::weightDecay</a></div><div class="ttdeci">double weightDecay(double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization)</div><div class="ttdoc">compute the weight decay for regularization (L1 or L2) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00496">NeuralNet.icc:496</a></div></div>
<div class="ttc" id="classTRandom_html"><div class="ttname"><a href="classTRandom.html">TRandom</a></div><div class="ttdoc"> This is the base class for the ROOT Random number generators. </div><div class="ttdef"><b>Definition:</b> <a href="TRandom_8h_source.html#l00027">TRandom.h:27</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a26b7904d418de785d77cf639ea0bc6d5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a26b7904d418de785d77cf639ea0bc6d5">TMVA::DNN::TReference::SoftmaxAE</a></div><div class="ttdeci">static void SoftmaxAE(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00085">DenoisePropagation.cxx:85</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_abd716e8b5841623e4baef78e37f2401f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#abd716e8b5841623e4baef78e37f2401f">TMVA::DNN::TReference::Flatten</a></div><div class="ttdeci">static void Flatten(TMatrixT&lt; AReal &gt; &amp;A, const std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;B, size_t size, size_t nRows, size_t nCols)</div><div class="ttdoc">Flattens the tensor B, such that each matrix, is stretched in one row, resulting with a matrix A...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00408">Propagation.cxx:408</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ac7137f9d1369daa39e3e8cde2272449b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ac7137f9d1369daa39e3e8cde2272449b">TMVA::DNN::TReference::Copy</a></div><div class="ttdeci">static void Copy(TMatrixT&lt; Scalar_t &gt; &amp;A, const TMatrixT&lt; Scalar_t &gt; &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00086">Propagation.cxx:86</a></div></div>
<div class="ttc" id="DNN_2Architectures_2Reference_2DataLoader_8h_html"><div class="ttname"><a href="DNN_2Architectures_2Reference_2DataLoader_8h.html">DataLoader.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_af49a2102d6e1318fdcbd088e3c789101"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#af49a2102d6e1318fdcbd088e3c789101">TMVA::DNN::TReference::GetRandomGenerator</a></div><div class="ttdeci">static TRandom &amp; GetRandomGenerator()</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00035">Initialization.cxx:35</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ab5d12cb4ed6a71383ec40e7986bae311"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ab5d12cb4ed6a71383ec40e7986bae311">TMVA::DNN::TReference::SoftmaxCrossEntropyGradients</a></div><div class="ttdeci">static void SoftmaxCrossEntropyGradients(TMatrixT&lt; AReal &gt; &amp;dY, const TMatrixT&lt; AReal &gt; &amp;Y, const TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;weights)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2LossFunctions_8cxx_source.html#l00131">LossFunctions.cxx:131</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a426dc25bfe9ec17405c753a04fe9f689"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a426dc25bfe9ec17405c753a04fe9f689">TMVA::DNN::TReference::ReconstructInput</a></div><div class="ttdeci">static void ReconstructInput(TMatrixT&lt; AReal &gt; &amp;compressedInput, TMatrixT&lt; AReal &gt; &amp;reconstructedInput, TMatrixT&lt; AReal &gt; &amp;fWeights)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00152">DenoisePropagation.cxx:152</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a8ad0f7fe63ec15ac93028a64420b29b9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a8ad0f7fe63ec15ac93028a64420b29b9">TMVA::DNN::TReference::ConvLayerBackward</a></div><div class="ttdeci">static void ConvLayerBackward(std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, TMatrixT&lt; AReal &gt; &amp;, TMatrixT&lt; AReal &gt; &amp;, std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, const std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, const TMatrixT&lt; AReal &gt; &amp;, const std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, size_t, size_t, size_t, size_t, size_t, size_t, size_t, size_t, size_t, size_t)</div><div class="ttdoc">Perform the complete backward propagation step in a Convolutional Layer. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00368">Reference.h:368</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a8de41bb6bf802a42a8bf99d5b6dfe3a3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a8de41bb6bf802a42a8bf99d5b6dfe3a3">TMVA::DNN::TReference::Scalar_t</a></div><div class="ttdeci">AReal Scalar_t</div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00050">Reference.h:50</a></div></div>
<div class="ttc" id="ConvLayer_8h_html"><div class="ttname"><a href="ConvLayer_8h.html">ConvLayer.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ae47a559a34fdbb79a25293a4d62c3606"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ae47a559a34fdbb79a25293a4d62c3606">TMVA::DNN::TReference::Reshape</a></div><div class="ttdeci">static void Reshape(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdoc">Transform the matrix B to a matrix with different dimensions A. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00393">Propagation.cxx:393</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a8e5f818de22e9867c6106b982e1ba139"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a8e5f818de22e9867c6106b982e1ba139">TMVA::DNN::TReference::RotateWeights</a></div><div class="ttdeci">static void RotateWeights(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;B, size_t filterDepth, size_t filterHeight, size_t filterWidth, size_t numFilters)</div><div class="ttdoc">Rotates the matrix B, which is representing a weights, and stores them in the matrix A...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00144">Propagation.cxx:144</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ab6186c135e05f7ce439ac41ecf0e4570"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ab6186c135e05f7ce439ac41ecf0e4570">TMVA::DNN::TReference::L1Regularization</a></div><div class="ttdeci">static AReal L1Regularization(const TMatrixT&lt; AReal &gt; &amp;W)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Regularization_8cxx_source.html#l00026">Regularization.cxx:26</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_afd53828de202c7f31de66162a8d26a4f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#afd53828de202c7f31de66162a8d26a4f">TMVA::DNN::TReference::InitializeUniform</a></div><div class="ttdeci">static void InitializeUniform(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00062">Initialization.cxx:62</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a15b9fb3711bc5c30a632c7185a8c7415"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a15b9fb3711bc5c30a632c7185a8c7415">TMVA::DNN::TReference::AdamUpdateFirstMom</a></div><div class="ttdeci">static void AdamUpdateFirstMom(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;B, AReal beta)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00117">Arithmetic.cxx:117</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a319a02de29ad0b6ca005937018f8f636"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a319a02de29ad0b6ca005937018f8f636">TMVA::DNN::TReference::AddL1RegularizationGradients</a></div><div class="ttdeci">static void AddL1RegularizationGradients(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;W, AReal weightDecay)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Regularization_8cxx_source.html#l00044">Regularization.cxx:44</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a14fe078f8033df7601c77fb841634fb9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a14fe078f8033df7601c77fb841634fb9">TMVA::DNN::TReference::InitializeGlorotNormal</a></div><div class="ttdeci">static void InitializeGlorotNormal(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdoc">Truncated normal initialization (Glorot, called also Xavier normal) The values are sample with a norm...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00085">Initialization.cxx:85</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a6ec8151d92e8bafae94b7b0d5d36b86b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a6ec8151d92e8bafae94b7b0d5d36b86b">TMVA::DNN::TReference::Backward</a></div><div class="ttdeci">static void Backward(TMatrixT&lt; Scalar_t &gt; &amp;activationGradientsBackward, TMatrixT&lt; Scalar_t &gt; &amp;weightGradients, TMatrixT&lt; Scalar_t &gt; &amp;biasGradients, TMatrixT&lt; Scalar_t &gt; &amp;df, const TMatrixT&lt; Scalar_t &gt; &amp;activationGradients, const TMatrixT&lt; Scalar_t &gt; &amp;weights, const TMatrixT&lt; Scalar_t &gt; &amp;activationBackward)</div><div class="ttdoc">Perform the complete backward propagation step. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00040">Propagation.cxx:40</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a02c6587ff963237d80a6645778549f3c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a02c6587ff963237d80a6645778549f3c">TMVA::DNN::TReference::AdamUpdateSecondMom</a></div><div class="ttdeci">static void AdamUpdateSecondMom(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;B, AReal beta)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00129">Arithmetic.cxx:129</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a1efefcce6d75e95b7a202d9cc095aa6e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a1efefcce6d75e95b7a202d9cc095aa6e">TMVA::DNN::TReference::Relu</a></div><div class="ttdeci">static void Relu(TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00043">ActivationFunctions.cxx:43</a></div></div>
<div class="ttc" id="Architectures_2Reference_2TensorDataLoader_8h_html"><div class="ttname"><a href="Architectures_2Reference_2TensorDataLoader_8h.html">TensorDataLoader.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a0818708ca6b5011c1543a95c396cfaf2"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a0818708ca6b5011c1543a95c396cfaf2">TMVA::DNN::TReference::SymmetricRelu</a></div><div class="ttdeci">static void SymmetricRelu(TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00142">ActivationFunctions.cxx:142</a></div></div>
<div class="ttc" id="namespaceROOT_1_1Math_1_1Cephes_html_ae4a80ce521bd09f94f06eec25c975c0e"><div class="ttname"><a href="namespaceROOT_1_1Math_1_1Cephes.html#ae4a80ce521bd09f94f06eec25c975c0e">ROOT::Math::Cephes::C</a></div><div class="ttdeci">static double C[]</div><div class="ttdef"><b>Definition:</b> <a href="SpecFuncCephes_8cxx_source.html#l00187">SpecFuncCephes.cxx:187</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a016754a9d74139e6c4185d451de18325"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a016754a9d74139e6c4185d451de18325">TMVA::DNN::TReference::AdamUpdate</a></div><div class="ttdeci">static void AdamUpdate(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;M, const TMatrixT&lt; AReal &gt; &amp;V, AReal alpha, AReal eps)</div><div class="ttdoc">Update functions for ADAM optimizer. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00103">Arithmetic.cxx:103</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a63182f0a60d90e8f0d3983e44440268b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a63182f0a60d90e8f0d3983e44440268b">TMVA::DNN::TReference::InitializeZero</a></div><div class="ttdeci">static void InitializeZero(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00148">Initialization.cxx:148</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_aca102f90d2c9c8e0490135321eff8cf7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#aca102f90d2c9c8e0490135321eff8cf7">TMVA::DNN::TReference::Deflatten</a></div><div class="ttdeci">static void Deflatten(std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;A, const TMatrixT&lt; Scalar_t &gt; &amp;B, size_t index, size_t nRows, size_t nCols)</div><div class="ttdoc">Transforms each row of B to a matrix and stores it in the tensor B. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00422">Propagation.cxx:422</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_acc0661daf8434f16bb7a618b7a97b592"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#acc0661daf8434f16bb7a618b7a97b592">TMVA::DNN::TReference::CorruptInput</a></div><div class="ttdeci">static void CorruptInput(TMatrixT&lt; AReal &gt; &amp;input, TMatrixT&lt; AReal &gt; &amp;corruptedInput, AReal corruptionLevel)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00108">DenoisePropagation.cxx:108</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a973fda80e880147e12bd6dfe0723fb9e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a973fda80e880147e12bd6dfe0723fb9e">TMVA::DNN::TReference::Hadamard</a></div><div class="ttdeci">static void Hadamard(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdoc">In-place Hadamard (element-wise) product of matrices A and B with the result being written into A...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00037">Arithmetic.cxx:37</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a49075564f1365e6bd6e53208f9887649"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a49075564f1365e6bd6e53208f9887649">TMVA::DNN::TReference::L2Regularization</a></div><div class="ttdeci">static AReal L2Regularization(const TMatrixT&lt; AReal &gt; &amp;W)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Regularization_8cxx_source.html#l00064">Regularization.cxx:64</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ab8091f38020dc1d63fc2c272cd2126b8"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ab8091f38020dc1d63fc2c272cd2126b8">TMVA::DNN::TReference::PrepareInternals</a></div><div class="ttdeci">static void PrepareInternals(std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;)</div><div class="ttdoc">Dummy placeholder - preparation is currently only required for the CUDA architecture. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00343">Reference.h:343</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a5514a2203330815754854230017e43d5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a5514a2203330815754854230017e43d5">TMVA::DNN::TReference::ConstAdd</a></div><div class="ttdeci">static void ConstAdd(TMatrixT&lt; AReal &gt; &amp;A, AReal beta)</div><div class="ttdoc">Add the constant beta to all the elements of matrix A and write the result into A. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00048">Arithmetic.cxx:48</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_adb3e54caba0ca96dc7e8ebfb85234709"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#adb3e54caba0ca96dc7e8ebfb85234709">TMVA::DNN::TReference::ReluDerivative</a></div><div class="ttdeci">static void ReluDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00058">ActivationFunctions.cxx:58</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_af172618e6454a2fa901f9cdea2677dbf"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#af172618e6454a2fa901f9cdea2677dbf">TMVA::DNN::TReference::AddBiases</a></div><div class="ttdeci">static void AddBiases(TMatrixT&lt; AReal &gt; &amp;A, const TMatrixT&lt; AReal &gt; &amp;biases)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00030">DenoisePropagation.cxx:30</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ad8bc6073b03280e6a175e107d6661f02"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ad8bc6073b03280e6a175e107d6661f02">TMVA::DNN::TReference::SumColumns</a></div><div class="ttdeci">static void SumColumns(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdoc">Sum columns of (m x n) matrixx A and write the results into the first m elements in A...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00025">Arithmetic.cxx:25</a></div></div>
<div class="ttc" id="TDocParser_8cxx_html_a728a0b17511d9239de0b9bb40ad60600"><div class="ttname"><a href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a></div><div class="ttdeci">include TDocParser_001 C image html pict1_TDocParser_001 png width</div><div class="ttdef"><b>Definition:</b> <a href="TDocParser_8cxx_source.html#l00121">TDocParser.cxx:121</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a33b86aaf4fd7c95d98a7492a585bd08c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a33b86aaf4fd7c95d98a7492a585bd08c">TMVA::DNN::TReference::CrossEntropyGradients</a></div><div class="ttdeci">static void CrossEntropyGradients(TMatrixT&lt; AReal &gt; &amp;dY, const TMatrixT&lt; AReal &gt; &amp;Y, const TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;weights)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2LossFunctions_8cxx_source.html#l00085">LossFunctions.cxx:85</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ab1ef32ebc9ee65f3cd1fb428fc2c5ca7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ab1ef32ebc9ee65f3cd1fb428fc2c5ca7">TMVA::DNN::TReference::UpdateParamsLogReg</a></div><div class="ttdeci">static void UpdateParamsLogReg(TMatrixT&lt; AReal &gt; &amp;input, TMatrixT&lt; AReal &gt; &amp;output, TMatrixT&lt; AReal &gt; &amp;difference, TMatrixT&lt; AReal &gt; &amp;p, TMatrixT&lt; AReal &gt; &amp;fWeights, TMatrixT&lt; AReal &gt; &amp;fBiases, AReal learningRate, size_t fBatchSize)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00191">DenoisePropagation.cxx:191</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a25e1a2972ce2c4ff488b0a8e2a0dd69e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a25e1a2972ce2c4ff488b0a8e2a0dd69e">TMVA::DNN::TReference::GaussDerivative</a></div><div class="ttdeci">static void GaussDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00222">ActivationFunctions.cxx:222</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a665788087e54383ef5465d99123ad0e3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a665788087e54383ef5465d99123ad0e3">TMVA::DNN::TReference::Softmax</a></div><div class="ttdeci">static void Softmax(TMatrixT&lt; AReal &gt; &amp;YHat, const TMatrixT&lt; AReal &gt; &amp;)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2OutputFunctions_8cxx_source.html#l00037">OutputFunctions.cxx:37</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a8d19b34ca1e6edc8fbcf8df418a23d02"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a8d19b34ca1e6edc8fbcf8df418a23d02">TMVA::DNN::TReference::fgRandomGen</a></div><div class="ttdeci">static TRandom * fgRandomGen</div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00047">Reference.h:47</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a3a8a5a344999491c7c24623f1a268915"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a3a8a5a344999491c7c24623f1a268915">TMVA::DNN::TReference::Downsample</a></div><div class="ttdeci">static void Downsample(TMatrixT&lt; AReal &gt; &amp;A, TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;C, size_t imgHeight, size_t imgWidth, size_t fltHeight, size_t fltWidth, size_t strideRows, size_t strideCols)</div><div class="ttdoc">Downsample the matrix C to the matrix A, using max operation, such that the winning indices are store...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00334">Propagation.cxx:334</a></div></div>
<div class="ttc" id="legend1_8C_html_a1380cd153a0fc78015dd604dbcb6c841"><div class="ttname"><a href="legend1_8C.html#a1380cd153a0fc78015dd604dbcb6c841">y</a></div><div class="ttdeci">Double_t y[n]</div><div class="ttdef"><b>Definition:</b> <a href="legend1_8C_source.html#l00017">legend1.C:17</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a9b7007a78cd8fddb9a6f26f4c782b7de"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a9b7007a78cd8fddb9a6f26f4c782b7de">TMVA::DNN::TReference::ScaleAdd</a></div><div class="ttdeci">static void ScaleAdd(TMatrixT&lt; Scalar_t &gt; &amp;A, const TMatrixT&lt; Scalar_t &gt; &amp;B, Scalar_t beta=1.0)</div><div class="ttdoc">Adds a the elements in matrix B scaled by c to the elements in the matrix A. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00076">Propagation.cxx:76</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a3c95a0e60090f94b7b244fe91a850db7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a3c95a0e60090f94b7b244fe91a850db7">TMVA::DNN::TReference::EncodeInput</a></div><div class="ttdeci">static void EncodeInput(TMatrixT&lt; AReal &gt; &amp;input, TMatrixT&lt; AReal &gt; &amp;compressedInput, TMatrixT&lt; AReal &gt; &amp;Weights)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00134">DenoisePropagation.cxx:134</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a0cfb8f7321a4448f28296e5885a069fa"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a0cfb8f7321a4448f28296e5885a069fa">TMVA::DNN::TReference::InitializeIdentity</a></div><div class="ttdeci">static void InitializeIdentity(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00129">Initialization.cxx:129</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a78432c7bd6e437b1c14bda2e29d24fad"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a78432c7bd6e437b1c14bda2e29d24fad">TMVA::DNN::TReference::SquareElementWise</a></div><div class="ttdeci">static void SquareElementWise(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdoc">Square each element of the matrix A and write the result into A. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00081">Arithmetic.cxx:81</a></div></div>
<div class="ttc" id="TRolke_8cxx_html_a89a026883dd7df087bf16c8c176caeed"><div class="ttname"><a href="TRolke_8cxx.html#a89a026883dd7df087bf16c8c176caeed">z</a></div><div class="ttdeci">you should not use this method at all Int_t Int_t z</div><div class="ttdef"><b>Definition:</b> <a href="TRolke_8cxx_source.html#l00630">TRolke.cxx:630</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a5f5d059bf26033c548dfca99d8060cb7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a5f5d059bf26033c548dfca99d8060cb7">TMVA::DNN::TReference::SoftSignDerivative</a></div><div class="ttdeci">static void SoftSignDerivative(TMatrixT&lt; AReal &gt; &amp;B, const TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00189">ActivationFunctions.cxx:189</a></div></div>
<div class="ttc" id="namespaceTMVA_html"><div class="ttname"><a href="namespaceTMVA.html">TMVA</a></div><div class="ttdoc">create variable transformations </div><div class="ttdef"><b>Definition:</b> <a href="GeneticMinimizer_8h_source.html#l00021">GeneticMinimizer.h:21</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_acf0444fde3155665d70fa6cfe7ed65ab"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#acf0444fde3155665d70fa6cfe7ed65ab">TMVA::DNN::TReference::InitializeGauss</a></div><div class="ttdeci">static void InitializeGauss(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Initialization_8cxx_source.html#l00043">Initialization.cxx:43</a></div></div>
<div class="ttc" id="TMatrix_8h_html"><div class="ttname"><a href="TMatrix_8h.html">TMatrix.h</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a74e33dcb050697064c231b88b51866c4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">TMVA::DNN::EActivationFunction</a></div><div class="ttdeci">EActivationFunction</div><div class="ttdoc">Enum that represents layer activation functions. </div><div class="ttdef"><b>Definition:</b> <a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_source.html#l00031">Functions.h:31</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a9c3a6efb1d7f0f51ff5126d67ff8f333"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a9c3a6efb1d7f0f51ff5126d67ff8f333">TMVA::DNN::TReference::CopyDiffArch</a></div><div class="ttdeci">static void CopyDiffArch(TMatrixT&lt; Scalar_t &gt; &amp;A, const AMatrix_t &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00569">Reference.h:569</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a4e0a44f00b7e7251306632c7575f3f48"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a4e0a44f00b7e7251306632c7575f3f48">TMVA::DNN::TReference::Rearrange</a></div><div class="ttdeci">static void Rearrange(std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;out, const std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;in)</div><div class="ttdoc">Rearrage data accoring to time fill B x T x D out with T x B x D matrix in. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00436">Propagation.cxx:436</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a11fc4ac4e11a2e0553004787ab57160d"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a11fc4ac4e11a2e0553004787ab57160d">TMVA::DNN::TReference::MultiplyTranspose</a></div><div class="ttdeci">static void MultiplyTranspose(TMatrixT&lt; Scalar_t &gt; &amp;output, const TMatrixT&lt; Scalar_t &gt; &amp;input, const TMatrixT&lt; Scalar_t &gt; &amp;weights)</div><div class="ttdoc">Matrix-multiply input with the transpose of  and write the results into output. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00023">Propagation.cxx:23</a></div></div>
<div class="ttc" id="win32gdk_2src_2gifencode_8c_html_a606a386e5db616c66c8c8d932d23dc39"><div class="ttname"><a href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a></div><div class="ttdeci">static void output(int code)</div><div class="ttdef"><b>Definition:</b> <a href="win32gdk_2src_2gifencode_8c_source.html#l00226">gifencode.c:226</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a8ca5531242a723ba0d50dc4b05060e91"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a8ca5531242a723ba0d50dc4b05060e91">TMVA::DNN::TReference::MeanSquaredErrorGradients</a></div><div class="ttdeci">static void MeanSquaredErrorGradients(TMatrixT&lt; AReal &gt; &amp;dY, const TMatrixT&lt; AReal &gt; &amp;Y, const TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;weights)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2LossFunctions_8cxx_source.html#l00045">LossFunctions.cxx:45</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a33968e5cbf79be3dff67c1956724d3f7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a33968e5cbf79be3dff67c1956724d3f7">TMVA::DNN::TReference::AddRowWise</a></div><div class="ttdeci">static void AddRowWise(TMatrixT&lt; Scalar_t &gt; &amp;output, const TMatrixT&lt; Scalar_t &gt; &amp;biases)</div><div class="ttdoc">Add the vectors biases row-wise to the matrix output. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Propagation_8cxx_source.html#l00030">Propagation.cxx:30</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a5b0670559d8c12b6d93cf4a30444858a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a5b0670559d8c12b6d93cf4a30444858a">TMVA::DNN::TReference::Gauss</a></div><div class="ttdeci">static void Gauss(TMatrixT&lt; AReal &gt; &amp;B)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2ActivationFunctions_8cxx_source.html#l00206">ActivationFunctions.cxx:206</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_ad4ebd5909722b89b1c12c46732398baa"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#ad4ebd5909722b89b1c12c46732398baa">TMVA::DNN::TReference::MeanSquaredError</a></div><div class="ttdeci">static AReal MeanSquaredError(const TMatrixT&lt; AReal &gt; &amp;Y, const TMatrixT&lt; AReal &gt; &amp;output, const TMatrixT&lt; AReal &gt; &amp;weights)</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2LossFunctions_8cxx_source.html#l00025">LossFunctions.cxx:25</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a0560782d97c0e7c83699dee70f4ea528"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a0560782d97c0e7c83699dee70f4ea528">TMVA::DNN::TReference::ConvLayerForward</a></div><div class="ttdeci">static void ConvLayerForward(std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, const std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;, const TMatrixT&lt; AReal &gt; &amp;, const TMatrixT&lt; AReal &gt; &amp;, const DNN::CNN::TConvParams &amp;, EActivationFunction, std::vector&lt; TMatrixT&lt; AReal &gt;&gt; &amp;)</div><div class="ttdoc">Forward propagation in the Convolutional layer. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_8h_source.html#l00346">Reference.h:346</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a47c5328ac49097dc5d34dd70f6417b8d"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a47c5328ac49097dc5d34dd70f6417b8d">TMVA::DNN::TReference::Dropout</a></div><div class="ttdeci">static void Dropout(TMatrixT&lt; AReal &gt; &amp;A, AReal dropoutProbability)</div><div class="ttdoc">Apply dropout with activation probability p to the given matrix A and scale the result by reciprocal ...</div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Dropout_8cxx_source.html#l00029">Dropout.cxx:29</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a9b0933f18c8d2d8076e46e91a80b5c7e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a9b0933f18c8d2d8076e46e91a80b5c7e">TMVA::DNN::TReference::UpdateParams</a></div><div class="ttdeci">static void UpdateParams(TMatrixT&lt; AReal &gt; &amp;x, TMatrixT&lt; AReal &gt; &amp;tildeX, TMatrixT&lt; AReal &gt; &amp;y, TMatrixT&lt; AReal &gt; &amp;z, TMatrixT&lt; AReal &gt; &amp;fVBiases, TMatrixT&lt; AReal &gt; &amp;fHBiases, TMatrixT&lt; AReal &gt; &amp;fWeights, TMatrixT&lt; AReal &gt; &amp;VBiasError, TMatrixT&lt; AReal &gt; &amp;HBiasError, AReal learningRate, size_t fBatchSize)</div><div class="ttdef"><b>Definition:</b> <a href="DenoisePropagation_8cxx_source.html#l00048">DenoisePropagation.cxx:48</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1TReference_html_a6a56044e4fff320c79d663b64b6dd852"><div class="ttname"><a href="classTMVA_1_1DNN_1_1TReference.html#a6a56044e4fff320c79d663b64b6dd852">TMVA::DNN::TReference::ReciprocalElementWise</a></div><div class="ttdeci">static void ReciprocalElementWise(TMatrixT&lt; AReal &gt; &amp;A)</div><div class="ttdoc">Reciprocal each element of the matrix A and write the result into A. </div><div class="ttdef"><b>Definition:</b> <a href="Reference_2Arithmetic_8cxx_source.html#l00070">Arithmetic.cxx:70</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:09:44 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
