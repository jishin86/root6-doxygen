<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: TMVA::DNN::TDeepNet&lt; Architecture_t, Layer_t &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceTMVA.html">TMVA</a></li><li class="navelem"><a class="el" href="namespaceTMVA_1_1DNN.html">DNN</a></li><li class="navelem"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="classTMVA_1_1DNN_1_1TDeepNet-members.html">List of all members</a> &#124;
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classTMVA_1_1DNN_1_1TDeepNet-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">TMVA::DNN::TDeepNet&lt; Architecture_t, Layer_t &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader"> </h2>
<div class="textblock"><h3>template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt;<br />
class TMVA::DNN::TDeepNet&lt; Architecture_t, Layer_t &gt;</h3>

<p>Generic Deep Neural Network class. </p>
<p>This classs encapsulates the information for all types of Deep Neural Networks.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Architecture</td><td>The Architecture type that holds the architecture-specific data types. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00074">74</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>
</div><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:af60370db07351a788ed14e24d8c2330f"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> = typename Architecture_t::Matrix_t</td></tr>
<tr class="separator:af60370db07351a788ed14e24d8c2330f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e3ce10d7bbd9c2b8559330289ccfdbf"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> = typename Architecture_t::Scalar_t</td></tr>
<tr class="separator:a1e3ce10d7bbd9c2b8559330289ccfdbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ae560df162fe64215e3e22e77fbebaa99"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ae560df162fe64215e3e22e77fbebaa99">TDeepNet</a> ()</td></tr>
<tr class="memdesc:ae560df162fe64215e3e22e77fbebaa99"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default Constructor.  <a href="#ae560df162fe64215e3e22e77fbebaa99">More...</a><br /></td></tr>
<tr class="separator:ae560df162fe64215e3e22e77fbebaa99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5956cd688cab73ecf0b05bec6b5a65fb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a5956cd688cab73ecf0b05bec6b5a65fb">TDeepNet</a> (size_t BatchSize, size_t InputDepth, size_t InputHeight, size_t InputWidth, size_t BatchDepth, size_t BatchHeight, size_t BatchWidth, <a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ad28844e15b7a8a71f8a7fdd08d2d71af">fJ</a>, <a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#afe035f843024e67b122f45bf046cfe63">fI</a>=<a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279a941d5a341a6f6a7a3986952dda4e9445">EInitialization::kZero</a>, <a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa332ceb5248fad2e6cd179fbe98c508c">fR</a>=<a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21a35c3ace1970663a16e5c65baa5941b13">ERegularization::kNone</a>, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a9688dbd9515c9011ccbb54568a2ff7c4">fWeightDecay</a>=0.0, bool isTraining=false)</td></tr>
<tr class="memdesc:a5956cd688cab73ecf0b05bec6b5a65fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="#a5956cd688cab73ecf0b05bec6b5a65fb">More...</a><br /></td></tr>
<tr class="separator:a5956cd688cab73ecf0b05bec6b5a65fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5a62834aa1b2fb6f07e82c2e0c09855"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ac5a62834aa1b2fb6f07e82c2e0c09855">TDeepNet</a> (const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a> &amp;)</td></tr>
<tr class="memdesc:ac5a62834aa1b2fb6f07e82c2e0c09855"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy-constructor.  <a href="#ac5a62834aa1b2fb6f07e82c2e0c09855">More...</a><br /></td></tr>
<tr class="separator:ac5a62834aa1b2fb6f07e82c2e0c09855"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6d84a2109330f4dfb1c552d3b3a0ea6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ad6d84a2109330f4dfb1c552d3b3a0ea6">~TDeepNet</a> ()</td></tr>
<tr class="memdesc:ad6d84a2109330f4dfb1c552d3b3a0ea6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="#ad6d84a2109330f4dfb1c552d3b3a0ea6">More...</a><br /></td></tr>
<tr class="separator:ad6d84a2109330f4dfb1c552d3b3a0ea6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5af75941c138afcd771bc4ec331f67b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1RNN_1_1TBasicRNNLayer.html">TBasicRNNLayer</a>&lt; Architecture_t &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa5af75941c138afcd771bc4ec331f67b">AddBasicRNNLayer</a> (size_t stateSize, size_t inputSize, size_t timeSteps, bool rememberState=false)</td></tr>
<tr class="memdesc:aa5af75941c138afcd771bc4ec331f67b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Recurrent <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, with given parameters.  <a href="#aa5af75941c138afcd771bc4ec331f67b">More...</a><br /></td></tr>
<tr class="separator:aa5af75941c138afcd771bc4ec331f67b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a863d15a780536d8126e8371a7868a074"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a863d15a780536d8126e8371a7868a074">AddBasicRNNLayer</a> (<a class="el" href="classTMVA_1_1DNN_1_1RNN_1_1TBasicRNNLayer.html">TBasicRNNLayer</a>&lt; Architecture_t &gt; *basicRNNLayer)</td></tr>
<tr class="memdesc:a863d15a780536d8126e8371a7868a074"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Vanilla <a class="el" href="namespaceTMVA_1_1DNN_1_1RNN.html">RNN</a> when the layer is already created.  <a href="#a863d15a780536d8126e8371a7868a074">More...</a><br /></td></tr>
<tr class="separator:a863d15a780536d8126e8371a7868a074"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa193284042d625c98b67c3254079c384"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TConvLayer.html">TConvLayer</a>&lt; Architecture_t &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa193284042d625c98b67c3254079c384">AddConvLayer</a> (size_t depth, size_t filterHeight, size_t filterWidth, size_t strideRows, size_t strideCols, size_t paddingHeight, size_t paddingWidth, <a class="el" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="el" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> dropoutProbability=1.0)</td></tr>
<tr class="memdesc:aa193284042d625c98b67c3254079c384"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Convolution layer in the Deep Neural Network, with a given depth, filter height and width, striding in rows and columns, the zero paddings, as well as the activation function and the dropout probability.  <a href="#aa193284042d625c98b67c3254079c384">More...</a><br /></td></tr>
<tr class="separator:aa193284042d625c98b67c3254079c384"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab7c8e03f9a66ccd1706d146692b4ac63"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ab7c8e03f9a66ccd1706d146692b4ac63">AddConvLayer</a> (<a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TConvLayer.html">TConvLayer</a>&lt; Architecture_t &gt; *convLayer)</td></tr>
<tr class="memdesc:ab7c8e03f9a66ccd1706d146692b4ac63"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Convolution <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, when the layer is already created.  <a href="#ab7c8e03f9a66ccd1706d146692b4ac63">More...</a><br /></td></tr>
<tr class="separator:ab7c8e03f9a66ccd1706d146692b4ac63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a583c91b7e94ec2a1216559f24fafe1ae"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TDenseLayer.html">TDenseLayer</a>&lt; Architecture_t &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a583c91b7e94ec2a1216559f24fafe1ae">AddDenseLayer</a> (size_t <a class="el" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, <a class="el" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a> <a class="el" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> dropoutProbability=1.0)</td></tr>
<tr class="memdesc:a583c91b7e94ec2a1216559f24fafe1ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Dense Connected <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, with a given width, activation function and dropout probability.  <a href="#a583c91b7e94ec2a1216559f24fafe1ae">More...</a><br /></td></tr>
<tr class="separator:a583c91b7e94ec2a1216559f24fafe1ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01046b52d62c8917f467ac7005d4d082"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a01046b52d62c8917f467ac7005d4d082">AddDenseLayer</a> (<a class="el" href="classTMVA_1_1DNN_1_1TDenseLayer.html">TDenseLayer</a>&lt; Architecture_t &gt; *denseLayer)</td></tr>
<tr class="memdesc:a01046b52d62c8917f467ac7005d4d082"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Dense <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, when the layer is already created.  <a href="#a01046b52d62c8917f467ac7005d4d082">More...</a><br /></td></tr>
<tr class="separator:a01046b52d62c8917f467ac7005d4d082"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a93fd71854972ae4c635c56ab37cbeced"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TMaxPoolLayer.html">TMaxPoolLayer</a>&lt; Architecture_t &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a93fd71854972ae4c635c56ab37cbeced">AddMaxPoolLayer</a> (size_t frameHeight, size_t frameWidth, size_t strideRows, size_t strideCols, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> dropoutProbability=1.0)</td></tr>
<tr class="memdesc:a93fd71854972ae4c635c56ab37cbeced"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Pooling layer in the Deep Neural Network, with a given filter height and width, striding in rows and columns as well as the dropout probability.  <a href="#a93fd71854972ae4c635c56ab37cbeced">More...</a><br /></td></tr>
<tr class="separator:a93fd71854972ae4c635c56ab37cbeced"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a910d9c1ef743cacf09b8fa5b48f50ed2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a910d9c1ef743cacf09b8fa5b48f50ed2">AddMaxPoolLayer</a> (<a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TMaxPoolLayer.html">CNN::TMaxPoolLayer</a>&lt; Architecture_t &gt; *maxPoolLayer)</td></tr>
<tr class="memdesc:a910d9c1ef743cacf09b8fa5b48f50ed2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Max Pooling layer in the Deep Neural Network, when the layer is already created.  <a href="#a910d9c1ef743cacf09b8fa5b48f50ed2">More...</a><br /></td></tr>
<tr class="separator:a910d9c1ef743cacf09b8fa5b48f50ed2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2f710651755d2133f2497cc64a6b98d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TReshapeLayer.html">TReshapeLayer</a>&lt; Architecture_t &gt; *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ab2f710651755d2133f2497cc64a6b98d">AddReshapeLayer</a> (size_t depth, size_t height, size_t <a class="el" href="TDocParser_8cxx.html#a728a0b17511d9239de0b9bb40ad60600">width</a>, bool flattening)</td></tr>
<tr class="memdesc:ab2f710651755d2133f2497cc64a6b98d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Reshape <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, with a given height and width.  <a href="#ab2f710651755d2133f2497cc64a6b98d">More...</a><br /></td></tr>
<tr class="separator:ab2f710651755d2133f2497cc64a6b98d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53619d2a64725e0ff1558ad6f1347d64"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a53619d2a64725e0ff1558ad6f1347d64">AddReshapeLayer</a> (<a class="el" href="classTMVA_1_1DNN_1_1TReshapeLayer.html">TReshapeLayer</a>&lt; Architecture_t &gt; *reshapeLayer)</td></tr>
<tr class="memdesc:a53619d2a64725e0ff1558ad6f1347d64"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for adding Reshape <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, when the layer is already created.  <a href="#a53619d2a64725e0ff1558ad6f1347d64">More...</a><br /></td></tr>
<tr class="separator:a53619d2a64725e0ff1558ad6f1347d64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa71b59b101614d0f063f031bdea9dc0b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa71b59b101614d0f063f031bdea9dc0b">Backward</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; &amp;input, const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;groundTruth, const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;weights)</td></tr>
<tr class="memdesc:aa71b59b101614d0f063f031bdea9dc0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function that executes the entire backward pass in the network.  <a href="#aa71b59b101614d0f063f031bdea9dc0b">More...</a><br /></td></tr>
<tr class="separator:aa71b59b101614d0f063f031bdea9dc0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55c23c97b8fc5a545d18f40e66036e90"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a55c23c97b8fc5a545d18f40e66036e90">Clear</a> ()</td></tr>
<tr class="memdesc:a55c23c97b8fc5a545d18f40e66036e90"><td class="mdescLeft">&#160;</td><td class="mdescRight">Remove all layers from the network.  <a href="#a55c23c97b8fc5a545d18f40e66036e90">More...</a><br /></td></tr>
<tr class="separator:a55c23c97b8fc5a545d18f40e66036e90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac39c192da75ecf181628f336037f85e3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ac39c192da75ecf181628f336037f85e3">Forward</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; &amp;input, bool applyDropout=false)</td></tr>
<tr class="memdesc:ac39c192da75ecf181628f336037f85e3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function that executes the entire forward pass in the network.  <a href="#ac39c192da75ecf181628f336037f85e3">More...</a><br /></td></tr>
<tr class="separator:ac39c192da75ecf181628f336037f85e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe16954f92da5a61831bd7c1f2114a0b"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#afe16954f92da5a61831bd7c1f2114a0b">GetBatchDepth</a> () const</td></tr>
<tr class="separator:afe16954f92da5a61831bd7c1f2114a0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a062eb9aad77bb359b70edae1a813445c"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a062eb9aad77bb359b70edae1a813445c">GetBatchHeight</a> () const</td></tr>
<tr class="separator:a062eb9aad77bb359b70edae1a813445c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2270e13efcb9d6f60af55ee6d312c027"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a2270e13efcb9d6f60af55ee6d312c027">GetBatchSize</a> () const</td></tr>
<tr class="memdesc:a2270e13efcb9d6f60af55ee6d312c027"><td class="mdescLeft">&#160;</td><td class="mdescRight">Getters.  <a href="#a2270e13efcb9d6f60af55ee6d312c027">More...</a><br /></td></tr>
<tr class="separator:a2270e13efcb9d6f60af55ee6d312c027"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82286de1daea4c5fd474ab68c29e0432"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a82286de1daea4c5fd474ab68c29e0432">GetBatchWidth</a> () const</td></tr>
<tr class="separator:a82286de1daea4c5fd474ab68c29e0432"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30ebd7ba774d1fd02bedb3e57d4f4f97"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a30ebd7ba774d1fd02bedb3e57d4f4f97">GetDepth</a> () const</td></tr>
<tr class="separator:a30ebd7ba774d1fd02bedb3e57d4f4f97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefcc239ecb69f0ab3beb34ffca9639cc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aefcc239ecb69f0ab3beb34ffca9639cc">GetInitialization</a> () const</td></tr>
<tr class="separator:aefcc239ecb69f0ab3beb34ffca9639cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a374bb988c4a05f45653d5bfc96b7cfac"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a374bb988c4a05f45653d5bfc96b7cfac">GetInputDepth</a> () const</td></tr>
<tr class="separator:a374bb988c4a05f45653d5bfc96b7cfac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67e12aee019b09443bded95e5d50905e"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a67e12aee019b09443bded95e5d50905e">GetInputHeight</a> () const</td></tr>
<tr class="separator:a67e12aee019b09443bded95e5d50905e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa51e2ec86f21ff3aaff6d939597aeb42"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa51e2ec86f21ff3aaff6d939597aeb42">GetInputWidth</a> () const</td></tr>
<tr class="separator:aa51e2ec86f21ff3aaff6d939597aeb42"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ac15db4159e904c81a77e16ea14a0ec"><td class="memItemLeft" align="right" valign="top">Layer_t *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a5ac15db4159e904c81a77e16ea14a0ec">GetLayerAt</a> (size_t i)</td></tr>
<tr class="memdesc:a5ac15db4159e904c81a77e16ea14a0ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the layer in the vector of layers at poistion i.  <a href="#a5ac15db4159e904c81a77e16ea14a0ec">More...</a><br /></td></tr>
<tr class="separator:a5ac15db4159e904c81a77e16ea14a0ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d4fefba607d32bdb7685d78ef1a400a"><td class="memItemLeft" align="right" valign="top">const Layer_t *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a8d4fefba607d32bdb7685d78ef1a400a">GetLayerAt</a> (size_t i) const</td></tr>
<tr class="separator:a8d4fefba607d32bdb7685d78ef1a400a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5de15c7ed2f9cfb1fd8c09906034021e"><td class="memItemLeft" align="right" valign="top">std::vector&lt; Layer_t * &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a5de15c7ed2f9cfb1fd8c09906034021e">GetLayers</a> ()</td></tr>
<tr class="separator:a5de15c7ed2f9cfb1fd8c09906034021e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad4657e98c9e0a95611eb904393370ee0"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; Layer_t * &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ad4657e98c9e0a95611eb904393370ee0">GetLayers</a> () const</td></tr>
<tr class="separator:ad4657e98c9e0a95611eb904393370ee0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9f8a7e424e7ccdf42db7916ba90511d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ae9f8a7e424e7ccdf42db7916ba90511d">GetLossFunction</a> () const</td></tr>
<tr class="separator:ae9f8a7e424e7ccdf42db7916ba90511d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa5ccd8b5cd982ad2534490489fa2bc3"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aaa5ccd8b5cd982ad2534490489fa2bc3">GetOutputWidth</a> () const</td></tr>
<tr class="separator:aaa5ccd8b5cd982ad2534490489fa2bc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13c66a8414a652df39aa7c5d51c7e292"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a13c66a8414a652df39aa7c5d51c7e292">GetRegularization</a> () const</td></tr>
<tr class="separator:a13c66a8414a652df39aa7c5d51c7e292"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a338435b4cd2ce04769a38598cbd42f75"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a338435b4cd2ce04769a38598cbd42f75">GetWeightDecay</a> () const</td></tr>
<tr class="separator:a338435b4cd2ce04769a38598cbd42f75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21d63c1ddd495dde3503ac35431bf15f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a21d63c1ddd495dde3503ac35431bf15f">Initialize</a> ()</td></tr>
<tr class="memdesc:a21d63c1ddd495dde3503ac35431bf15f"><td class="mdescLeft">&#160;</td><td class="mdescRight">DAE functions.  <a href="#a21d63c1ddd495dde3503ac35431bf15f">More...</a><br /></td></tr>
<tr class="separator:a21d63c1ddd495dde3503ac35431bf15f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a648e2e62b539ac78f67bb8b62e2093f6"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a648e2e62b539ac78f67bb8b62e2093f6">IsTraining</a> () const</td></tr>
<tr class="separator:a648e2e62b539ac78f67bb8b62e2093f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99f6c5c05b866333dac64afc70f022cd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a99f6c5c05b866333dac64afc70f022cd">Loss</a> (const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;groundTruth, const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;weights, bool includeRegularization=true) const</td></tr>
<tr class="memdesc:a99f6c5c05b866333dac64afc70f022cd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for evaluating the loss, based on the activations stored in the last layer.  <a href="#a99f6c5c05b866333dac64afc70f022cd">More...</a><br /></td></tr>
<tr class="separator:a99f6c5c05b866333dac64afc70f022cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf028407404e67802f09b5cd9d655b20"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#adf028407404e67802f09b5cd9d655b20">Loss</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; &amp;input, const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;groundTruth, const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;weights, bool applyDropout=false, bool includeRegularization=true)</td></tr>
<tr class="memdesc:adf028407404e67802f09b5cd9d655b20"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for evaluating the loss, based on the propagation of the given input.  <a href="#adf028407404e67802f09b5cd9d655b20">More...</a><br /></td></tr>
<tr class="separator:adf028407404e67802f09b5cd9d655b20"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24e68086f38e075f473dcec9d403c4ba"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a24e68086f38e075f473dcec9d403c4ba">ParallelBackward</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;nets, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;batches, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> learningRate)</td></tr>
<tr class="memdesc:a24e68086f38e075f473dcec9d403c4ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for parallel backward in the vector of deep nets, where the master net is the net calling this function and getting the updates from the other nets.  <a href="#a24e68086f38e075f473dcec9d403c4ba">More...</a><br /></td></tr>
<tr class="separator:a24e68086f38e075f473dcec9d403c4ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ba940fb5642567aed7fbb17f228fd1f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a5ba940fb5642567aed7fbb17f228fd1f">ParallelBackwardMomentum</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;nets, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;batches, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> learningRate, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> momentum)</td></tr>
<tr class="memdesc:a5ba940fb5642567aed7fbb17f228fd1f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for parallel backward in the vector of deep nets, where the master net is the net calling this function and getting the updates from the other nets, following the momentum strategy.  <a href="#a5ba940fb5642567aed7fbb17f228fd1f">More...</a><br /></td></tr>
<tr class="separator:a5ba940fb5642567aed7fbb17f228fd1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb88c204204f6df9b1f9f1f1af2ba49a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#acb88c204204f6df9b1f9f1f1af2ba49a">ParallelBackwardNestorov</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;nets, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;batches, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> learningRate, <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> momentum)</td></tr>
<tr class="memdesc:acb88c204204f6df9b1f9f1f1af2ba49a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for parallel backward in the vector of deep nets, where the master net is the net calling this function and getting the updates from the other nets, following the Nestorov momentum strategy.  <a href="#acb88c204204f6df9b1f9f1f1af2ba49a">More...</a><br /></td></tr>
<tr class="separator:acb88c204204f6df9b1f9f1f1af2ba49a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa62f912689c9773d9413fdb75ae7a586"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa62f912689c9773d9413fdb75ae7a586">ParallelForward</a> (std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;nets, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;batches, bool applyDropout=false)</td></tr>
<tr class="memdesc:aa62f912689c9773d9413fdb75ae7a586"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for parallel forward in the vector of deep nets, where the master net is the net calling this function.  <a href="#aa62f912689c9773d9413fdb75ae7a586">More...</a><br /></td></tr>
<tr class="separator:aa62f912689c9773d9413fdb75ae7a586"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e33c9f942056a145bc0b33f89b89cb2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a6e33c9f942056a145bc0b33f89b89cb2">Prediction</a> (<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;predictions, <a class="el" href="namespaceTMVA_1_1DNN.html#a38848bbc9246d0fcf34529517be92a13">EOutputFunction</a> <a class="el" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>) const</td></tr>
<tr class="memdesc:a6e33c9f942056a145bc0b33f89b89cb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prediction based on activations stored in the last layer.  <a href="#a6e33c9f942056a145bc0b33f89b89cb2">More...</a><br /></td></tr>
<tr class="separator:a6e33c9f942056a145bc0b33f89b89cb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a591f5bc896169cdb544475f5e64220ec"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a591f5bc896169cdb544475f5e64220ec">Prediction</a> (<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;predictions, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; input, <a class="el" href="namespaceTMVA_1_1DNN.html#a38848bbc9246d0fcf34529517be92a13">EOutputFunction</a> <a class="el" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>)</td></tr>
<tr class="memdesc:a591f5bc896169cdb544475f5e64220ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prediction for the given inputs, based on what network learned.  <a href="#a591f5bc896169cdb544475f5e64220ec">More...</a><br /></td></tr>
<tr class="separator:a591f5bc896169cdb544475f5e64220ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47e33b3d7d72e61b4fda1c62ea19ab23"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a47e33b3d7d72e61b4fda1c62ea19ab23">Print</a> () const</td></tr>
<tr class="memdesc:a47e33b3d7d72e61b4fda1c62ea19ab23"><td class="mdescLeft">&#160;</td><td class="mdescRight">Print the Deep <a class="el" href="classTMVA_1_1DNN_1_1Net.html" title="neural net ">Net</a> Info.  <a href="#a47e33b3d7d72e61b4fda1c62ea19ab23">More...</a><br /></td></tr>
<tr class="separator:a47e33b3d7d72e61b4fda1c62ea19ab23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56a3ef68980a668f36711e9031f7d000"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a56a3ef68980a668f36711e9031f7d000">RegularizationTerm</a> () const</td></tr>
<tr class="memdesc:a56a3ef68980a668f36711e9031f7d000"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for computing the regularizaton term to be added to the loss function.  <a href="#a56a3ef68980a668f36711e9031f7d000">More...</a><br /></td></tr>
<tr class="separator:a56a3ef68980a668f36711e9031f7d000"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06ec0245b44a5271f39864d5ce461468"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a06ec0245b44a5271f39864d5ce461468">SetBatchDepth</a> (size_t batchDepth)</td></tr>
<tr class="separator:a06ec0245b44a5271f39864d5ce461468"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae686bf847fb88ee6ed3561eb843ca41e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ae686bf847fb88ee6ed3561eb843ca41e">SetBatchHeight</a> (size_t batchHeight)</td></tr>
<tr class="separator:ae686bf847fb88ee6ed3561eb843ca41e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab37b63fb66fa378fab2f84c343df3c7b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ab37b63fb66fa378fab2f84c343df3c7b">SetBatchSize</a> (size_t batchSize)</td></tr>
<tr class="memdesc:ab37b63fb66fa378fab2f84c343df3c7b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Setters.  <a href="#ab37b63fb66fa378fab2f84c343df3c7b">More...</a><br /></td></tr>
<tr class="separator:ab37b63fb66fa378fab2f84c343df3c7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adef960d52b5f4a2e8875646e0e04c9af"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#adef960d52b5f4a2e8875646e0e04c9af">SetBatchWidth</a> (size_t batchWidth)</td></tr>
<tr class="separator:adef960d52b5f4a2e8875646e0e04c9af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1d55bea8922ee2880565e888a23f0e9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ae1d55bea8922ee2880565e888a23f0e9">SetDropoutProbabilities</a> (const std::vector&lt; <a class="el" href="RtypesCore_8h.html#ab9b5334647b78ec4256db251e3ae1fc6">Double_t</a> &gt; &amp;probabilities)</td></tr>
<tr class="separator:ae1d55bea8922ee2880565e888a23f0e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee4571ae71c4e5bc013226e8fc672604"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aee4571ae71c4e5bc013226e8fc672604">SetInitialization</a> (<a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a> <a class="el" href="md5_8inl.html#ac0eafdc9ee161b71e7af98af736952fd">I</a>)</td></tr>
<tr class="separator:aee4571ae71c4e5bc013226e8fc672604"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a626c5e4ce181c4f5506e3028398615bc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a626c5e4ce181c4f5506e3028398615bc">SetInputDepth</a> (size_t inputDepth)</td></tr>
<tr class="separator:a626c5e4ce181c4f5506e3028398615bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a808631744eb351530a08b6251cfd6350"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a808631744eb351530a08b6251cfd6350">SetInputHeight</a> (size_t inputHeight)</td></tr>
<tr class="separator:a808631744eb351530a08b6251cfd6350"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5b70cb9cb436be909f323249116e6cc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af5b70cb9cb436be909f323249116e6cc">SetInputWidth</a> (size_t inputWidth)</td></tr>
<tr class="separator:af5b70cb9cb436be909f323249116e6cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0d8963df1df85b16b7eb399713646384"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a0d8963df1df85b16b7eb399713646384">SetLossFunction</a> (<a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a> J)</td></tr>
<tr class="separator:a0d8963df1df85b16b7eb399713646384"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac27383d13ec157a90e6c4e66fc9acaf8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ac27383d13ec157a90e6c4e66fc9acaf8">SetRegularization</a> (<a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="el" href="RSha256_8hxx.html#ae076917a1bc8cbea6ed0af47d7c897fe">R</a>)</td></tr>
<tr class="separator:ac27383d13ec157a90e6c4e66fc9acaf8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4fee8e0cfe8f9845b83b10160a9175b5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a4fee8e0cfe8f9845b83b10160a9175b5">SetWeightDecay</a> (<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> <a class="el" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>)</td></tr>
<tr class="separator:a4fee8e0cfe8f9845b83b10160a9175b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae80a47260da5b099c31de2ccf5d13cca"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ae80a47260da5b099c31de2ccf5d13cca">Update</a> (<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> learningRate)</td></tr>
<tr class="memdesc:ae80a47260da5b099c31de2ccf5d13cca"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function that will update the weights and biases in the layers that contain weights and biases.  <a href="#ae80a47260da5b099c31de2ccf5d13cca">More...</a><br /></td></tr>
<tr class="separator:ae80a47260da5b099c31de2ccf5d13cca"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:aea836134ccadd6c62c7eac7451bcdec8"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aea836134ccadd6c62c7eac7451bcdec8">calculateDimension</a> (int imgDim, int fltDim, int padding, int stride)</td></tr>
<tr class="separator:aea836134ccadd6c62c7eac7451bcdec8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8ad8ee97fe933a2ee78b2d4ecb6ba54"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa8ad8ee97fe933a2ee78b2d4ecb6ba54">isInteger</a> (<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> <a class="el" href="TRolke_8cxx.html#ada5c5f3c15b1aa65d2ed9e5fa97a38d5">x</a>) const</td></tr>
<tr class="separator:aa8ad8ee97fe933a2ee78b2d4ecb6ba54"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a3c6a5825de255f99cf31d10a663ddcdc"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a3c6a5825de255f99cf31d10a663ddcdc">fBatchDepth</a></td></tr>
<tr class="memdesc:a3c6a5825de255f99cf31d10a663ddcdc"><td class="mdescLeft">&#160;</td><td class="mdescRight">The depth of the batch used for training/testing.  <a href="#a3c6a5825de255f99cf31d10a663ddcdc">More...</a><br /></td></tr>
<tr class="separator:a3c6a5825de255f99cf31d10a663ddcdc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1130f1773d0370b3064ef7f1a0bf3030"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1130f1773d0370b3064ef7f1a0bf3030">fBatchHeight</a></td></tr>
<tr class="memdesc:a1130f1773d0370b3064ef7f1a0bf3030"><td class="mdescLeft">&#160;</td><td class="mdescRight">The height of the batch used for training/testing.  <a href="#a1130f1773d0370b3064ef7f1a0bf3030">More...</a><br /></td></tr>
<tr class="separator:a1130f1773d0370b3064ef7f1a0bf3030"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69400f97680efffa11752f22bb2e73af"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a69400f97680efffa11752f22bb2e73af">fBatchSize</a></td></tr>
<tr class="memdesc:a69400f97680efffa11752f22bb2e73af"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classTMVA_1_1DNN_1_1Batch.html" title="The Batch class encapsulates one mini-batch. ">Batch</a> size used for training and evaluation.  <a href="#a69400f97680efffa11752f22bb2e73af">More...</a><br /></td></tr>
<tr class="separator:a69400f97680efffa11752f22bb2e73af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace43ba7bfdfd9c2c18d14d94f6aaae7f"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ace43ba7bfdfd9c2c18d14d94f6aaae7f">fBatchWidth</a></td></tr>
<tr class="memdesc:ace43ba7bfdfd9c2c18d14d94f6aaae7f"><td class="mdescLeft">&#160;</td><td class="mdescRight">The width of the batch used for training/testing.  <a href="#ace43ba7bfdfd9c2c18d14d94f6aaae7f">More...</a><br /></td></tr>
<tr class="separator:ace43ba7bfdfd9c2c18d14d94f6aaae7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe035f843024e67b122f45bf046cfe63"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#afe035f843024e67b122f45bf046cfe63">fI</a></td></tr>
<tr class="memdesc:afe035f843024e67b122f45bf046cfe63"><td class="mdescLeft">&#160;</td><td class="mdescRight">The initialization method of the network.  <a href="#afe035f843024e67b122f45bf046cfe63">More...</a><br /></td></tr>
<tr class="separator:afe035f843024e67b122f45bf046cfe63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a434a8e970aba0664cf4508faa1ddd79d"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a434a8e970aba0664cf4508faa1ddd79d">fInputDepth</a></td></tr>
<tr class="memdesc:a434a8e970aba0664cf4508faa1ddd79d"><td class="mdescLeft">&#160;</td><td class="mdescRight">The depth of the input.  <a href="#a434a8e970aba0664cf4508faa1ddd79d">More...</a><br /></td></tr>
<tr class="separator:a434a8e970aba0664cf4508faa1ddd79d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc12296a260f5cdd610b851dc5793381"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#abc12296a260f5cdd610b851dc5793381">fInputHeight</a></td></tr>
<tr class="memdesc:abc12296a260f5cdd610b851dc5793381"><td class="mdescLeft">&#160;</td><td class="mdescRight">The height of the input.  <a href="#abc12296a260f5cdd610b851dc5793381">More...</a><br /></td></tr>
<tr class="separator:abc12296a260f5cdd610b851dc5793381"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78bd3820cf699e7df55df8f3f3bc2377"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a78bd3820cf699e7df55df8f3f3bc2377">fInputWidth</a></td></tr>
<tr class="memdesc:a78bd3820cf699e7df55df8f3f3bc2377"><td class="mdescLeft">&#160;</td><td class="mdescRight">The width of the input.  <a href="#a78bd3820cf699e7df55df8f3f3bc2377">More...</a><br /></td></tr>
<tr class="separator:a78bd3820cf699e7df55df8f3f3bc2377"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafa5d707713a8f6d09b254822c75c119"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aafa5d707713a8f6d09b254822c75c119">fIsTraining</a></td></tr>
<tr class="memdesc:aafa5d707713a8f6d09b254822c75c119"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the network training?  <a href="#aafa5d707713a8f6d09b254822c75c119">More...</a><br /></td></tr>
<tr class="separator:aafa5d707713a8f6d09b254822c75c119"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad28844e15b7a8a71f8a7fdd08d2d71af"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#ad28844e15b7a8a71f8a7fdd08d2d71af">fJ</a></td></tr>
<tr class="memdesc:ad28844e15b7a8a71f8a7fdd08d2d71af"><td class="mdescLeft">&#160;</td><td class="mdescRight">The loss function of the network.  <a href="#ad28844e15b7a8a71f8a7fdd08d2d71af">More...</a><br /></td></tr>
<tr class="separator:ad28844e15b7a8a71f8a7fdd08d2d71af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a382f7265cc1591308b47255820b02664"><td class="memItemLeft" align="right" valign="top">std::vector&lt; Layer_t * &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a382f7265cc1591308b47255820b02664">fLayers</a></td></tr>
<tr class="memdesc:a382f7265cc1591308b47255820b02664"><td class="mdescLeft">&#160;</td><td class="mdescRight">The layers consisting the DeepNet.  <a href="#a382f7265cc1591308b47255820b02664">More...</a><br /></td></tr>
<tr class="separator:a382f7265cc1591308b47255820b02664"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa332ceb5248fad2e6cd179fbe98c508c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#aa332ceb5248fad2e6cd179fbe98c508c">fR</a></td></tr>
<tr class="memdesc:aa332ceb5248fad2e6cd179fbe98c508c"><td class="mdescLeft">&#160;</td><td class="mdescRight">The regularization used for the network.  <a href="#aa332ceb5248fad2e6cd179fbe98c508c">More...</a><br /></td></tr>
<tr class="separator:aa332ceb5248fad2e6cd179fbe98c508c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9688dbd9515c9011ccbb54568a2ff7c4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a9688dbd9515c9011ccbb54568a2ff7c4">fWeightDecay</a></td></tr>
<tr class="memdesc:a9688dbd9515c9011ccbb54568a2ff7c4"><td class="mdescLeft">&#160;</td><td class="mdescRight">The weight decay factor.  <a href="#a9688dbd9515c9011ccbb54568a2ff7c4">More...</a><br /></td></tr>
<tr class="separator:a9688dbd9515c9011ccbb54568a2ff7c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>

<p><code>#include &lt;<a class="el" href="DeepNet_8h_source.html">TMVA/DNN/DeepNet.h</a>&gt;</code></p>
<h2 class="groupheader">Member Typedef Documentation</h2>
<a id="af60370db07351a788ed14e24d8c2330f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af60370db07351a788ed14e24d8c2330f">&#9670;&nbsp;</a></span>Matrix_t</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> =  typename Architecture_t::Matrix_t</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00076">76</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a1e3ce10d7bbd9c2b8559330289ccfdbf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e3ce10d7bbd9c2b8559330289ccfdbf">&#9670;&nbsp;</a></span>Scalar_t</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> =  typename Architecture_t::Scalar_t</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00077">77</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ae560df162fe64215e3e22e77fbebaa99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae560df162fe64215e3e22e77fbebaa99">&#9670;&nbsp;</a></span>TDeepNet() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Default Constructor. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00345">345</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a5956cd688cab73ecf0b05bec6b5a65fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5956cd688cab73ecf0b05bec6b5a65fb">&#9670;&nbsp;</a></span>TDeepNet() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a> </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>BatchSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>InputDepth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>InputHeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>InputWidth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>BatchDepth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>BatchHeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>BatchWidth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a>&#160;</td>
          <td class="paramname"><em>fJ</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a>&#160;</td>
          <td class="paramname"><em>fI</em> = <code><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279a941d5a341a6f6a7a3986952dda4e9445">EInitialization::kZero</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a>&#160;</td>
          <td class="paramname"><em>fR</em> = <code><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21a35c3ace1970663a16e5c65baa5941b13">ERegularization::kNone</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>fWeightDecay</em> = <code>0.0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>isTraining</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00355">355</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ac5a62834aa1b2fb6f07e82c2e0c09855"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac5a62834aa1b2fb6f07e82c2e0c09855">&#9670;&nbsp;</a></span>TDeepNet() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>deepNet</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Copy-constructor. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00367">367</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ad6d84a2109330f4dfb1c552d3b3a0ea6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6d84a2109330f4dfb1c552d3b3a0ea6">&#9670;&nbsp;</a></span>~TDeepNet()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::~<a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destructor. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00378">378</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aa5af75941c138afcd771bc4ec331f67b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5af75941c138afcd771bc4ec331f67b">&#9670;&nbsp;</a></span>AddBasicRNNLayer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1RNN_1_1TBasicRNNLayer.html">TBasicRNNLayer</a>&lt; Architecture_t &gt; * <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddBasicRNNLayer </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stateSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>inputSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>timeSteps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>rememberState</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Recurrent <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, with given parameters. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00488">488</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a863d15a780536d8126e8371a7868a074"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a863d15a780536d8126e8371a7868a074">&#9670;&nbsp;</a></span>AddBasicRNNLayer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddBasicRNNLayer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1RNN_1_1TBasicRNNLayer.html">TBasicRNNLayer</a>&lt; Architecture_t &gt; *&#160;</td>
          <td class="paramname"><em>basicRNNLayer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Vanilla <a class="el" href="namespaceTMVA_1_1DNN_1_1RNN.html">RNN</a> when the layer is already created. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00521">521</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aa193284042d625c98b67c3254079c384"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa193284042d625c98b67c3254079c384">&#9670;&nbsp;</a></span>AddConvLayer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TConvLayer.html">TConvLayer</a>&lt; Architecture_t &gt; * <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddConvLayer </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>depth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>filterHeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>filterWidth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>strideRows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>strideCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>paddingHeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>paddingWidth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a>&#160;</td>
          <td class="paramname"><em>f</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>dropoutProbability</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Convolution layer in the Deep Neural Network, with a given depth, filter height and width, striding in rows and columns, the zero paddings, as well as the activation function and the dropout probability. </p>
<p>Based on these parameters, it calculates the width and height of the convolutional layer. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00403">403</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ab7c8e03f9a66ccd1706d146692b4ac63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab7c8e03f9a66ccd1706d146692b4ac63">&#9670;&nbsp;</a></span>AddConvLayer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddConvLayer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TConvLayer.html">TConvLayer</a>&lt; Architecture_t &gt; *&#160;</td>
          <td class="paramname"><em>convLayer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Convolution <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, when the layer is already created. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00442">442</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a583c91b7e94ec2a1216559f24fafe1ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a583c91b7e94ec2a1216559f24fafe1ae">&#9670;&nbsp;</a></span>AddDenseLayer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDenseLayer.html">TDenseLayer</a>&lt; Architecture_t &gt; * <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddDenseLayer </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a74e33dcb050697064c231b88b51866c4">EActivationFunction</a>&#160;</td>
          <td class="paramname"><em>f</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>dropoutProbability</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Dense Connected <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, with a given width, activation function and dropout probability. </p>
<p>Based on the previous layer dimensions, it calculates the input width of the fully connected layer. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00618">618</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a01046b52d62c8917f467ac7005d4d082"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01046b52d62c8917f467ac7005d4d082">&#9670;&nbsp;</a></span>AddDenseLayer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddDenseLayer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDenseLayer.html">TDenseLayer</a>&lt; Architecture_t &gt; *&#160;</td>
          <td class="paramname"><em>denseLayer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Dense <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, when the layer is already created. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00644">644</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a93fd71854972ae4c635c56ab37cbeced"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a93fd71854972ae4c635c56ab37cbeced">&#9670;&nbsp;</a></span>AddMaxPoolLayer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TMaxPoolLayer.html">TMaxPoolLayer</a>&lt; Architecture_t &gt; * <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddMaxPoolLayer </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>frameHeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>frameWidth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>strideRows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>strideCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>dropoutProbability</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Pooling layer in the Deep Neural Network, with a given filter height and width, striding in rows and columns as well as the dropout probability. </p>
<p>The depth is same as the previous layer depth. Based on these parameters, it calculates the width and height of the pooling layer. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00449">449</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a910d9c1ef743cacf09b8fa5b48f50ed2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a910d9c1ef743cacf09b8fa5b48f50ed2">&#9670;&nbsp;</a></span>AddMaxPoolLayer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddMaxPoolLayer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1CNN_1_1TMaxPoolLayer.html">CNN::TMaxPoolLayer</a>&lt; Architecture_t &gt; *&#160;</td>
          <td class="paramname"><em>maxPoolLayer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Max Pooling layer in the Deep Neural Network, when the layer is already created. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00481">481</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ab2f710651755d2133f2497cc64a6b98d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2f710651755d2133f2497cc64a6b98d">&#9670;&nbsp;</a></span>AddReshapeLayer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TReshapeLayer.html">TReshapeLayer</a>&lt; Architecture_t &gt; * <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddReshapeLayer </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>depth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>flattening</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Reshape <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, with a given height and width. </p>
<p>It will take every matrix from the previous layer and reshape it to a matrix with new dimensions. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00651">651</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a53619d2a64725e0ff1558ad6f1347d64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53619d2a64725e0ff1558ad6f1347d64">&#9670;&nbsp;</a></span>AddReshapeLayer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::AddReshapeLayer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TReshapeLayer.html">TReshapeLayer</a>&lt; Architecture_t &gt; *&#160;</td>
          <td class="paramname"><em>reshapeLayer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for adding Reshape <a class="el" href="classTMVA_1_1DNN_1_1Layer.html" title="Layer defines the layout of a layer. ">Layer</a> in the Deep Neural Network, when the layer is already created. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00703">703</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aa71b59b101614d0f063f031bdea9dc0b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa71b59b101614d0f063f031bdea9dc0b">&#9670;&nbsp;</a></span>Backward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Backward </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>groundTruth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>weights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function that executes the entire backward pass in the network. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00889">889</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aea836134ccadd6c62c7eac7451bcdec8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea836134ccadd6c62c7eac7451bcdec8">&#9670;&nbsp;</a></span>calculateDimension()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::calculateDimension </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>imgDim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>fltDim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00385">385</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a55c23c97b8fc5a545d18f40e66036e90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55c23c97b8fc5a545d18f40e66036e90">&#9670;&nbsp;</a></span>Clear()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Clear </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Remove all layers from the network. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00301">301</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ac39c192da75ecf181628f336037f85e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac39c192da75ecf181628f336037f85e3">&#9670;&nbsp;</a></span>Forward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Forward </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>applyDropout</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function that executes the entire forward pass in the network. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00734">734</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="afe16954f92da5a61831bd7c1f2114a0b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe16954f92da5a61831bd7c1f2114a0b">&#9670;&nbsp;</a></span>GetBatchDepth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetBatchDepth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00309">309</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a062eb9aad77bb359b70edae1a813445c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a062eb9aad77bb359b70edae1a813445c">&#9670;&nbsp;</a></span>GetBatchHeight()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetBatchHeight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00310">310</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a2270e13efcb9d6f60af55ee6d312c027"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2270e13efcb9d6f60af55ee6d312c027">&#9670;&nbsp;</a></span>GetBatchSize()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetBatchSize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Getters. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00304">304</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a82286de1daea4c5fd474ab68c29e0432"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82286de1daea4c5fd474ab68c29e0432">&#9670;&nbsp;</a></span>GetBatchWidth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetBatchWidth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00311">311</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a30ebd7ba774d1fd02bedb3e57d4f4f97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a30ebd7ba774d1fd02bedb3e57d4f4f97">&#9670;&nbsp;</a></span>GetDepth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetDepth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00293">293</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aefcc239ecb69f0ab3beb34ffca9639cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aefcc239ecb69f0ab3beb34ffca9639cc">&#9670;&nbsp;</a></span>GetInitialization()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetInitialization </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00316">316</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a374bb988c4a05f45653d5bfc96b7cfac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a374bb988c4a05f45653d5bfc96b7cfac">&#9670;&nbsp;</a></span>GetInputDepth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetInputDepth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00305">305</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a67e12aee019b09443bded95e5d50905e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67e12aee019b09443bded95e5d50905e">&#9670;&nbsp;</a></span>GetInputHeight()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetInputHeight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00306">306</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aa51e2ec86f21ff3aaff6d939597aeb42"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa51e2ec86f21ff3aaff6d939597aeb42">&#9670;&nbsp;</a></span>GetInputWidth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetInputWidth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00307">307</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a5ac15db4159e904c81a77e16ea14a0ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ac15db4159e904c81a77e16ea14a0ec">&#9670;&nbsp;</a></span>GetLayerAt() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Layer_t* <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetLayerAt </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>i</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the layer in the vector of layers at poistion i. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00289">289</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a8d4fefba607d32bdb7685d78ef1a400a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d4fefba607d32bdb7685d78ef1a400a">&#9670;&nbsp;</a></span>GetLayerAt() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const Layer_t* <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetLayerAt </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>i</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00290">290</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a5de15c7ed2f9cfb1fd8c09906034021e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5de15c7ed2f9cfb1fd8c09906034021e">&#9670;&nbsp;</a></span>GetLayers() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;Layer_t *&gt;&amp; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetLayers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00297">297</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ad4657e98c9e0a95611eb904393370ee0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad4657e98c9e0a95611eb904393370ee0">&#9670;&nbsp;</a></span>GetLayers() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::vector&lt;Layer_t *&gt;&amp; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetLayers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00298">298</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ae9f8a7e424e7ccdf42db7916ba90511d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9f8a7e424e7ccdf42db7916ba90511d">&#9670;&nbsp;</a></span>GetLossFunction()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetLossFunction </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00315">315</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aaa5ccd8b5cd982ad2534490489fa2bc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaa5ccd8b5cd982ad2534490489fa2bc3">&#9670;&nbsp;</a></span>GetOutputWidth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetOutputWidth </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00294">294</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a13c66a8414a652df39aa7c5d51c7e292"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13c66a8414a652df39aa7c5d51c7e292">&#9670;&nbsp;</a></span>GetRegularization()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetRegularization </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00317">317</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a338435b4cd2ce04769a38598cbd42f75"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a338435b4cd2ce04769a38598cbd42f75">&#9670;&nbsp;</a></span>GetWeightDecay()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::GetWeightDecay </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00318">318</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a21d63c1ddd495dde3503ac35431bf15f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21d63c1ddd495dde3503ac35431bf15f">&#9670;&nbsp;</a></span>Initialize()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Initialize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>DAE functions. </p>
<p>Function for initialization of the Neural <a class="el" href="classTMVA_1_1DNN_1_1Net.html" title="neural net ">Net</a>. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00710">710</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aa8ad8ee97fe933a2ee78b2d4ecb6ba54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8ad8ee97fe933a2ee78b2d4ecb6ba54">&#9670;&nbsp;</a></span>isInteger()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::isInteger </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00080">80</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a648e2e62b539ac78f67bb8b62e2093f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a648e2e62b539ac78f67bb8b62e2093f6">&#9670;&nbsp;</a></span>IsTraining()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::IsTraining </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00313">313</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a99f6c5c05b866333dac64afc70f022cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99f6c5c05b866333dac64afc70f022cd">&#9670;&nbsp;</a></span>Loss() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Loss </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>groundTruth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>includeRegularization</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for evaluating the loss, based on the activations stored in the last layer. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01092">1092</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="adf028407404e67802f09b5cd9d655b20"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf028407404e67802f09b5cd9d655b20">&#9670;&nbsp;</a></span>Loss() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Loss </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>groundTruth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>applyDropout</em> = <code>false</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>includeRegularization</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for evaluating the loss, based on the propagation of the given input. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01108">1108</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a24e68086f38e075f473dcec9d403c4ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24e68086f38e075f473dcec9d403c4ba">&#9670;&nbsp;</a></span>ParallelBackward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::ParallelBackward </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>nets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>batches</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>learningRate</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for parallel backward in the vector of deep nets, where the master net is the net calling this function and getting the updates from the other nets. </p>
<p>There is one batch for one deep net. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00911">911</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a5ba940fb5642567aed7fbb17f228fd1f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ba940fb5642567aed7fbb17f228fd1f">&#9670;&nbsp;</a></span>ParallelBackwardMomentum()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::ParallelBackwardMomentum </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>nets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>batches</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>learningRate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for parallel backward in the vector of deep nets, where the master net is the net calling this function and getting the updates from the other nets, following the momentum strategy. </p>
<p>There is one batch for one deep net. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00958">958</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="acb88c204204f6df9b1f9f1f1af2ba49a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb88c204204f6df9b1f9f1f1af2ba49a">&#9670;&nbsp;</a></span>ParallelBackwardNestorov()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::ParallelBackwardNestorov </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>nets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>batches</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>learningRate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>momentum</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for parallel backward in the vector of deep nets, where the master net is the net calling this function and getting the updates from the other nets, following the Nestorov momentum strategy. </p>
<p>There is one batch for one deep net. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01021">1021</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aa62f912689c9773d9413fdb75ae7a586"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa62f912689c9773d9413fdb75ae7a586">&#9670;&nbsp;</a></span>ParallelForward()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::ParallelForward </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TDeepNet</a>&lt; Architecture_t, Layer_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>nets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TTensorBatch.html">TTensorBatch</a>&lt; Architecture_t &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>batches</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>applyDropout</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for parallel forward in the vector of deep nets, where the master net is the net calling this function. </p>
<p>There is one batch for one deep net. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00745">745</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a6e33c9f942056a145bc0b33f89b89cb2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6e33c9f942056a145bc0b33f89b89cb2">&#9670;&nbsp;</a></span>Prediction() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Prediction </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>predictions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a38848bbc9246d0fcf34529517be92a13">EOutputFunction</a>&#160;</td>
          <td class="paramname"><em>f</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prediction based on activations stored in the last layer. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01132">1132</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a591f5bc896169cdb544475f5e64220ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a591f5bc896169cdb544475f5e64220ec">&#9670;&nbsp;</a></span>Prediction() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Prediction </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &amp;&#160;</td>
          <td class="paramname"><em>predictions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#af60370db07351a788ed14e24d8c2330f">Matrix_t</a> &gt;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a38848bbc9246d0fcf34529517be92a13">EOutputFunction</a>&#160;</td>
          <td class="paramname"><em>f</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prediction for the given inputs, based on what network learned. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01140">1140</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a47e33b3d7d72e61b4fda1c62ea19ab23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47e33b3d7d72e61b4fda1c62ea19ab23">&#9670;&nbsp;</a></span>Print()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Print </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Print the Deep <a class="el" href="classTMVA_1_1DNN_1_1Net.html" title="neural net ">Net</a> Info. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01150">1150</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a56a3ef68980a668f36711e9031f7d000"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a56a3ef68980a668f36711e9031f7d000">&#9670;&nbsp;</a></span>RegularizationTerm()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::RegularizationTerm </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for computing the regularizaton term to be added to the loss function. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01118">1118</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a06ec0245b44a5271f39864d5ce461468"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06ec0245b44a5271f39864d5ce461468">&#9670;&nbsp;</a></span>SetBatchDepth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetBatchDepth </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchDepth</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00328">328</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ae686bf847fb88ee6ed3561eb843ca41e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae686bf847fb88ee6ed3561eb843ca41e">&#9670;&nbsp;</a></span>SetBatchHeight()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetBatchHeight </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchHeight</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00329">329</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ab37b63fb66fa378fab2f84c343df3c7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab37b63fb66fa378fab2f84c343df3c7b">&#9670;&nbsp;</a></span>SetBatchSize()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetBatchSize </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchSize</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Setters. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00324">324</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="adef960d52b5f4a2e8875646e0e04c9af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adef960d52b5f4a2e8875646e0e04c9af">&#9670;&nbsp;</a></span>SetBatchWidth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetBatchWidth </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchWidth</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00330">330</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ae1d55bea8922ee2880565e888a23f0e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1d55bea8922ee2880565e888a23f0e9">&#9670;&nbsp;</a></span>SetDropoutProbabilities()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetDropoutProbabilities </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="RtypesCore_8h.html#ab9b5334647b78ec4256db251e3ae1fc6">Double_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>probabilities</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01169">1169</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aee4571ae71c4e5bc013226e8fc672604"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee4571ae71c4e5bc013226e8fc672604">&#9670;&nbsp;</a></span>SetInitialization()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetInitialization </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a>&#160;</td>
          <td class="paramname"><em>I</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00332">332</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a626c5e4ce181c4f5506e3028398615bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a626c5e4ce181c4f5506e3028398615bc">&#9670;&nbsp;</a></span>SetInputDepth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetInputDepth </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>inputDepth</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00325">325</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a808631744eb351530a08b6251cfd6350"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a808631744eb351530a08b6251cfd6350">&#9670;&nbsp;</a></span>SetInputHeight()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetInputHeight </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>inputHeight</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00326">326</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="af5b70cb9cb436be909f323249116e6cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5b70cb9cb436be909f323249116e6cc">&#9670;&nbsp;</a></span>SetInputWidth()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetInputWidth </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>inputWidth</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00327">327</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a0d8963df1df85b16b7eb399713646384"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d8963df1df85b16b7eb399713646384">&#9670;&nbsp;</a></span>SetLossFunction()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetLossFunction </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a>&#160;</td>
          <td class="paramname"><em>J</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00331">331</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ac27383d13ec157a90e6c4e66fc9acaf8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac27383d13ec157a90e6c4e66fc9acaf8">&#9670;&nbsp;</a></span>SetRegularization()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetRegularization </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a>&#160;</td>
          <td class="paramname"><em>R</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00333">333</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a4fee8e0cfe8f9845b83b10160a9175b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4fee8e0cfe8f9845b83b10160a9175b5">&#9670;&nbsp;</a></span>SetWeightDecay()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::SetWeightDecay </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>weightDecay</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00334">334</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ae80a47260da5b099c31de2ccf5d13cca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae80a47260da5b099c31de2ccf5d13cca">&#9670;&nbsp;</a></span>Update()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::Update </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>learningRate</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function that will update the weights and biases in the layers that contain weights and biases. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l01083">1083</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a3c6a5825de255f99cf31d10a663ddcdc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c6a5825de255f99cf31d10a663ddcdc">&#9670;&nbsp;</a></span>fBatchDepth</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fBatchDepth</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The depth of the batch used for training/testing. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00091">91</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a1130f1773d0370b3064ef7f1a0bf3030"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1130f1773d0370b3064ef7f1a0bf3030">&#9670;&nbsp;</a></span>fBatchHeight</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fBatchHeight</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The height of the batch used for training/testing. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00092">92</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a69400f97680efffa11752f22bb2e73af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69400f97680efffa11752f22bb2e73af">&#9670;&nbsp;</a></span>fBatchSize</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fBatchSize</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><a class="el" href="classTMVA_1_1DNN_1_1Batch.html" title="The Batch class encapsulates one mini-batch. ">Batch</a> size used for training and evaluation. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00086">86</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ace43ba7bfdfd9c2c18d14d94f6aaae7f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace43ba7bfdfd9c2c18d14d94f6aaae7f">&#9670;&nbsp;</a></span>fBatchWidth</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fBatchWidth</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The width of the batch used for training/testing. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00093">93</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="afe035f843024e67b122f45bf046cfe63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe035f843024e67b122f45bf046cfe63">&#9670;&nbsp;</a></span>fI</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceTMVA_1_1DNN.html#a049d2f0cfa299ef98834e42202151279">EInitialization</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fI</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The initialization method of the network. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00098">98</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a434a8e970aba0664cf4508faa1ddd79d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a434a8e970aba0664cf4508faa1ddd79d">&#9670;&nbsp;</a></span>fInputDepth</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fInputDepth</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The depth of the input. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00087">87</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="abc12296a260f5cdd610b851dc5793381"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc12296a260f5cdd610b851dc5793381">&#9670;&nbsp;</a></span>fInputHeight</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fInputHeight</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The height of the input. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00088">88</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a78bd3820cf699e7df55df8f3f3bc2377"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a78bd3820cf699e7df55df8f3f3bc2377">&#9670;&nbsp;</a></span>fInputWidth</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fInputWidth</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The width of the input. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00089">89</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aafa5d707713a8f6d09b254822c75c119"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aafa5d707713a8f6d09b254822c75c119">&#9670;&nbsp;</a></span>fIsTraining</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fIsTraining</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Is the network training? </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00095">95</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="ad28844e15b7a8a71f8a7fdd08d2d71af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad28844e15b7a8a71f8a7fdd08d2d71af">&#9670;&nbsp;</a></span>fJ</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceTMVA_1_1DNN.html#a76d8bf2cef401425abc0d35935309dab">ELossFunction</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fJ</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The loss function of the network. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00097">97</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a382f7265cc1591308b47255820b02664"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a382f7265cc1591308b47255820b02664">&#9670;&nbsp;</a></span>fLayers</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;Layer_t *&gt; <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fLayers</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The layers consisting the DeepNet. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00084">84</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="aa332ceb5248fad2e6cd179fbe98c508c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa332ceb5248fad2e6cd179fbe98c508c">&#9670;&nbsp;</a></span>fR</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceTMVA_1_1DNN.html#a64325c2ac191062b28a7da62a3f63a21">ERegularization</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fR</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The regularization used for the network. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00099">99</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<a id="a9688dbd9515c9011ccbb54568a2ff7c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9688dbd9515c9011ccbb54568a2ff7c4">&#9670;&nbsp;</a></span>fWeightDecay</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html#a1e3ce10d7bbd9c2b8559330289ccfdbf">Scalar_t</a> <a class="el" href="classTMVA_1_1DNN_1_1TDeepNet.html">TMVA::DNN::TDeepNet</a>&lt; Architecture_t, Layer_t &gt;::fWeightDecay</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The weight decay factor. </p>

<p class="definition">Definition at line <a class="el" href="DeepNet_8h_source.html#l00100">100</a> of file <a class="el" href="DeepNet_8h_source.html">DeepNet.h</a>.</p>

</div>
</div>
<div class="dynheader">
</div>
<div class="dyncontent">
</div><hr/>The documentation for this class was generated from the following file:<ul>
<li>tmva/tmva/inc/TMVA/DNN/<a class="el" href="DeepNet_8h_source.html">DeepNet.h</a></li>
</ul>
</div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:12:02 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
