<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: tutorials/tmva/TMVAClassification.C File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_0d353d24d0afa59909efab6593124f6d.html">tutorials</a></li><li class="navelem"><a class="el" href="dir_57937f7cf6e069c092300443fa5e4440.html">tmva</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">TMVAClassification.C File Reference<div class="ingroups"><a class="el" href="group__Tutorials.html">Tutorials</a> &raquo; <a class="el" href="group__tutorial__tmva.html">TMVA tutorials</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p> <a href="http://nbviewer.jupyter.org/url/root.cern.ch/doc/master/notebooks/TMVAClassification.C.nbconvert.ipynb" target="_blank"><img src= notebook.gif alt="View in nbviewer" style="height:1em" ></a> <a href="https://cern.ch/swanserver/cgi-bin/go?projurl=https://root.cern.ch/doc/master/notebooks/TMVAClassification.C.nbconvert.ipynb" target="_blank"><img src="http://swanserver.web.cern.ch/swanserver/images/badge_swan_white_150.png"  alt="Open in SWAN" style="height:1em" ></a>  This macro provides examples for the training and testing of the TMVA classifiers. </p>
<p>As input data is used a toy-MC sample consisting of four Gaussian-distributed and linearly correlated input variables. The methods to be used can be switched on and off by means of booleans, or via the prompt command, for example: </p><pre class="fragment">root -l ./TMVAClassification.C\(\"Fisher,Likelihood\"\)
</pre><p>(note that the backslashes are mandatory) If no method given, a default set of classifiers is used. The output file "TMVA.root" can be analysed with the use of dedicated macros (simply say: root -l &lt;macro.C&gt;), which can be conveniently invoked through a GUI that will appear at the end of the run of this macro. Launch the GUI via the command: </p><pre class="fragment">root -l ./TMVAGui.C
</pre><p>You can also compile and run the example with the following commands </p><pre class="fragment">make
./TMVAClassification &lt;Methods&gt;
</pre><p>where: <code>&lt;Methods&gt; = "method1 method2"</code> are the TMVA classifier names example: </p><pre class="fragment">./TMVAClassification Fisher LikelihoodPCA BDT
</pre><p>If no method given, a default set is of classifiers is used</p>
<ul>
<li>Project : TMVA - a ROOT-integrated toolkit for multivariate data analysis</li>
<li>Package : TMVA</li>
<li>Root Macro: TMVAClassification</li>
</ul>
<div class="fragment"><div class="line"></div><div class="line"></div><div class="line">==&gt; Start TMVAClassification</div><div class="line">--- TMVAClassification       : Using input file: ./files/tmva_class_example.root</div><div class="line">DataSetInfo              : [dataset] : Added class &quot;Signal&quot;</div><div class="line">                         : Add Tree TreeS of type Signal with 6000 events</div><div class="line">DataSetInfo              : [dataset] : Added class &quot;Background&quot;</div><div class="line">                         : Add Tree TreeB of type Background with 6000 events</div><div class="line">Factory                  : Booking method: [1mCuts[0m</div><div class="line">                         : </div><div class="line">                         : Use optimization method: &quot;Monte Carlo&quot;</div><div class="line">                         : Use efficiency computation method: &quot;Event Selection&quot;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;myvar1&#39;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;myvar2&#39;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;var3&#39;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;var4&#39;</div><div class="line">Factory                  : Booking method: [1mCutsD[0m</div><div class="line">                         : </div><div class="line">CutsD                    : [dataset] : Create Transformation &quot;Decorrelate&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">                         : Use optimization method: &quot;Monte Carlo&quot;</div><div class="line">                         : Use efficiency computation method: &quot;Event Selection&quot;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;myvar1&#39;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;myvar2&#39;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;var3&#39;</div><div class="line">                         : Use &quot;FSmart&quot; cuts for variable: &#39;var4&#39;</div><div class="line">Factory                  : Booking method: [1mLikelihood[0m</div><div class="line">                         : </div><div class="line">Factory                  : Booking method: [1mLikelihoodPCA[0m</div><div class="line">                         : </div><div class="line">LikelihoodPCA            : [dataset] : Create Transformation &quot;PCA&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">Factory                  : Booking method: [1mPDERS[0m</div><div class="line">                         : </div><div class="line">Factory                  : Booking method: [1mPDEFoam[0m</div><div class="line">                         : </div><div class="line">Factory                  : Booking method: [1mKNN[0m</div><div class="line">                         : </div><div class="line">Factory                  : Booking method: [1mLD[0m</div><div class="line">                         : </div><div class="line">DataSetFactory           : [dataset] : Number of events in input trees</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : Number of training and testing events</div><div class="line">                         : ---------------------------------------------------------------------------</div><div class="line">                         : Signal     -- training events            : 1000</div><div class="line">                         : Signal     -- testing events             : 5000</div><div class="line">                         : Signal     -- training and testing events: 6000</div><div class="line">                         : Background -- training events            : 1000</div><div class="line">                         : Background -- testing events             : 5000</div><div class="line">                         : Background -- training and testing events: 6000</div><div class="line">                         : </div><div class="line">DataSetInfo              : Correlation matrix (Signal):</div><div class="line">                         : ----------------------------------------------</div><div class="line">                         :            var1+var2 var1-var2    var3    var4</div><div class="line">                         : var1+var2:    +1.000    +0.038  +0.748  +0.922</div><div class="line">                         : var1-var2:    +0.038    +1.000  -0.058  +0.128</div><div class="line">                         :      var3:    +0.748    -0.058  +1.000  +0.831</div><div class="line">                         :      var4:    +0.922    +0.128  +0.831  +1.000</div><div class="line">                         : ----------------------------------------------</div><div class="line">DataSetInfo              : Correlation matrix (Background):</div><div class="line">                         : ----------------------------------------------</div><div class="line">                         :            var1+var2 var1-var2    var3    var4</div><div class="line">                         : var1+var2:    +1.000    -0.021  +0.783  +0.931</div><div class="line">                         : var1-var2:    -0.021    +1.000  -0.162  +0.057</div><div class="line">                         :      var3:    +0.783    -0.162  +1.000  +0.841</div><div class="line">                         :      var4:    +0.931    +0.057  +0.841  +1.000</div><div class="line">                         : ----------------------------------------------</div><div class="line">DataSetFactory           : [dataset] :  </div><div class="line">                         : </div><div class="line">Factory                  : Booking method: [1mFDA_GA[0m</div><div class="line">                         : </div><div class="line">                         : Create parameter interval for parameter 0 : [-1,1]</div><div class="line">                         : Create parameter interval for parameter 1 : [-10,10]</div><div class="line">                         : Create parameter interval for parameter 2 : [-10,10]</div><div class="line">                         : Create parameter interval for parameter 3 : [-10,10]</div><div class="line">                         : Create parameter interval for parameter 4 : [-10,10]</div><div class="line">                         : User-defined formula string       : &quot;(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3&quot;</div><div class="line">                         : TFormula-compatible formula string: &quot;[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]&quot;</div><div class="line">Factory                  : Booking method: [1mMLPBNN[0m</div><div class="line">                         : </div><div class="line">MLPBNN                   : [dataset] : Create Transformation &quot;N&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">MLPBNN                   : Building Network. </div><div class="line">                         : Initializing weights</div><div class="line">Factory                  : Booking method: [1mDNN_CPU[0m</div><div class="line">                         : </div><div class="line">                         : Parsing option string: </div><div class="line">                         : ... &quot;!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=30,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5, Multithreading=True|LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True|LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True:Architecture=CPU&quot;</div><div class="line">                         : The following options are set:</div><div class="line">                         : - By User:</div><div class="line">                         :     &lt;none&gt;</div><div class="line">                         : - Default:</div><div class="line">                         :     Boost_num: &quot;0&quot; [Number of times the classifier will be boosted]</div><div class="line">                         : Parsing option string: </div><div class="line">                         : ... &quot;!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=30,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5, Multithreading=True|LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True|LearningRate=1e-3,Momentum=0.0,Repetitions=1,ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=L2,DropConfig=0.0+0.0+0.0+0.0, Multithreading=True:Architecture=CPU&quot;</div><div class="line">                         : The following options are set:</div><div class="line">                         : - By User:</div><div class="line">                         :     V: &quot;True&quot; [Verbose output (short form of &quot;VerbosityLevel&quot; below - overrides the latter one)]</div><div class="line">                         :     VarTransform: &quot;N&quot; [List of variable transformations performed before training, e.g., &quot;D_Background,P_Signal,G,N_AllClasses&quot; for: &quot;Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events (&#39;AllClasses&#39; denotes all events of all classes, if no class indication is given, &#39;All&#39; is assumed)&quot;]</div><div class="line">                         :     H: &quot;False&quot; [Print method-specific help message]</div><div class="line">                         :     Layout: &quot;TANH|128,TANH|128,TANH|128,LINEAR&quot; [Layout of the network.]</div><div class="line">                         :     ErrorStrategy: &quot;CROSSENTROPY&quot; [Loss function: Mean squared error (regression) or cross entropy (binary classification).]</div><div class="line">                         :     WeightInitialization: &quot;XAVIERUNIFORM&quot; [Weight initialization strategy]</div><div class="line">                         :     Architecture: &quot;CPU&quot; [Which architecture to perform the training on.]</div><div class="line">                         :     TrainingStrategy: &quot;LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=30,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5,&quot; [Defines the training strategies.]</div><div class="line">                         : - Default:</div><div class="line">                         :     VerbosityLevel: &quot;Default&quot; [Verbosity level]</div><div class="line">                         :     CreateMVAPdfs: &quot;False&quot; [Create PDFs for classifier outputs (signal and background)]</div><div class="line">                         :     IgnoreNegWeightsInTraining: &quot;False&quot; [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]</div><div class="line">                         :     InputLayout: &quot;0|0|0&quot; [The Layout of the input]</div><div class="line">                         :     BatchLayout: &quot;0|0|0&quot; [The Layout of the batch]</div><div class="line">                         :     RandomSeed: &quot;0&quot; [Random seed used for weight initialization and batch shuffling]</div><div class="line">                         :     ValidationSize: &quot;20%&quot; [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]</div><div class="line">DNN_CPU                  : [dataset] : Create Transformation &quot;N&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">                         : Will use now the CPU architecture !</div><div class="line">Factory                  : Booking method: [1mSVM[0m</div><div class="line">                         : </div><div class="line">SVM                      : [dataset] : Create Transformation &quot;Norm&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">Factory                  : Booking method: [1mBDT[0m</div><div class="line">                         : </div><div class="line">Factory                  : Booking method: [1mRuleFit[0m</div><div class="line">                         : </div><div class="line">Factory                  : [1mTrain all methods[0m</div><div class="line">Factory                  : [dataset] : Create Transformation &quot;I&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">Factory                  : [dataset] : Create Transformation &quot;D&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">Factory                  : [dataset] : Create Transformation &quot;P&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">Factory                  : [dataset] : Create Transformation &quot;G&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">Factory                  : [dataset] : Create Transformation &quot;D&quot; with events from all classes.</div><div class="line">                         : </div><div class="line">                         : Transformation, Variable selection : </div><div class="line">                         : Input : variable &#39;myvar1&#39; &lt;---&gt; Output : variable &#39;myvar1&#39;</div><div class="line">                         : Input : variable &#39;myvar2&#39; &lt;---&gt; Output : variable &#39;myvar2&#39;</div><div class="line">                         : Input : variable &#39;var3&#39; &lt;---&gt; Output : variable &#39;var3&#39;</div><div class="line">                         : Input : variable &#39;var4&#39; &lt;---&gt; Output : variable &#39;var4&#39;</div><div class="line">TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:  -0.062775     1.7187   [    -9.3380     7.6931 ]</div><div class="line">                         :   myvar2:   0.056495     1.0784   [    -3.2551     4.0291 ]</div><div class="line">                         :     var3:  -0.020366     1.0633   [    -5.2777     4.6430 ]</div><div class="line">                         :     var4:    0.13214     1.2464   [    -5.6007     4.6744 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Preparing the Decorrelation transformation...</div><div class="line">TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]</div><div class="line">                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]</div><div class="line">                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]</div><div class="line">                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Preparing the Principle Component (PCA) transformation...</div><div class="line">TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.11433     2.2714   [    -11.272     9.0916 ]</div><div class="line">                         :   myvar2: -0.0070834     1.0934   [    -3.9875     3.3836 ]</div><div class="line">                         :     var3:   0.011107    0.57824   [    -2.0171     2.1958 ]</div><div class="line">                         :     var4: -0.0094450    0.33437   [    -1.0176     1.0617 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Preparing the Gaussian transformation...</div><div class="line">                         : Preparing the Decorrelation transformation...</div><div class="line">TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:  -0.054412     1.0000   [    -3.0924     8.1350 ]</div><div class="line">                         :   myvar2: -0.0021417     1.0000   [    -4.5913     5.6461 ]</div><div class="line">                         :     var3: -0.0051998     1.0000   [    -3.1457     4.6043 ]</div><div class="line">                         :     var4:   0.074624     1.0000   [    -3.4587     5.9397 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Ranking input variables (method unspecific)...</div><div class="line">IdTransformation         : Ranking result (top variable is best ranked)</div><div class="line">                         : -------------------------------------</div><div class="line">                         : Rank : Variable     : Separation</div><div class="line">                         : -------------------------------------</div><div class="line">                         :    1 : Variable 4   : 2.843e-01</div><div class="line">                         :    2 : Variable 3   : 1.756e-01</div><div class="line">                         :    3 : myvar1       : 1.018e-01</div><div class="line">                         :    4 : Expression 2 : 3.860e-02</div><div class="line">                         : -------------------------------------</div><div class="line">Factory                  : Train method: Cuts for Classification</div><div class="line">                         : </div><div class="line">FitterBase               : &lt;MCFitter&gt; Sampling, please be patient ...</div><div class="line">                         : Elapsed time: 3.33 sec                           </div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.1</div><div class="line">                         : Corresponding background efficiency       : 0.00621902</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -1.19223 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=      2.126</div><div class="line">                         : Cut[ 2]:   -2.90978 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:    2.16207 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.2</div><div class="line">                         : Corresponding background efficiency       : 0.0171253</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -5.85714 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    2.21109</div><div class="line">                         : Cut[ 2]:  -0.759439 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:    1.66846 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.3</div><div class="line">                         : Corresponding background efficiency       : 0.0401486</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -6.09813 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    2.81831</div><div class="line">                         : Cut[ 2]:   -2.09336 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:    1.34308 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.4</div><div class="line">                         : Corresponding background efficiency       : 0.062887</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -4.55141 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    2.94573</div><div class="line">                         : Cut[ 2]:   -4.68697 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:    1.07157 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.5</div><div class="line">                         : Corresponding background efficiency       : 0.104486</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -5.86032 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    2.89615</div><div class="line">                         : Cut[ 2]:  -0.966191 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.773848 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.6</div><div class="line">                         : Corresponding background efficiency       : 0.172806</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -5.52552 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    4.08498</div><div class="line">                         : Cut[ 2]:   -2.61706 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.469684 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.7</div><div class="line">                         : Corresponding background efficiency       : 0.258379</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -5.69875 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    1.73784</div><div class="line">                         : Cut[ 2]:   -1.21467 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.109026 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.8</div><div class="line">                         : Corresponding background efficiency       : 0.362964</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -1.99372 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    3.93767</div><div class="line">                         : Cut[ 2]:   -1.56317 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:  -0.124013 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : ------------------------------------------</div><div class="line">Cuts                     : Cut values for requested signal efficiency: 0.9</div><div class="line">                         : Corresponding background efficiency       : 0.503885</div><div class="line">                         : Transformation applied to input variables : None</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Cut[ 0]:   -3.97304 &lt; myvar1 &lt;=      1e+30</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt; myvar2 &lt;=    3.31284</div><div class="line">                         : Cut[ 2]:   -2.82879 &lt;   var3 &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:  -0.577302 &lt;   var4 &lt;=      1e+30</div><div class="line">                         : ------------------------------------------</div><div class="line">                         : Elapsed time for training with 2000 events: 3.33 sec         </div><div class="line">Cuts                     : [dataset] : Evaluation of Cuts on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00121 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_Cuts.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_Cuts.class.C[0m</div><div class="line">                         : TMVA.root:/dataset/Method_Cuts/Cuts</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: CutsD for Classification</div><div class="line">                         : </div><div class="line">                         : Preparing the Decorrelation transformation...</div><div class="line">TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]</div><div class="line">                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]</div><div class="line">                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]</div><div class="line">                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]</div><div class="line">                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]</div><div class="line">                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]</div><div class="line">                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">FitterBase               : &lt;MCFitter&gt; Sampling, please be patient ...</div><div class="line">                         : Elapsed time: 2.58 sec                           </div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.1</div><div class="line">                         : Corresponding background efficiency       : 0</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=   0.513038</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=  -0.733858</div><div class="line">                         : Cut[ 2]:   -0.87113 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.687739 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.2</div><div class="line">                         : Corresponding background efficiency       : 0.000493656</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    1.60056</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    1.26936</div><div class="line">                         : Cut[ 2]:   -1.50073 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:    1.54845 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.3</div><div class="line">                         : Corresponding background efficiency       : 0.00334252</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    2.16898</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    3.25932</div><div class="line">                         : Cut[ 2]:   -2.08503 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:    1.43959 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.4</div><div class="line">                         : Corresponding background efficiency       : 0.00821453</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=     1.9086</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    1.94778</div><div class="line">                         : Cut[ 2]:   -2.11471 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:     1.1885 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.5</div><div class="line">                         : Corresponding background efficiency       : 0.0209024</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    3.97301</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    2.87835</div><div class="line">                         : Cut[ 2]:   -1.68889 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.969507 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.6</div><div class="line">                         : Corresponding background efficiency       : 0.055037</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    2.57624</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    2.20263</div><div class="line">                         : Cut[ 2]:   -3.86902 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.802122 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.7</div><div class="line">                         : Corresponding background efficiency       : 0.0975699</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    3.65719</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    3.19411</div><div class="line">                         : Cut[ 2]:   -2.87372 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.583961 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.8</div><div class="line">                         : Corresponding background efficiency       : 0.170999</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    4.74857</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    2.75269</div><div class="line">                         : Cut[ 2]:   -3.22043 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:   0.327788 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">CutsD                    : Cut values for requested signal efficiency: 0.9</div><div class="line">                         : Corresponding background efficiency       : 0.326977</div><div class="line">                         : Transformation applied to input variables : &quot;Deco&quot;</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Cut[ 0]:     -1e+30 &lt;  +     1.1476*[myvar1] +   0.027923*[myvar2] -    0.19981*[var3] -    0.82843*[var4] &lt;=    3.56614</div><div class="line">                         : Cut[ 1]:     -1e+30 &lt;  +   0.027923*[myvar1] +    0.95469*[myvar2] +    0.18581*[var3] -     0.1623*[var4] &lt;=    3.09071</div><div class="line">                         : Cut[ 2]:    -3.9944 &lt;  -    0.19981*[myvar1] +    0.18581*[myvar2] +     1.7913*[var3] -    0.77231*[var4] &lt;=      1e+30</div><div class="line">                         : Cut[ 3]:  0.0311777 &lt;  -    0.82843*[myvar1] -     0.1623*[myvar2] -    0.77231*[var3] +     2.1918*[var4] &lt;=      1e+30</div><div class="line">                         : ------------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : Elapsed time for training with 2000 events: 2.58 sec         </div><div class="line">CutsD                    : [dataset] : Evaluation of CutsD on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00236 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_CutsD.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_CutsD.class.C[0m</div><div class="line">                         : TMVA.root:/dataset/Method_Cuts/CutsD</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: Likelihood for Classification</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : [1mH e l p   f o r   M V A   m e t h o d   [ Likelihood ] :[0m</div><div class="line">                         : </div><div class="line">                         : [1m--- Short description:[0m</div><div class="line">                         : </div><div class="line">                         : The maximum-likelihood classifier models the data with probability </div><div class="line">                         : density functions (PDF) reproducing the signal and background</div><div class="line">                         : distributions of the input variables. Correlations among the </div><div class="line">                         : variables are ignored.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance optimisation:[0m</div><div class="line">                         : </div><div class="line">                         : Required for good performance are decorrelated input variables</div><div class="line">                         : (PCA transformation via the option &quot;VarTransform=Decorrelate&quot;</div><div class="line">                         : may be tried). Irreducible non-linear correlations may be reduced</div><div class="line">                         : by precombining strongly correlated input variables, or by simply</div><div class="line">                         : removing one of the variables.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance tuning via configuration options:[0m</div><div class="line">                         : </div><div class="line">                         : High fidelity PDF estimates are mandatory, i.e., sufficient training </div><div class="line">                         : statistics is required to populate the tails of the distributions</div><div class="line">                         : It would be a surprise if the default Spline or KDE kernel parameters</div><div class="line">                         : provide a satisfying fit to the data. The user is advised to properly</div><div class="line">                         : tune the events per bin and smooth options in the spline cases</div><div class="line">                         : individually per variable. If the KDE kernel is used, the adaptive</div><div class="line">                         : Gaussian kernel may lead to artefacts, so please always also try</div><div class="line">                         : the non-adaptive one.</div><div class="line">                         : </div><div class="line">                         : All tuning parameters must be adjusted individually for each input</div><div class="line">                         : variable!</div><div class="line">                         : </div><div class="line">                         : &lt;Suppress this message by specifying &quot;!H&quot; in the booking option&gt;</div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : </div><div class="line">                         : Filling reference histograms</div><div class="line">                         : Building PDF out of reference histograms</div><div class="line">                         : Elapsed time for training with 2000 events: 0.0135 sec         </div><div class="line">Likelihood               : [dataset] : Evaluation of Likelihood on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00315 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_Likelihood.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_Likelihood.class.C[0m</div><div class="line">                         : TMVA.root:/dataset/Method_Likelihood/Likelihood</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: LikelihoodPCA for Classification</div><div class="line">                         : </div><div class="line">                         : Preparing the Principle Component (PCA) transformation...</div><div class="line">TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.11433     2.2714   [    -11.272     9.0916 ]</div><div class="line">                         :   myvar2: -0.0070834     1.0934   [    -3.9875     3.3836 ]</div><div class="line">                         :     var3:   0.011107    0.57824   [    -2.0171     2.1958 ]</div><div class="line">                         :     var4: -0.0094450    0.33437   [    -1.0176     1.0617 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Filling reference histograms</div><div class="line">                         : Building PDF out of reference histograms</div><div class="line">                         : Elapsed time for training with 2000 events: 0.0145 sec         </div><div class="line">LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00482 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_LikelihoodPCA.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_LikelihoodPCA.class.C[0m</div><div class="line">                         : TMVA.root:/dataset/Method_Likelihood/LikelihoodPCA</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: PDERS for Classification</div><div class="line">                         : </div><div class="line">                         : Elapsed time for training with 2000 events: 0.00341 sec         </div><div class="line">PDERS                    : [dataset] : Evaluation of PDERS on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.25 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PDERS.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PDERS.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: PDEFoam for Classification</div><div class="line">                         : </div><div class="line">PDEFoam                  : NormMode=NUMEVENTS chosen. Note that only NormMode=EqualNumEvents ensures that Discriminant values correspond to signal probabilities.</div><div class="line">                         : Build up discriminator foam</div><div class="line">                         : Elapsed time: 0.312 sec                                 </div><div class="line">                         : Elapsed time for training with 2000 events: 0.354 sec         </div><div class="line">PDEFoam                  : [dataset] : Evaluation of PDEFoam on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.0166 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PDEFoam.weights.xml[0m</div><div class="line">                         : writing foam DiscrFoam to file</div><div class="line">                         : Foams written to file: [0;36mdataset/weights/TMVAClassification_PDEFoam.weights_foams.root[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PDEFoam.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: KNN for Classification</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : [1mH e l p   f o r   M V A   m e t h o d   [ KNN ] :[0m</div><div class="line">                         : </div><div class="line">                         : [1m--- Short description:[0m</div><div class="line">                         : </div><div class="line">                         : The k-nearest neighbor (k-NN) algorithm is a multi-dimensional classification</div><div class="line">                         : and regression algorithm. Similarly to other TMVA algorithms, k-NN uses a set of</div><div class="line">                         : training events for which a classification category/regression target is known. </div><div class="line">                         : The k-NN method compares a test event to all training events using a distance </div><div class="line">                         : function, which is an Euclidean distance in a space defined by the input variables. </div><div class="line">                         : The k-NN method, as implemented in TMVA, uses a kd-tree algorithm to perform a</div><div class="line">                         : quick search for the k events with shortest distance to the test event. The method</div><div class="line">                         : returns a fraction of signal events among the k neighbors. It is recommended</div><div class="line">                         : that a histogram which stores the k-NN decision variable is binned with k+1 bins</div><div class="line">                         : between 0 and 1.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance tuning via configuration options: [0m</div><div class="line">                         : </div><div class="line">                         : The k-NN method estimates a density of signal and background events in a </div><div class="line">                         : neighborhood around the test event. The method assumes that the density of the </div><div class="line">                         : signal and background events is uniform and constant within the neighborhood. </div><div class="line">                         : k is an adjustable parameter and it determines an average size of the </div><div class="line">                         : neighborhood. Small k values (less than 10) are sensitive to statistical </div><div class="line">                         : fluctuations and large (greater than 100) values might not sufficiently capture  </div><div class="line">                         : local differences between events in the training set. The speed of the k-NN</div><div class="line">                         : method also increases with larger values of k. </div><div class="line">                         : </div><div class="line">                         : The k-NN method assigns equal weight to all input variables. Different scales </div><div class="line">                         : among the input variables is compensated using ScaleFrac parameter: the input </div><div class="line">                         : variables are scaled so that the widths for central ScaleFrac*100% events are </div><div class="line">                         : equal among all the input variables.</div><div class="line">                         : </div><div class="line">                         : [1m--- Additional configuration options: [0m</div><div class="line">                         : </div><div class="line">                         : The method inclues an option to use a Gaussian kernel to smooth out the k-NN</div><div class="line">                         : response. The kernel re-weights events using a distance to the test event.</div><div class="line">                         : </div><div class="line">                         : &lt;Suppress this message by specifying &quot;!H&quot; in the booking option&gt;</div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : </div><div class="line">KNN                      : &lt;Train&gt; start...</div><div class="line">                         : Reading 2000 events</div><div class="line">                         : Number of signal events 1000</div><div class="line">                         : Number of background events 1000</div><div class="line">                         : Creating kd-tree with 2000 events</div><div class="line">                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)</div><div class="line">ModulekNN                : Optimizing tree for 4 variables with 2000 values</div><div class="line">                         : &lt;Fill&gt; Class 1 has     1000 events</div><div class="line">                         : &lt;Fill&gt; Class 2 has     1000 events</div><div class="line">                         : Elapsed time for training with 2000 events: 0.00273 sec         </div><div class="line">KNN                      : [dataset] : Evaluation of KNN on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.046 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_KNN.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_KNN.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: LD for Classification</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : [1mH e l p   f o r   M V A   m e t h o d   [ LD ] :[0m</div><div class="line">                         : </div><div class="line">                         : [1m--- Short description:[0m</div><div class="line">                         : </div><div class="line">                         : Linear discriminants select events by distinguishing the mean </div><div class="line">                         : values of the signal and background distributions in a trans- </div><div class="line">                         : formed variable space where linear correlations are removed.</div><div class="line">                         : The LD implementation here is equivalent to the &quot;Fisher&quot; discriminant</div><div class="line">                         : for classification, but also provides linear regression.</div><div class="line">                         : </div><div class="line">                         :    (More precisely: the &quot;linear discriminator&quot; determines</div><div class="line">                         :     an axis in the (correlated) hyperspace of the input </div><div class="line">                         :     variables such that, when projecting the output classes </div><div class="line">                         :     (signal and background) upon this axis, they are pushed </div><div class="line">                         :     as far as possible away from each other, while events</div><div class="line">                         :     of a same class are confined in a close vicinity. The  </div><div class="line">                         :     linearity property of this classifier is reflected in the </div><div class="line">                         :     metric with which &quot;far apart&quot; and &quot;close vicinity&quot; are </div><div class="line">                         :     determined: the covariance matrix of the discriminating</div><div class="line">                         :     variable space.)</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance optimisation:[0m</div><div class="line">                         : </div><div class="line">                         : Optimal performance for the linear discriminant is obtained for </div><div class="line">                         : linearly correlated Gaussian-distributed variables. Any deviation</div><div class="line">                         : from this ideal reduces the achievable separation power. In </div><div class="line">                         : particular, no discrimination at all is achieved for a variable</div><div class="line">                         : that has the same sample mean for signal and background, even if </div><div class="line">                         : the shapes of the distributions are very different. Thus, the linear </div><div class="line">                         : discriminant often benefits from a suitable transformation of the </div><div class="line">                         : input variables. For example, if a variable x in [-1,1] has a </div><div class="line">                         : a parabolic signal distributions, and a uniform background</div><div class="line">                         : distributions, their mean value is zero in both cases, leading </div><div class="line">                         : to no separation. The simple transformation x -&gt; |x| renders this </div><div class="line">                         : variable powerful for the use in a linear discriminant.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance tuning via configuration options:[0m</div><div class="line">                         : </div><div class="line">                         : &lt;None&gt;</div><div class="line">                         : </div><div class="line">                         : &lt;Suppress this message by specifying &quot;!H&quot; in the booking option&gt;</div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : </div><div class="line">LD                       : Results for LD coefficients:</div><div class="line">                         : -----------------------</div><div class="line">                         : Variable:  Coefficient:</div><div class="line">                         : -----------------------</div><div class="line">                         :   myvar1:       -0.309</div><div class="line">                         :   myvar2:       -0.102</div><div class="line">                         :     var3:       -0.142</div><div class="line">                         :     var4:       +0.705</div><div class="line">                         : (offset):       -0.055</div><div class="line">                         : -----------------------</div><div class="line">                         : Elapsed time for training with 2000 events: 0.000937 sec         </div><div class="line">LD                       : [dataset] : Evaluation of LD on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00144 sec       </div><div class="line">                         : &lt;CreateMVAPdfs&gt; Separation from histogram (PDF): 0.540 (0.000)</div><div class="line">                         : Dataset[dataset] : Evaluation of LD on training sample</div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_LD.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_LD.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: FDA_GA for Classification</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : [1mH e l p   f o r   M V A   m e t h o d   [ FDA_GA ] :[0m</div><div class="line">                         : </div><div class="line">                         : [1m--- Short description:[0m</div><div class="line">                         : </div><div class="line">                         : The function discriminant analysis (FDA) is a classifier suitable </div><div class="line">                         : to solve linear or simple nonlinear discrimination problems.</div><div class="line">                         : </div><div class="line">                         : The user provides the desired function with adjustable parameters</div><div class="line">                         : via the configuration option string, and FDA fits the parameters to</div><div class="line">                         : it, requiring the signal (background) function value to be as close</div><div class="line">                         : as possible to 1 (0). Its advantage over the more involved and</div><div class="line">                         : automatic nonlinear discriminators is the simplicity and transparency </div><div class="line">                         : of the discrimination expression. A shortcoming is that FDA will</div><div class="line">                         : underperform for involved problems with complicated, phase space</div><div class="line">                         : dependent nonlinear correlations.</div><div class="line">                         : </div><div class="line">                         : Please consult the Users Guide for the format of the formula string</div><div class="line">                         : and the allowed parameter ranges:</div><div class="line">                         : http://tmva.sourceforge.net/docu/TMVAUsersGuide.pdf</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance optimisation:[0m</div><div class="line">                         : </div><div class="line">                         : The FDA performance depends on the complexity and fidelity of the</div><div class="line">                         : user-defined discriminator function. As a general rule, it should</div><div class="line">                         : be able to reproduce the discrimination power of any linear</div><div class="line">                         : discriminant analysis. To reach into the nonlinear domain, it is</div><div class="line">                         : useful to inspect the correlation profiles of the input variables,</div><div class="line">                         : and add quadratic and higher polynomial terms between variables as</div><div class="line">                         : necessary. Comparison with more involved nonlinear classifiers can</div><div class="line">                         : be used as a guide.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance tuning via configuration options:[0m</div><div class="line">                         : </div><div class="line">                         : Depending on the function used, the choice of &quot;FitMethod&quot; is</div><div class="line">                         : crucial for getting valuable solutions with FDA. As a guideline it</div><div class="line">                         : is recommended to start with &quot;FitMethod=MINUIT&quot;. When more complex</div><div class="line">                         : functions are used where MINUIT does not converge to reasonable</div><div class="line">                         : results, the user should switch to non-gradient FitMethods such</div><div class="line">                         : as GeneticAlgorithm (GA) or Monte Carlo (MC). It might prove to be</div><div class="line">                         : useful to combine GA (or MC) with MINUIT by setting the option</div><div class="line">                         : &quot;Converger=MINUIT&quot;. GA (MC) will then set the starting parameters</div><div class="line">                         : for MINUIT such that the basic quality of GA (MC) of finding global</div><div class="line">                         : minima is combined with the efficacy of MINUIT of finding local</div><div class="line">                         : minima.</div><div class="line">                         : </div><div class="line">                         : &lt;Suppress this message by specifying &quot;!H&quot; in the booking option&gt;</div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : </div><div class="line">FitterBase               : &lt;GeneticFitter&gt; Optimisation, please be patient ... (inaccurate progress timing for GA)</div><div class="line">                         : Elapsed time: 0.712 sec                            </div><div class="line">FDA_GA                   : Results for parameter fit using &quot;GA&quot; fitter:</div><div class="line">                         : -----------------------</div><div class="line">                         : Parameter:  Fit result:</div><div class="line">                         : -----------------------</div><div class="line">                         :    Par(0):    0.428106</div><div class="line">                         :    Par(1):           0</div><div class="line">                         :    Par(2):           0</div><div class="line">                         :    Par(3):   -0.328821</div><div class="line">                         :    Par(4):    0.536921</div><div class="line">                         : -----------------------</div><div class="line">                         : Discriminator expression: &quot;(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3&quot;</div><div class="line">                         : Value of estimator at minimum: 0.417329</div><div class="line">                         : Elapsed time for training with 2000 events: 0.744 sec         </div><div class="line">FDA_GA                   : [dataset] : Evaluation of FDA_GA on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00261 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_FDA_GA.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_FDA_GA.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: MLPBNN for Classification</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : [1mH e l p   f o r   M V A   m e t h o d   [ MLPBNN ] :[0m</div><div class="line">                         : </div><div class="line">                         : [1m--- Short description:[0m</div><div class="line">                         : </div><div class="line">                         : The MLP artificial neural network (ANN) is a traditional feed-</div><div class="line">                         : forward multilayer perceptron implementation. The MLP has a user-</div><div class="line">                         : defined hidden layer architecture, while the number of input (output)</div><div class="line">                         : nodes is determined by the input variables (output classes, i.e., </div><div class="line">                         : signal and one background). </div><div class="line">                         : </div><div class="line">                         : [1m--- Performance optimisation:[0m</div><div class="line">                         : </div><div class="line">                         : Neural networks are stable and performing for a large variety of </div><div class="line">                         : linear and non-linear classification problems. However, in contrast</div><div class="line">                         : to (e.g.) boosted decision trees, the user is advised to reduce the </div><div class="line">                         : number of input variables that have only little discrimination power. </div><div class="line">                         : </div><div class="line">                         : In the tests we have carried out so far, the MLP and ROOT networks</div><div class="line">                         : (TMlpANN, interfaced via TMVA) performed equally well, with however</div><div class="line">                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural </div><div class="line">                         : net (CFMlpANN) exhibited worse classification performance in these</div><div class="line">                         : tests, which is partly due to the slow convergence of its training</div><div class="line">                         : (at least 10k training cycles are required to achieve approximately</div><div class="line">                         : competitive results).</div><div class="line">                         : </div><div class="line">                         : [1mOvertraining: [0monly the TMlpANN performs an explicit separation of the</div><div class="line">                         : full training sample into independent training and validation samples.</div><div class="line">                         : We have found that in most high-energy physics applications the </div><div class="line">                         : available degrees of freedom (training events) are sufficient to </div><div class="line">                         : constrain the weights of the relatively simple architectures required</div><div class="line">                         : to achieve good performance. Hence no overtraining should occur, and </div><div class="line">                         : the use of validation samples would only reduce the available training</div><div class="line">                         : information. However, if the performance on the training sample is </div><div class="line">                         : found to be significantly better than the one found with the inde-</div><div class="line">                         : pendent test sample, caution is needed. The results for these samples </div><div class="line">                         : are printed to standard output at the end of each training job.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance tuning via configuration options:[0m</div><div class="line">                         : </div><div class="line">                         : The hidden layer architecture for all ANNs is defined by the option</div><div class="line">                         : &quot;HiddenLayers=N+1,N,...&quot;, where here the first hidden layer has N+1</div><div class="line">                         : neurons and the second N neurons (and so on), and where N is the number  </div><div class="line">                         : of input variables. Excessive numbers of hidden layers should be avoided,</div><div class="line">                         : in favour of more neurons in the first hidden layer.</div><div class="line">                         : </div><div class="line">                         : The number of cycles should be above 500. As said, if the number of</div><div class="line">                         : adjustable weights is small compared to the training sample size,</div><div class="line">                         : using a large number of training samples should not lead to overtraining.</div><div class="line">                         : </div><div class="line">                         : &lt;Suppress this message by specifying &quot;!H&quot; in the booking option&gt;</div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : </div><div class="line">TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]</div><div class="line">                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]</div><div class="line">                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]</div><div class="line">                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Training Network</div><div class="line">                         : </div><div class="line">                         : Finalizing handling of Regulator terms, trainE=0.713219 testE=0.724617</div><div class="line">                         : Done with handling of Regulator terms</div><div class="line">                         : Elapsed time for training with 2000 events: 2.68 sec         </div><div class="line">MLPBNN                   : [dataset] : Evaluation of MLPBNN on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00469 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_MLPBNN.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_MLPBNN.class.C[0m</div><div class="line">                         : Write special histos to file: TMVA.root:/dataset/Method_MLP/MLPBNN</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: DNN_CPU for Classification</div><div class="line">                         : </div><div class="line">TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]</div><div class="line">                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]</div><div class="line">                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]</div><div class="line">                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1</div><div class="line">                         : </div><div class="line">TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]</div><div class="line">                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]</div><div class="line">                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]</div><div class="line">                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : *****   Deep Learning Network *****</div><div class="line">DEEP NEURAL NETWORK:   Depth = 4  Input = ( 1, 1, 4 )  Batch size = 256  Loss function = C</div><div class="line">   Layer 0   DENSE Layer:   ( Input =     4 , Width =   128 )  Output = (  1 ,   256 ,   128 )   Activation Function = Tanh</div><div class="line">   Layer 1   DENSE Layer:   ( Input =   128 , Width =   128 )  Output = (  1 ,   256 ,   128 )   Activation Function = Tanh    Dropout prob. = 0.5</div><div class="line">   Layer 2   DENSE Layer:   ( Input =   128 , Width =   128 )  Output = (  1 ,   256 ,   128 )   Activation Function = Tanh    Dropout prob. = 0.5</div><div class="line">   Layer 3   DENSE Layer:   ( Input =   128 , Width =     1 )  Output = (  1 ,   256 ,     1 )   Activation Function = Identity   Dropout prob. = 0.5</div><div class="line">                         : Using 1600 events for training and 400 for testing</div><div class="line">                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.01 regularization 0 minimum error = 0.709233</div><div class="line">                         : --------------------------------------------------------------</div><div class="line">                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps</div><div class="line">                         : --------------------------------------------------------------</div><div class="line">                         :         10 Minimum Test error found - save the configuration </div><div class="line">                         :         10 |     0.358217    0.359321   0.0292842   0.0142135     55127.3           0</div><div class="line">                         :         20 |     0.363714    0.359772   0.0271121   0.0121885     59320.4          10</div><div class="line">                         :         30 |     0.357984    0.365498   0.0266478   0.0146621     60996.9          20</div><div class="line">                         :         40 |     0.361409    0.373769   0.0293727   0.0138556     54882.4          30</div><div class="line">                         :         50 |      0.36803    0.368007    0.029183   0.0138646     55258.7          40</div><div class="line">                         : </div><div class="line">                         : Elapsed time for training with 2000 events: 1.49 sec         </div><div class="line">                         : Evaluate deep neural network on CPU using batches with size = 256</div><div class="line">                         : </div><div class="line">DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.0233 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_DNN_CPU.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_DNN_CPU.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: SVM for Classification</div><div class="line">                         : </div><div class="line">TFHandler_SVM            : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]</div><div class="line">                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]</div><div class="line">                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]</div><div class="line">                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : Building SVM Working Set...with 2000 event instances</div><div class="line">                         : Elapsed time for Working Set build: 0.0746 sec</div><div class="line">                         : Sorry, no computing time forecast available for SVM, please wait ...</div><div class="line">                         : Elapsed time: 0.342 sec                                          </div><div class="line">                         : Elapsed time for training with 2000 events: 0.421 sec         </div><div class="line">SVM                      : [dataset] : Evaluation of SVM on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.0814 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_SVM.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_SVM.class.C[0m</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: BDT for Classification</div><div class="line">                         : </div><div class="line">BDT                      : #events: (reweighted) sig: 1000 bkg: 1000</div><div class="line">                         : #events: (unweighted) sig: 1000 bkg: 1000</div><div class="line">                         : Training 850 Decision Trees ... patience please</div><div class="line">                         : Elapsed time for training with 2000 events: 0.805 sec         </div><div class="line">BDT                      : [dataset] : Evaluation of BDT on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.153 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_BDT.class.C[0m</div><div class="line">                         : TMVA.root:/dataset/Method_BDT/BDT</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">Factory                  : Train method: RuleFit for Classification</div><div class="line">                         : </div><div class="line">                         : </div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : [1mH e l p   f o r   M V A   m e t h o d   [ RuleFit ] :[0m</div><div class="line">                         : </div><div class="line">                         : [1m--- Short description:[0m</div><div class="line">                         : </div><div class="line">                         : This method uses a collection of so called rules to create a</div><div class="line">                         : discriminating scoring function. Each rule consists of a series</div><div class="line">                         : of cuts in parameter space. The ensemble of rules are created</div><div class="line">                         : from a forest of decision trees, trained using the training data.</div><div class="line">                         : Each node (apart from the root) corresponds to one rule.</div><div class="line">                         : The scoring function is then obtained by linearly combining</div><div class="line">                         : the rules. A fitting procedure is applied to find the optimum</div><div class="line">                         : set of coefficients. The goal is to find a model with few rules</div><div class="line">                         : but with a strong discriminating power.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance optimisation:[0m</div><div class="line">                         : </div><div class="line">                         : There are two important considerations to make when optimising:</div><div class="line">                         : </div><div class="line">                         :   1. Topology of the decision tree forest</div><div class="line">                         :   2. Fitting of the coefficients</div><div class="line">                         : </div><div class="line">                         : The maximum complexity of the rules is defined by the size of</div><div class="line">                         : the trees. Large trees will yield many complex rules and capture</div><div class="line">                         : higher order correlations. On the other hand, small trees will</div><div class="line">                         : lead to a smaller ensemble with simple rules, only capable of</div><div class="line">                         : modeling simple structures.</div><div class="line">                         : Several parameters exists for controlling the complexity of the</div><div class="line">                         : rule ensemble.</div><div class="line">                         : </div><div class="line">                         : The fitting procedure searches for a minimum using a gradient</div><div class="line">                         : directed path. Apart from step size and number of steps, the</div><div class="line">                         : evolution of the path is defined by a cut-off parameter, tau.</div><div class="line">                         : This parameter is unknown and depends on the training data.</div><div class="line">                         : A large value will tend to give large weights to a few rules.</div><div class="line">                         : Similarly, a small value will lead to a large set of rules</div><div class="line">                         : with similar weights.</div><div class="line">                         : </div><div class="line">                         : A final point is the model used; rules and/or linear terms.</div><div class="line">                         : For a given training sample, the result may improve by adding</div><div class="line">                         : linear terms. If best performance is obtained using only linear</div><div class="line">                         : terms, it is very likely that the Fisher discriminant would be</div><div class="line">                         : a better choice. Ideally the fitting procedure should be able to</div><div class="line">                         : make this choice by giving appropriate weights for either terms.</div><div class="line">                         : </div><div class="line">                         : [1m--- Performance tuning via configuration options:[0m</div><div class="line">                         : </div><div class="line">                         : I.  TUNING OF RULE ENSEMBLE:</div><div class="line">                         : </div><div class="line">                         :    [1mForestType  [0m: Recommended is to use the default &quot;AdaBoost&quot;.</div><div class="line">                         :    [1mnTrees      [0m: More trees leads to more rules but also slow</div><div class="line">                         :                  performance. With too few trees the risk is</div><div class="line">                         :                  that the rule ensemble becomes too simple.</div><div class="line">                         :    [1mfEventsMin  [0m</div><div class="line">                         :    [1mfEventsMax  [0m: With a lower min, more large trees will be generated</div><div class="line">                         :                  leading to more complex rules.</div><div class="line">                         :                  With a higher max, more small trees will be</div><div class="line">                         :                  generated leading to more simple rules.</div><div class="line">                         :                  By changing this range, the average complexity</div><div class="line">                         :                  of the rule ensemble can be controlled.</div><div class="line">                         :    [1mRuleMinDist [0m: By increasing the minimum distance between</div><div class="line">                         :                  rules, fewer and more diverse rules will remain.</div><div class="line">                         :                  Initially it is a good idea to keep this small</div><div class="line">                         :                  or zero and let the fitting do the selection of</div><div class="line">                         :                  rules. In order to reduce the ensemble size,</div><div class="line">                         :                  the value can then be increased.</div><div class="line">                         : </div><div class="line">                         : II. TUNING OF THE FITTING:</div><div class="line">                         : </div><div class="line">                         :    [1mGDPathEveFrac [0m: fraction of events in path evaluation</div><div class="line">                         :                  Increasing this fraction will improve the path</div><div class="line">                         :                  finding. However, a too high value will give few</div><div class="line">                         :                  unique events available for error estimation.</div><div class="line">                         :                  It is recommended to use the default = 0.5.</div><div class="line">                         :    [1mGDTau         [0m: cutoff parameter tau</div><div class="line">                         :                  By default this value is set to -1.0.</div><div class="line">                         :                  This means that the cut off parameter is</div><div class="line">                         :                  automatically estimated. In most cases</div><div class="line">                         :                  this should be fine. However, you may want</div><div class="line">                         :                  to fix this value if you already know it</div><div class="line">                         :                  and want to reduce on training time.</div><div class="line">                         :    [1mGDTauPrec     [0m: precision of estimated tau</div><div class="line">                         :                  Increase this precision to find a more</div><div class="line">                         :                  optimum cut-off parameter.</div><div class="line">                         :    [1mGDNStep       [0m: number of steps in path search</div><div class="line">                         :                  If the number of steps is too small, then</div><div class="line">                         :                  the program will give a warning message.</div><div class="line">                         : </div><div class="line">                         : III. WARNING MESSAGES</div><div class="line">                         : </div><div class="line">                         : [1mRisk(i+1)&gt;=Risk(i) in path[0m</div><div class="line">                         : [1mChaotic behaviour of risk evolution.[0m</div><div class="line">                         :                  The error rate was still decreasing at the end</div><div class="line">                         :                  By construction the Risk should always decrease.</div><div class="line">                         :                  However, if the training sample is too small or</div><div class="line">                         :                  the model is overtrained, such warnings can</div><div class="line">                         :                  occur.</div><div class="line">                         :                  The warnings can safely be ignored if only a</div><div class="line">                         :                  few (&lt;3) occur. If more warnings are generated,</div><div class="line">                         :                  the fitting fails.</div><div class="line">                         :                  A remedy may be to increase the value</div><div class="line">                         :                  [1mGDValidEveFrac[0m to 1.0 (or a larger value).</div><div class="line">                         :                  In addition, if [1mGDPathEveFrac[0m is too high</div><div class="line">                         :                  the same warnings may occur since the events</div><div class="line">                         :                  used for error estimation are also used for</div><div class="line">                         :                  path estimation.</div><div class="line">                         :                  Another possibility is to modify the model - </div><div class="line">                         :                  See above on tuning the rule ensemble.</div><div class="line">                         : </div><div class="line">                         : [1mThe error rate was still decreasing at the end of the path[0m</div><div class="line">                         :                  Too few steps in path! Increase [1mGDNSteps[0m.</div><div class="line">                         : </div><div class="line">                         : [1mReached minimum early in the search[0m</div><div class="line">                         :                  Minimum was found early in the fitting. This</div><div class="line">                         :                  may indicate that the used step size [1mGDStep[0m.</div><div class="line">                         :                  was too large. Reduce it and rerun.</div><div class="line">                         :                  If the results still are not OK, modify the</div><div class="line">                         :                  model either by modifying the rule ensemble</div><div class="line">                         :                  or add/remove linear terms</div><div class="line">                         : </div><div class="line">                         : &lt;Suppress this message by specifying &quot;!H&quot; in the booking option&gt;</div><div class="line">                         : [1m================================================================[0m</div><div class="line">                         : </div><div class="line">RuleFit                  : -------------------RULE ENSEMBLE SUMMARY------------------------</div><div class="line">                         : Tree training method               : AdaBoost</div><div class="line">                         : Number of events per tree          : 2000</div><div class="line">                         : Number of trees                    : 20</div><div class="line">                         : Number of generated rules          : 196</div><div class="line">                         : Idem, after cleanup                : 80</div><div class="line">                         : Average number of cuts per rule    :     3.01</div><div class="line">                         : Spread in number of cuts per rules :     1.23</div><div class="line">                         : ----------------------------------------------------------------</div><div class="line">                         : </div><div class="line">                         : GD path scan - the scan stops when the max num. of steps is reached or a min is found</div><div class="line">                         : Estimating the cutoff parameter tau. The estimated time is a pessimistic maximum.</div><div class="line">                         : Best path found with tau = 0.0000 after 2.93 sec      </div><div class="line">                         : Fitting model...</div><div class="line">&lt;WARNING&gt;                : </div><div class="line">                         : Minimisation elapsed time : 1.41 sec                      </div><div class="line">                         : ----------------------------------------------------------------</div><div class="line">                         : Found minimum at step 10000 with error = 0.552378</div><div class="line">                         : Reason for ending loop: end of loop reached</div><div class="line">                         : ----------------------------------------------------------------</div><div class="line">                         : The error rate was still decreasing at the end of the path</div><div class="line">                         : Increase number of steps (GDNSteps).</div><div class="line">                         : Removed 28 out of a total of 80 rules with importance &lt; 0.001</div><div class="line">                         : </div><div class="line">                         : ================================================================</div><div class="line">                         :                           M o d e l                             </div><div class="line">                         : ================================================================</div><div class="line">RuleFit                  : Offset (a0) = 9.46803</div><div class="line">                         : ------------------------------------</div><div class="line">                         : Linear model (weights unnormalised)</div><div class="line">                         : ------------------------------------</div><div class="line">                         : Variable :     Weights : Importance</div><div class="line">                         : ------------------------------------</div><div class="line">                         :   myvar1 :  -6.338e-01 :  0.472</div><div class="line">                         :   myvar2 :  -4.488e-01 :  0.209</div><div class="line">                         :     var3 :  -2.810e-01 :  0.129</div><div class="line">                         :     var4 :   1.850e+00 :  1.000</div><div class="line">                         : ------------------------------------</div><div class="line">                         : Number of rules = 52</div><div class="line">                         : Printing the first 10 rules, ordered in importance.</div><div class="line">                         : Rule    1 : Importance  = 0.4294</div><div class="line">                         :             Cut  1 :     -0.708 &lt; var4             </div><div class="line">                         : Rule    2 : Importance  = 0.3676</div><div class="line">                         :             Cut  1 :              var3 &lt;    -0.0812</div><div class="line">                         : Rule    3 : Importance  = 0.3363</div><div class="line">                         :             Cut  1 :    -0.0812 &lt; var3             </div><div class="line">                         : Rule    4 : Importance  = 0.2934</div><div class="line">                         :             Cut  1 :     -0.877 &lt; var3             </div><div class="line">                         :             Cut  2 :      0.271 &lt; var4             </div><div class="line">                         : Rule    5 : Importance  = 0.2706</div><div class="line">                         :             Cut  1 :              myvar1 &lt;       2.83</div><div class="line">                         :             Cut  2 :      -1.67 &lt; var3             </div><div class="line">                         : Rule    6 : Importance  = 0.2387</div><div class="line">                         :             Cut  1 :              myvar1 &lt;       1.46</div><div class="line">                         :             Cut  2 :              var4 &lt;      0.271</div><div class="line">                         : Rule    7 : Importance  = 0.1904</div><div class="line">                         :             Cut  1 :              var4 &lt;     -0.708</div><div class="line">                         : Rule    8 : Importance  = 0.1897</div><div class="line">                         :             Cut  1 :              var3 &lt;      0.256</div><div class="line">                         :             Cut  2 :              var4 &lt;     -0.708</div><div class="line">                         : Rule    9 : Importance  = 0.1689</div><div class="line">                         :             Cut  1 :              myvar1 &lt;      -2.85</div><div class="line">                         : Rule   10 : Importance  = 0.1611</div><div class="line">                         :             Cut  1 :      -2.85 &lt; myvar1 &lt;       2.68</div><div class="line">                         : Skipping the next 42 rules</div><div class="line">                         : ================================================================</div><div class="line">                         : </div><div class="line">&lt;WARNING&gt;                : No input variable directory found - BUG?</div><div class="line">                         : Elapsed time for training with 2000 events: 4.4 sec         </div><div class="line">RuleFit                  : [dataset] : Evaluation of RuleFit on training sample (2000 events)</div><div class="line">                         : Elapsed time for evaluation of 2000 events: 0.00391 sec       </div><div class="line">                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_RuleFit.weights.xml[0m</div><div class="line">                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_RuleFit.class.C[0m</div><div class="line">                         : TMVA.root:/dataset/Method_RuleFit/RuleFit</div><div class="line">Factory                  : Training finished</div><div class="line">                         : </div><div class="line">                         : Ranking input variables (method specific)...</div><div class="line">                         : No variable ranking supplied by classifier: Cuts</div><div class="line">                         : No variable ranking supplied by classifier: CutsD</div><div class="line">Likelihood               : Ranking result (top variable is best ranked)</div><div class="line">                         : -------------------------------------</div><div class="line">                         : Rank : Variable  : Delta Separation</div><div class="line">                         : -------------------------------------</div><div class="line">                         :    1 : var4      : 5.365e-02</div><div class="line">                         :    2 : myvar1    : -4.483e-04</div><div class="line">                         :    3 : myvar2    : -2.298e-03</div><div class="line">                         :    4 : var3      : -9.266e-03</div><div class="line">                         : -------------------------------------</div><div class="line">LikelihoodPCA            : Ranking result (top variable is best ranked)</div><div class="line">                         : -------------------------------------</div><div class="line">                         : Rank : Variable  : Delta Separation</div><div class="line">                         : -------------------------------------</div><div class="line">                         :    1 : var4      : 2.952e-01</div><div class="line">                         :    2 : myvar1    : 7.646e-02</div><div class="line">                         :    3 : var3      : 2.035e-02</div><div class="line">                         :    4 : myvar2    : 1.950e-02</div><div class="line">                         : -------------------------------------</div><div class="line">                         : No variable ranking supplied by classifier: PDERS</div><div class="line">PDEFoam                  : Ranking result (top variable is best ranked)</div><div class="line">                         : ----------------------------------------</div><div class="line">                         : Rank : Variable  : Variable Importance</div><div class="line">                         : ----------------------------------------</div><div class="line">                         :    1 : var4      : 3.830e-01</div><div class="line">                         :    2 : myvar1    : 2.979e-01</div><div class="line">                         :    3 : var3      : 1.915e-01</div><div class="line">                         :    4 : myvar2    : 1.277e-01</div><div class="line">                         : ----------------------------------------</div><div class="line">                         : No variable ranking supplied by classifier: KNN</div><div class="line">LD                       : Ranking result (top variable is best ranked)</div><div class="line">                         : ---------------------------------</div><div class="line">                         : Rank : Variable  : Discr. power</div><div class="line">                         : ---------------------------------</div><div class="line">                         :    1 : var4      : 7.053e-01</div><div class="line">                         :    2 : myvar1    : 3.094e-01</div><div class="line">                         :    3 : var3      : 1.423e-01</div><div class="line">                         :    4 : myvar2    : 1.019e-01</div><div class="line">                         : ---------------------------------</div><div class="line">                         : No variable ranking supplied by classifier: FDA_GA</div><div class="line">MLPBNN                   : Ranking result (top variable is best ranked)</div><div class="line">                         : -------------------------------</div><div class="line">                         : Rank : Variable  : Importance</div><div class="line">                         : -------------------------------</div><div class="line">                         :    1 : var4      : 1.360e+00</div><div class="line">                         :    2 : myvar2    : 1.009e+00</div><div class="line">                         :    3 : myvar1    : 8.834e-01</div><div class="line">                         :    4 : var3      : 3.562e-01</div><div class="line">                         : -------------------------------</div><div class="line">                         : No variable ranking supplied by classifier: DNN_CPU</div><div class="line">                         : No variable ranking supplied by classifier: SVM</div><div class="line">BDT                      : Ranking result (top variable is best ranked)</div><div class="line">                         : ----------------------------------------</div><div class="line">                         : Rank : Variable  : Variable Importance</div><div class="line">                         : ----------------------------------------</div><div class="line">                         :    1 : var4      : 2.697e-01</div><div class="line">                         :    2 : myvar1    : 2.467e-01</div><div class="line">                         :    3 : myvar2    : 2.460e-01</div><div class="line">                         :    4 : var3      : 2.377e-01</div><div class="line">                         : ----------------------------------------</div><div class="line">RuleFit                  : Ranking result (top variable is best ranked)</div><div class="line">                         : -------------------------------</div><div class="line">                         : Rank : Variable  : Importance</div><div class="line">                         : -------------------------------</div><div class="line">                         :    1 : var4      : 1.000e+00</div><div class="line">                         :    2 : myvar1    : 6.981e-01</div><div class="line">                         :    3 : var3      : 5.947e-01</div><div class="line">                         :    4 : myvar2    : 4.105e-01</div><div class="line">                         : -------------------------------</div><div class="line">Factory                  : === Destroy and recreate all methods via weight files for testing ===</div><div class="line">                         : </div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_Cuts.weights.xml[0m</div><div class="line">                         : Read cuts optimised using sample of MC events</div><div class="line">                         : Reading 100 signal efficiency bins for 4 variables</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_CutsD.weights.xml[0m</div><div class="line">                         : Read cuts optimised using sample of MC events</div><div class="line">                         : Reading 100 signal efficiency bins for 4 variables</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_Likelihood.weights.xml[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_LikelihoodPCA.weights.xml[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_PDERS.weights.xml[0m</div><div class="line">                         : signal and background scales: 0.001 0.001</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_PDEFoam.weights.xml[0m</div><div class="line">                         : Read foams from file: [0;36mdataset/weights/TMVAClassification_PDEFoam.weights_foams.root[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_KNN.weights.xml[0m</div><div class="line">                         : Creating kd-tree with 2000 events</div><div class="line">                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)</div><div class="line">ModulekNN                : Optimizing tree for 4 variables with 2000 values</div><div class="line">                         : &lt;Fill&gt; Class 1 has     1000 events</div><div class="line">                         : &lt;Fill&gt; Class 2 has     1000 events</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_LD.weights.xml[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_FDA_GA.weights.xml[0m</div><div class="line">                         : User-defined formula string       : &quot;(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3&quot;</div><div class="line">                         : TFormula-compatible formula string: &quot;[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]&quot;</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_MLPBNN.weights.xml[0m</div><div class="line">MLPBNN                   : Building Network. </div><div class="line">                         : Initializing weights</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_DNN_CPU.weights.xml[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_SVM.weights.xml[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m</div><div class="line">                         : Reading weight file: [0;36mdataset/weights/TMVAClassification_RuleFit.weights.xml[0m</div><div class="line">Factory                  : [1mTest all methods[0m</div><div class="line">Factory                  : Test method: Cuts for Classification performance</div><div class="line">                         : </div><div class="line">Cuts                     : [dataset] : Evaluation of Cuts on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.00184 sec       </div><div class="line">Factory                  : Test method: CutsD for Classification performance</div><div class="line">                         : </div><div class="line">CutsD                    : [dataset] : Evaluation of CutsD on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.00611 sec       </div><div class="line">Factory                  : Test method: Likelihood for Classification performance</div><div class="line">                         : </div><div class="line">Likelihood               : [dataset] : Evaluation of Likelihood on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.00974 sec       </div><div class="line">Factory                  : Test method: LikelihoodPCA for Classification performance</div><div class="line">                         : </div><div class="line">LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.0199 sec       </div><div class="line">Factory                  : Test method: PDERS for Classification performance</div><div class="line">                         : </div><div class="line">PDERS                    : [dataset] : Evaluation of PDERS on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.899 sec       </div><div class="line">Factory                  : Test method: PDEFoam for Classification performance</div><div class="line">                         : </div><div class="line">PDEFoam                  : [dataset] : Evaluation of PDEFoam on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.0705 sec       </div><div class="line">Factory                  : Test method: KNN for Classification performance</div><div class="line">                         : </div><div class="line">KNN                      : [dataset] : Evaluation of KNN on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.189 sec       </div><div class="line">Factory                  : Test method: LD for Classification performance</div><div class="line">                         : </div><div class="line">LD                       : [dataset] : Evaluation of LD on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.00306 sec       </div><div class="line">                         : Dataset[dataset] : Evaluation of LD on testing sample</div><div class="line">Factory                  : Test method: FDA_GA for Classification performance</div><div class="line">                         : </div><div class="line">FDA_GA                   : [dataset] : Evaluation of FDA_GA on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.00259 sec       </div><div class="line">Factory                  : Test method: MLPBNN for Classification performance</div><div class="line">                         : </div><div class="line">MLPBNN                   : [dataset] : Evaluation of MLPBNN on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.017 sec       </div><div class="line">Factory                  : Test method: DNN_CPU for Classification performance</div><div class="line">                         : </div><div class="line">                         : Evaluate deep neural network on CPU using batches with size = 1000</div><div class="line">                         : </div><div class="line">TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]</div><div class="line">                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]</div><div class="line">                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]</div><div class="line">                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.0768 sec       </div><div class="line">Factory                  : Test method: SVM for Classification performance</div><div class="line">                         : </div><div class="line">SVM                      : [dataset] : Evaluation of SVM on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.324 sec       </div><div class="line">Factory                  : Test method: BDT for Classification performance</div><div class="line">                         : </div><div class="line">BDT                      : [dataset] : Evaluation of BDT on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.547 sec       </div><div class="line">Factory                  : Test method: RuleFit for Classification performance</div><div class="line">                         : </div><div class="line">RuleFit                  : [dataset] : Evaluation of RuleFit on testing sample (10000 events)</div><div class="line">                         : Elapsed time for evaluation of 10000 events: 0.0143 sec       </div><div class="line">Factory                  : [1mEvaluate all methods[0m</div><div class="line">Factory                  : Evaluate classifier: Cuts</div><div class="line">                         : </div><div class="line">&lt;WARNING&gt;                : You have asked for histogram MVA_EFF_BvsS which does not seem to exist in *Results* .. better don&#39;t use it </div><div class="line">&lt;WARNING&gt;                : You have asked for histogram EFF_BVSS_TR which does not seem to exist in *Results* .. better don&#39;t use it </div><div class="line">TFHandler_Cuts           : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: CutsD</div><div class="line">                         : </div><div class="line">&lt;WARNING&gt;                : You have asked for histogram MVA_EFF_BvsS which does not seem to exist in *Results* .. better don&#39;t use it </div><div class="line">TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.14555     1.0166   [    -5.5736     5.0206 ]</div><div class="line">                         :   myvar2:  -0.093417     1.0353   [    -3.8442     3.7856 ]</div><div class="line">                         :     var3:  -0.096857     1.0078   [    -4.5469     4.5058 ]</div><div class="line">                         :     var4:    0.65748    0.95864   [    -4.0893     3.7760 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">&lt;WARNING&gt;                : You have asked for histogram EFF_BVSS_TR which does not seem to exist in *Results* .. better don&#39;t use it </div><div class="line">TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.17586     1.0000   [    -5.6401     4.8529 ]</div><div class="line">                         :   myvar2:   0.026952     1.0000   [    -2.9292     3.7065 ]</div><div class="line">                         :     var3:   -0.11549     1.0000   [    -4.1792     3.5180 ]</div><div class="line">                         :     var4:    0.34819     1.0000   [    -3.3363     3.3963 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">TFHandler_CutsD          : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   -0.14555     1.0166   [    -5.5736     5.0206 ]</div><div class="line">                         :   myvar2:  -0.093417     1.0353   [    -3.8442     3.7856 ]</div><div class="line">                         :     var3:  -0.096857     1.0078   [    -4.5469     4.5058 ]</div><div class="line">                         :     var4:    0.65748    0.95864   [    -4.0893     3.7760 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: Likelihood</div><div class="line">                         : </div><div class="line">Likelihood               : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_Likelihood     : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: LikelihoodPCA</div><div class="line">                         : </div><div class="line">TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:     1.1147     2.2628   [    -12.508     10.719 ]</div><div class="line">                         :   myvar2:   -0.25554     1.1225   [    -4.1578     3.8995 ]</div><div class="line">                         :     var3:   -0.19401    0.58225   [    -2.2950     1.8880 ]</div><div class="line">                         :     var4:   -0.32038    0.33412   [    -1.3929    0.88819 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">LikelihoodPCA            : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:     1.1147     2.2628   [    -12.508     10.719 ]</div><div class="line">                         :   myvar2:   -0.25554     1.1225   [    -4.1578     3.8995 ]</div><div class="line">                         :     var3:   -0.19401    0.58225   [    -2.2950     1.8880 ]</div><div class="line">                         :     var4:   -0.32038    0.33412   [    -1.3929    0.88819 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: PDERS</div><div class="line">                         : </div><div class="line">PDERS                    : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_PDERS          : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: PDEFoam</div><div class="line">                         : </div><div class="line">PDEFoam                  : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_PDEFoam        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: KNN</div><div class="line">                         : </div><div class="line">KNN                      : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_KNN            : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: LD</div><div class="line">                         : </div><div class="line">LD                       : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">                         : Also filling probability and rarity histograms (on request)...</div><div class="line">TFHandler_LD             : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: FDA_GA</div><div class="line">                         : </div><div class="line">FDA_GA                   : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_FDA_GA         : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: MLPBNN</div><div class="line">                         : </div><div class="line">TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]</div><div class="line">                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]</div><div class="line">                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]</div><div class="line">                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">MLPBNN                   : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]</div><div class="line">                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]</div><div class="line">                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]</div><div class="line">                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: DNN_CPU</div><div class="line">                         : </div><div class="line">DNN_CPU                  : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">                         : Evaluate deep neural network on CPU using batches with size = 1000</div><div class="line">                         : </div><div class="line">TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:   0.089214    0.20183   [    -1.0000     1.0000 ]</div><div class="line">                         :   myvar2:  -0.090751    0.29609   [    -1.0000     1.0000 ]</div><div class="line">                         :     var3:   0.059878    0.21436   [    -1.0000     1.0000 ]</div><div class="line">                         :     var4:    0.11587    0.24261   [    -1.0000     1.0000 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]</div><div class="line">                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]</div><div class="line">                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]</div><div class="line">                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: SVM</div><div class="line">                         : </div><div class="line">TFHandler_SVM            : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]</div><div class="line">                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]</div><div class="line">                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]</div><div class="line">                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">SVM                      : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_SVM            : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.12216    0.20255   [    -1.0614     1.0246 ]</div><div class="line">                         :   myvar2:   -0.12333    0.30492   [    -1.2280    0.99911 ]</div><div class="line">                         :     var3:   0.097148    0.21347   [    -1.0158    0.99984 ]</div><div class="line">                         :     var4:    0.17495    0.23851   [    -1.2661     1.0694 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: BDT</div><div class="line">                         : </div><div class="line">BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">Factory                  : Evaluate classifier: RuleFit</div><div class="line">                         : </div><div class="line">RuleFit                  : [dataset] : Loop over test events and fill histograms with classifier response...</div><div class="line">                         : </div><div class="line">TFHandler_RuleFit        : Variable        Mean        RMS   [        Min        Max ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         :   myvar1:    0.21781     1.7248   [    -9.8605     7.9024 ]</div><div class="line">                         :   myvar2:  -0.062175     1.1106   [    -4.0854     4.0259 ]</div><div class="line">                         :     var3:    0.16451     1.0589   [    -5.3563     4.6422 ]</div><div class="line">                         :     var4:    0.43566     1.2253   [    -6.9675     5.0307 ]</div><div class="line">                         : -----------------------------------------------------------</div><div class="line">                         : </div><div class="line">                         : Evaluation results ranked by best signal efficiency and purity (area)</div><div class="line">                         : -------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : DataSet       MVA                       </div><div class="line">                         : Name:         Method:          ROC-integ</div><div class="line">                         : dataset       LD             : 0.921</div><div class="line">                         : dataset       DNN_CPU        : 0.920</div><div class="line">                         : dataset       MLPBNN         : 0.919</div><div class="line">                         : dataset       LikelihoodPCA  : 0.914</div><div class="line">                         : dataset       CutsD          : 0.908</div><div class="line">                         : dataset       SVM            : 0.898</div><div class="line">                         : dataset       RuleFit        : 0.881</div><div class="line">                         : dataset       BDT            : 0.881</div><div class="line">                         : dataset       KNN            : 0.838</div><div class="line">                         : dataset       PDEFoam        : 0.822</div><div class="line">                         : dataset       FDA_GA         : 0.800</div><div class="line">                         : dataset       PDERS          : 0.797</div><div class="line">                         : dataset       Cuts           : 0.792</div><div class="line">                         : dataset       Likelihood     : 0.757</div><div class="line">                         : -------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : </div><div class="line">                         : Testing efficiency compared to training efficiency (overtraining check)</div><div class="line">                         : -------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) </div><div class="line">                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   </div><div class="line">                         : -------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : dataset              LD             : 0.364 (0.438)       0.781 (0.758)      0.929 (0.920)</div><div class="line">                         : dataset              DNN_CPU        : 0.371 (0.420)       0.776 (0.752)      0.927 (0.920)</div><div class="line">                         : dataset              MLPBNN         : 0.343 (0.432)       0.777 (0.768)      0.926 (0.920)</div><div class="line">                         : dataset              LikelihoodPCA  : 0.308 (0.345)       0.757 (0.728)      0.920 (0.911)</div><div class="line">                         : dataset              CutsD          : 0.262 (0.449)       0.735 (0.709)      0.914 (0.890)</div><div class="line">                         : dataset              SVM            : 0.321 (0.332)       0.711 (0.725)      0.894 (0.898)</div><div class="line">                         : dataset              RuleFit        : 0.075 (0.077)       0.667 (0.718)      0.893 (0.896)</div><div class="line">                         : dataset              BDT            : 0.275 (0.402)       0.661 (0.731)      0.870 (0.899)</div><div class="line">                         : dataset              KNN            : 0.195 (0.252)       0.561 (0.642)      0.810 (0.843)</div><div class="line">                         : dataset              PDEFoam        : 0.173 (0.219)       0.499 (0.541)      0.761 (0.773)</div><div class="line">                         : dataset              FDA_GA         : 0.126 (0.142)       0.458 (0.475)      0.751 (0.751)</div><div class="line">                         : dataset              PDERS          : 0.158 (0.171)       0.465 (0.492)      0.750 (0.756)</div><div class="line">                         : dataset              Cuts           : 0.112 (0.133)       0.444 (0.496)      0.741 (0.758)</div><div class="line">                         : dataset              Likelihood     : 0.076 (0.089)       0.389 (0.420)      0.686 (0.692)</div><div class="line">                         : -------------------------------------------------------------------------------------------------------------------</div><div class="line">                         : </div><div class="line">Dataset:dataset          : Created tree &#39;TestTree&#39; with 10000 events</div><div class="line">                         : </div><div class="line">Dataset:dataset          : Created tree &#39;TrainTree&#39; with 2000 events</div><div class="line">                         : </div><div class="line">Factory                  : [1mThank you for using TMVA![0m</div><div class="line">                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m</div><div class="line">==&gt; Wrote root file: TMVA.root</div><div class="line">==&gt; TMVAClassification is done!</div><div class="line">(int) 0</div></div><!-- fragment --> <div class="fragment"><div class="line"></div><div class="line"></div><div class="line"><span class="preprocessor">#include &lt;cstdlib&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;map&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;string&gt;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TChain_8h.html">TChain.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TFile_8h.html">TFile.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TTree_8h.html">TTree.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TString_8h.html">TString.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TObjString_8h.html">TObjString.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TSystem_8h.html">TSystem.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TROOT_8h.html">TROOT.h</a>&quot;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="tmva_2tmva_2inc_2TMVA_2Factory_8h.html">TMVA/Factory.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="DataLoader_8h.html">TMVA/DataLoader.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="Tools_8h.html">TMVA/Tools.h</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="TMVAGui_8h.html">TMVA/TMVAGui.h</a>&quot;</span></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> TMVAClassification( <a class="code" href="classTString.html">TString</a> myMethodList = <span class="stringliteral">&quot;&quot;</span> )</div><div class="line">{</div><div class="line">   <span class="comment">// The explicit loading of the shared libTMVA is done in TMVAlogon.C, defined in .rootrc</span></div><div class="line">   <span class="comment">// if you use your private .rootrc, or run from a different directory, please copy the</span></div><div class="line">   <span class="comment">// corresponding lines from .rootrc</span></div><div class="line"></div><div class="line">   <span class="comment">// Methods to be processed can be given as an argument; use format:</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//     mylinux~&gt; root -l TMVAClassification.C\(\&quot;myMethod1,myMethod2,myMethod3\&quot;\)</span></div><div class="line"></div><div class="line">   <span class="comment">//---------------------------------------------------------------</span></div><div class="line">   <span class="comment">// This loads the library</span></div><div class="line">   <a class="code" href="classTMVA_1_1Tools.html#a1b3f35bb142fcc8b7d6a29a6b48306d4">TMVA::Tools::Instance</a>();</div><div class="line"></div><div class="line">   <span class="comment">// Default MVA methods to be trained + tested</span></div><div class="line">   std::map&lt;std::string,int&gt; Use;</div><div class="line"></div><div class="line">   <span class="comment">// Cut optimisation</span></div><div class="line">   Use[<span class="stringliteral">&quot;Cuts&quot;</span>]            = 1;</div><div class="line">   Use[<span class="stringliteral">&quot;CutsD&quot;</span>]           = 1;</div><div class="line">   Use[<span class="stringliteral">&quot;CutsPCA&quot;</span>]         = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;CutsGA&quot;</span>]          = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;CutsSA&quot;</span>]          = 0;</div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// 1-dimensional likelihood (&quot;naive Bayes estimator&quot;)</span></div><div class="line">   Use[<span class="stringliteral">&quot;Likelihood&quot;</span>]      = 1;</div><div class="line">   Use[<span class="stringliteral">&quot;LikelihoodD&quot;</span>]     = 0; <span class="comment">// the &quot;D&quot; extension indicates decorrelated input variables (see option strings)</span></div><div class="line">   Use[<span class="stringliteral">&quot;LikelihoodPCA&quot;</span>]   = 1; <span class="comment">// the &quot;PCA&quot; extension indicates PCA-transformed input variables (see option strings)</span></div><div class="line">   Use[<span class="stringliteral">&quot;LikelihoodKDE&quot;</span>]   = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;LikelihoodMIX&quot;</span>]   = 0;</div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Mutidimensional likelihood and Nearest-Neighbour methods</span></div><div class="line">   Use[<span class="stringliteral">&quot;PDERS&quot;</span>]           = 1;</div><div class="line">   Use[<span class="stringliteral">&quot;PDERSD&quot;</span>]          = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;PDERSPCA&quot;</span>]        = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;PDEFoam&quot;</span>]         = 1;</div><div class="line">   Use[<span class="stringliteral">&quot;PDEFoamBoost&quot;</span>]    = 0; <span class="comment">// uses generalised MVA method boosting</span></div><div class="line">   Use[<span class="stringliteral">&quot;KNN&quot;</span>]             = 1; <span class="comment">// k-nearest neighbour method</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Linear Discriminant Analysis</span></div><div class="line">   Use[<span class="stringliteral">&quot;LD&quot;</span>]              = 1; <span class="comment">// Linear Discriminant identical to Fisher</span></div><div class="line">   Use[<span class="stringliteral">&quot;Fisher&quot;</span>]          = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;FisherG&quot;</span>]         = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;BoostedFisher&quot;</span>]   = 0; <span class="comment">// uses generalised MVA method boosting</span></div><div class="line">   Use[<span class="stringliteral">&quot;HMatrix&quot;</span>]         = 0;</div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Function Discriminant analysis</span></div><div class="line">   Use[<span class="stringliteral">&quot;FDA_GA&quot;</span>]          = 1; <span class="comment">// minimisation of user-defined function using Genetics Algorithm</span></div><div class="line">   Use[<span class="stringliteral">&quot;FDA_SA&quot;</span>]          = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;FDA_MC&quot;</span>]          = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;FDA_MT&quot;</span>]          = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;FDA_GAMT&quot;</span>]        = 0;</div><div class="line">   Use[<span class="stringliteral">&quot;FDA_MCMT&quot;</span>]        = 0;</div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Neural Networks (all are feed-forward Multilayer Perceptrons)</span></div><div class="line">   Use[<span class="stringliteral">&quot;MLP&quot;</span>]             = 0; <span class="comment">// Recommended ANN</span></div><div class="line">   Use[<span class="stringliteral">&quot;MLPBFGS&quot;</span>]         = 0; <span class="comment">// Recommended ANN with optional training method</span></div><div class="line">   Use[<span class="stringliteral">&quot;MLPBNN&quot;</span>]          = 1; <span class="comment">// Recommended ANN with BFGS training method and bayesian regulator</span></div><div class="line">   Use[<span class="stringliteral">&quot;CFMlpANN&quot;</span>]        = 0; <span class="comment">// Depreciated ANN from ALEPH</span></div><div class="line">   Use[<span class="stringliteral">&quot;TMlpANN&quot;</span>]         = 0; <span class="comment">// ROOT&#39;s own ANN</span></div><div class="line"><span class="preprocessor">#ifdef R__HAS_TMVAGPU</span></div><div class="line">   Use[<span class="stringliteral">&quot;DNN_GPU&quot;</span>]         = 1; <span class="comment">// CUDA-accelerated DNN training.</span></div><div class="line"><span class="preprocessor">#else</span></div><div class="line">   Use[<span class="stringliteral">&quot;DNN_GPU&quot;</span>]         = 0;</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"></div><div class="line"><span class="preprocessor">#ifdef R__HAS_TMVACPU</span></div><div class="line">   Use[<span class="stringliteral">&quot;DNN_CPU&quot;</span>]         = 1; <span class="comment">// Multi-core accelerated DNN.</span></div><div class="line"><span class="preprocessor">#else</span></div><div class="line">   Use[<span class="stringliteral">&quot;DNN_CPU&quot;</span>]         = 0;</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Support Vector Machine</span></div><div class="line">   Use[<span class="stringliteral">&quot;SVM&quot;</span>]             = 1;</div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Boosted Decision Trees</span></div><div class="line">   Use[<span class="stringliteral">&quot;BDT&quot;</span>]             = 1; <span class="comment">// uses Adaptive Boost</span></div><div class="line">   Use[<span class="stringliteral">&quot;BDTG&quot;</span>]            = 0; <span class="comment">// uses Gradient Boost</span></div><div class="line">   Use[<span class="stringliteral">&quot;BDTB&quot;</span>]            = 0; <span class="comment">// uses Bagging</span></div><div class="line">   Use[<span class="stringliteral">&quot;BDTD&quot;</span>]            = 0; <span class="comment">// decorrelation + Adaptive Boost</span></div><div class="line">   Use[<span class="stringliteral">&quot;BDTF&quot;</span>]            = 0; <span class="comment">// allow usage of fisher discriminant for node splitting</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Friedman&#39;s RuleFit method, ie, an optimised series of cuts (&quot;rules&quot;)</span></div><div class="line">   Use[<span class="stringliteral">&quot;RuleFit&quot;</span>]         = 1;</div><div class="line">   <span class="comment">// ---------------------------------------------------------------</span></div><div class="line"></div><div class="line">   std::cout &lt;&lt; std::endl;</div><div class="line">   std::cout &lt;&lt; <span class="stringliteral">&quot;==&gt; Start TMVAClassification&quot;</span> &lt;&lt; std::endl;</div><div class="line"></div><div class="line">   <span class="comment">// Select methods (don&#39;t look at this code - not of interest)</span></div><div class="line">   <span class="keywordflow">if</span> (myMethodList != <span class="stringliteral">&quot;&quot;</span>) {</div><div class="line">      <span class="keywordflow">for</span> (std::map&lt;std::string,int&gt;::iterator it = Use.begin(); it != Use.end(); it++) it-&gt;second = 0;</div><div class="line"></div><div class="line">      std::vector&lt;TString&gt; mlist = <a class="code" href="namespaceTMVA.html#a0c14643ab19d3bedaae1ea1e5d8eb56c">TMVA::gTools</a>().<a class="code" href="classTMVA_1_1Tools.html#a5de2aa84469ea1506111daf38f14b905">SplitString</a>( myMethodList, <span class="charliteral">&#39;,&#39;</span> );</div><div class="line">      <span class="keywordflow">for</span> (<a class="code" href="RtypesCore_8h.html#a7c1bc4939263cb6c0f48e434d77ac258">UInt_t</a> i=0; i&lt;mlist.size(); i++) {</div><div class="line">         std::string regMethod(mlist[i]);</div><div class="line"></div><div class="line">         <span class="keywordflow">if</span> (Use.find(regMethod) == Use.end()) {</div><div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Method \&quot;&quot;</span> &lt;&lt; regMethod &lt;&lt; <span class="stringliteral">&quot;\&quot; not known in TMVA under this name. Choose among the following:&quot;</span> &lt;&lt; std::endl;</div><div class="line">            <span class="keywordflow">for</span> (std::map&lt;std::string,int&gt;::iterator it = Use.begin(); it != Use.end(); it++) std::cout &lt;&lt; it-&gt;first &lt;&lt; <span class="stringliteral">&quot; &quot;</span>;</div><div class="line">            std::cout &lt;&lt; std::endl;</div><div class="line">            <span class="keywordflow">return</span> 1;</div><div class="line">         }</div><div class="line">         Use[regMethod] = 1;</div><div class="line">      }</div><div class="line">   }</div><div class="line"></div><div class="line">   <span class="comment">// --------------------------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line">   <span class="comment">// Here the preparation phase begins</span></div><div class="line"></div><div class="line">   <span class="comment">// Read training and test data</span></div><div class="line">   <span class="comment">// (it is also possible to use ASCII format as input -&gt; see TMVA Users Guide)</span></div><div class="line">   <a class="code" href="classTFile.html">TFile</a> *input(0);</div><div class="line">   <a class="code" href="classTString.html">TString</a> fname = <span class="stringliteral">&quot;./tmva_class_example.root&quot;</span>;</div><div class="line">   <span class="keywordflow">if</span> (!<a class="code" href="TSystem_8h.html#ab7182c9ab5a9236e2bc1ed8b3fcb045f">gSystem</a>-&gt;<a class="code" href="classTSystem.html#a849c28ea0dd3b3aa3310a4d447c7b21a">AccessPathName</a>( fname )) {</div><div class="line">      input = <a class="code" href="classTFile.html#aec5f3fae0774aabfc615ebb4b00fe5e0">TFile::Open</a>( fname ); <span class="comment">// check if file in local directory exists</span></div><div class="line">   }</div><div class="line">   <span class="keywordflow">else</span> {</div><div class="line">      <a class="code" href="classTFile.html#ab80316ea9ebda1357aefeb83eb45aab2">TFile::SetCacheFileDir</a>(<span class="stringliteral">&quot;.&quot;</span>);</div><div class="line">      input = <a class="code" href="classTFile.html#aec5f3fae0774aabfc615ebb4b00fe5e0">TFile::Open</a>(<span class="stringliteral">&quot;http://root.cern.ch/files/tmva_class_example.root&quot;</span>, <span class="stringliteral">&quot;CACHEREAD&quot;</span>);</div><div class="line">   }</div><div class="line">   <span class="keywordflow">if</span> (!input) {</div><div class="line">      std::cout &lt;&lt; <span class="stringliteral">&quot;ERROR: could not open data file&quot;</span> &lt;&lt; std::endl;</div><div class="line">      exit(1);</div><div class="line">   }</div><div class="line">   std::cout &lt;&lt; <span class="stringliteral">&quot;--- TMVAClassification       : Using input file: &quot;</span> &lt;&lt; input-&gt;<a class="code" href="classTCollection.html#a3cc7d60e72049ef09935e5020c3bbf9f">GetName</a>() &lt;&lt; std::endl;</div><div class="line"></div><div class="line">   <span class="comment">// Register the training and test trees</span></div><div class="line"></div><div class="line">   <a class="code" href="classTTree.html">TTree</a> *signalTree     = (<a class="code" href="classTTree.html">TTree</a>*)input-&gt;Get(<span class="stringliteral">&quot;TreeS&quot;</span>);</div><div class="line">   <a class="code" href="classTTree.html">TTree</a> *background     = (<a class="code" href="classTTree.html">TTree</a>*)input-&gt;Get(<span class="stringliteral">&quot;TreeB&quot;</span>);</div><div class="line"></div><div class="line">   <span class="comment">// Create a ROOT output file where TMVA will store ntuples, histograms, etc.</span></div><div class="line">   <a class="code" href="classTString.html">TString</a> outfileName( <span class="stringliteral">&quot;TMVA.root&quot;</span> );</div><div class="line">   <a class="code" href="classTFile.html">TFile</a>* outputFile = <a class="code" href="classTFile.html#aec5f3fae0774aabfc615ebb4b00fe5e0">TFile::Open</a>( outfileName, <span class="stringliteral">&quot;RECREATE&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Create the factory object. Later you can choose the methods</span></div><div class="line">   <span class="comment">// whose performance you&#39;d like to investigate. The factory is</span></div><div class="line">   <span class="comment">// the only TMVA object you have to interact with</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// The first argument is the base of the name of all the</span></div><div class="line">   <span class="comment">// weightfiles in the directory weight/</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// The second argument is the output file for the training results</span></div><div class="line">   <span class="comment">// All TMVA output can be suppressed by removing the &quot;!&quot; (not) in</span></div><div class="line">   <span class="comment">// front of the &quot;Silent&quot; argument in the option string</span></div><div class="line">   <a class="code" href="classTMVA_1_1Factory.html">TMVA::Factory</a> *factory = <span class="keyword">new</span> <a class="code" href="classTMVA_1_1Factory.html">TMVA::Factory</a>( <span class="stringliteral">&quot;TMVAClassification&quot;</span>, outputFile,</div><div class="line">                                               <span class="stringliteral">&quot;!V:!Silent:Color:DrawProgressBar:Transformations=I;D;P;G,D:AnalysisType=Classification&quot;</span> );</div><div class="line"></div><div class="line">   <a class="code" href="classTMVA_1_1DataLoader.html">TMVA::DataLoader</a> *dataloader=<span class="keyword">new</span> <a class="code" href="classTMVA_1_1DataLoader.html">TMVA::DataLoader</a>(<span class="stringliteral">&quot;dataset&quot;</span>);</div><div class="line">   <span class="comment">// If you wish to modify default settings</span></div><div class="line">   <span class="comment">// (please check &quot;src/Config.h&quot; to see all available global options)</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//    (TMVA::gConfig().GetVariablePlotting()).fTimesRMS = 8.0;</span></div><div class="line">   <span class="comment">//    (TMVA::gConfig().GetIONames()).fWeightFileDir = &quot;myWeightDirectory&quot;;</span></div><div class="line"></div><div class="line">   <span class="comment">// Define the input variables that shall be used for the MVA training</span></div><div class="line">   <span class="comment">// note that you may also use variable expressions, such as: &quot;3*var1/var2*abs(var3)&quot;</span></div><div class="line">   <span class="comment">// [all types of expressions that can also be parsed by TTree::Draw( &quot;expression&quot; )]</span></div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#af2de13debc441fd2c4f1cd826ef175f9">AddVariable</a>( <span class="stringliteral">&quot;myvar1 := var1+var2&quot;</span>, <span class="charliteral">&#39;F&#39;</span> );</div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#af2de13debc441fd2c4f1cd826ef175f9">AddVariable</a>( <span class="stringliteral">&quot;myvar2 := var1-var2&quot;</span>, <span class="stringliteral">&quot;Expression 2&quot;</span>, <span class="stringliteral">&quot;&quot;</span>, <span class="charliteral">&#39;F&#39;</span> );</div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#af2de13debc441fd2c4f1cd826ef175f9">AddVariable</a>( <span class="stringliteral">&quot;var3&quot;</span>,                <span class="stringliteral">&quot;Variable 3&quot;</span>, <span class="stringliteral">&quot;units&quot;</span>, <span class="charliteral">&#39;F&#39;</span> );</div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#af2de13debc441fd2c4f1cd826ef175f9">AddVariable</a>( <span class="stringliteral">&quot;var4&quot;</span>,                <span class="stringliteral">&quot;Variable 4&quot;</span>, <span class="stringliteral">&quot;units&quot;</span>, <span class="charliteral">&#39;F&#39;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// You can add so-called &quot;Spectator variables&quot;, which are not used in the MVA training,</span></div><div class="line">   <span class="comment">// but will appear in the final &quot;TestTree&quot; produced by TMVA. This TestTree will contain the</span></div><div class="line">   <span class="comment">// input variables, the response values of all trained MVAs, and the spectator variables</span></div><div class="line"></div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#a1645ca8eca7338d719f1e38c944af1ee">AddSpectator</a>( <span class="stringliteral">&quot;spec1 := var1*2&quot;</span>,  <span class="stringliteral">&quot;Spectator 1&quot;</span>, <span class="stringliteral">&quot;units&quot;</span>, <span class="charliteral">&#39;F&#39;</span> );</div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#a1645ca8eca7338d719f1e38c944af1ee">AddSpectator</a>( <span class="stringliteral">&quot;spec2 := var1*3&quot;</span>,  <span class="stringliteral">&quot;Spectator 2&quot;</span>, <span class="stringliteral">&quot;units&quot;</span>, <span class="charliteral">&#39;F&#39;</span> );</div><div class="line"></div><div class="line"></div><div class="line">   <span class="comment">// global event weights per tree (see below for setting event-wise weights)</span></div><div class="line">   <a class="code" href="RtypesCore_8h.html#ab9b5334647b78ec4256db251e3ae1fc6">Double_t</a> signalWeight     = 1.0;</div><div class="line">   <a class="code" href="RtypesCore_8h.html#ab9b5334647b78ec4256db251e3ae1fc6">Double_t</a> backgroundWeight = 1.0;</div><div class="line"></div><div class="line">   <span class="comment">// You can add an arbitrary number of signal or background trees</span></div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#a13af6fea089757545abfdb2cee9a6ff4">AddSignalTree</a>    ( signalTree,     signalWeight );</div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#a7d02fd365801a0d582f04b8c9d1cf3f5">AddBackgroundTree</a>( background, backgroundWeight );</div><div class="line"></div><div class="line">   <span class="comment">// To give different trees for training and testing, do as follows:</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//     dataloader-&gt;AddSignalTree( signalTrainingTree, signalTrainWeight, &quot;Training&quot; );</span></div><div class="line">   <span class="comment">//     dataloader-&gt;AddSignalTree( signalTestTree,     signalTestWeight,  &quot;Test&quot; );</span></div><div class="line"></div><div class="line">   <span class="comment">// Use the following code instead of the above two or four lines to add signal and background</span></div><div class="line">   <span class="comment">// training and test events &quot;by hand&quot;</span></div><div class="line">   <span class="comment">// NOTE that in this case one should not give expressions (such as &quot;var1+var2&quot;) in the input</span></div><div class="line">   <span class="comment">//      variable definition, but simply compute the expression before adding the event</span></div><div class="line">   <span class="comment">// ```cpp</span></div><div class="line">   <span class="comment">// // --- begin ----------------------------------------------------------</span></div><div class="line">   <span class="comment">// std::vector&lt;Double_t&gt; vars( 4 ); // vector has size of number of input variables</span></div><div class="line">   <span class="comment">// Float_t  treevars[4], weight;</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// // Signal</span></div><div class="line">   <span class="comment">// for (UInt_t ivar=0; ivar&lt;4; ivar++) signalTree-&gt;SetBranchAddress( Form( &quot;var%i&quot;, ivar+1 ), &amp;(treevars[ivar]) );</span></div><div class="line">   <span class="comment">// for (UInt_t i=0; i&lt;signalTree-&gt;GetEntries(); i++) {</span></div><div class="line">   <span class="comment">//    signalTree-&gt;GetEntry(i);</span></div><div class="line">   <span class="comment">//    for (UInt_t ivar=0; ivar&lt;4; ivar++) vars[ivar] = treevars[ivar];</span></div><div class="line">   <span class="comment">//    // add training and test events; here: first half is training, second is testing</span></div><div class="line">   <span class="comment">//    // note that the weight can also be event-wise</span></div><div class="line">   <span class="comment">//    if (i &lt; signalTree-&gt;GetEntries()/2.0) dataloader-&gt;AddSignalTrainingEvent( vars, signalWeight );</span></div><div class="line">   <span class="comment">//    else                              dataloader-&gt;AddSignalTestEvent    ( vars, signalWeight );</span></div><div class="line">   <span class="comment">// }</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// // Background (has event weights)</span></div><div class="line">   <span class="comment">// background-&gt;SetBranchAddress( &quot;weight&quot;, &amp;weight );</span></div><div class="line">   <span class="comment">// for (UInt_t ivar=0; ivar&lt;4; ivar++) background-&gt;SetBranchAddress( Form( &quot;var%i&quot;, ivar+1 ), &amp;(treevars[ivar]) );</span></div><div class="line">   <span class="comment">// for (UInt_t i=0; i&lt;background-&gt;GetEntries(); i++) {</span></div><div class="line">   <span class="comment">//    background-&gt;GetEntry(i);</span></div><div class="line">   <span class="comment">//    for (UInt_t ivar=0; ivar&lt;4; ivar++) vars[ivar] = treevars[ivar];</span></div><div class="line">   <span class="comment">//    // add training and test events; here: first half is training, second is testing</span></div><div class="line">   <span class="comment">//    // note that the weight can also be event-wise</span></div><div class="line">   <span class="comment">//    if (i &lt; background-&gt;GetEntries()/2) dataloader-&gt;AddBackgroundTrainingEvent( vars, backgroundWeight*weight );</span></div><div class="line">   <span class="comment">//    else                                dataloader-&gt;AddBackgroundTestEvent    ( vars, backgroundWeight*weight );</span></div><div class="line">   <span class="comment">// }</span></div><div class="line">   <span class="comment">// // --- end ------------------------------------------------------------</span></div><div class="line">   <span class="comment">// ```</span></div><div class="line">   <span class="comment">// End of tree registration</span></div><div class="line"></div><div class="line">   <span class="comment">// Set individual event weights (the variables must exist in the original TTree)</span></div><div class="line">   <span class="comment">// -  for signal    : `dataloader-&gt;SetSignalWeightExpression    (&quot;weight1*weight2&quot;);`</span></div><div class="line">   <span class="comment">// -  for background: `dataloader-&gt;SetBackgroundWeightExpression(&quot;weight1*weight2&quot;);`</span></div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#a649a4e48c9de7ebbf237ef89bdbcbe93">SetBackgroundWeightExpression</a>( <span class="stringliteral">&quot;weight&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Apply additional cuts on the signal and background samples (can be different)</span></div><div class="line">   <a class="code" href="classTCut.html">TCut</a> mycuts = <span class="stringliteral">&quot;&quot;</span>; <span class="comment">// for example: TCut mycuts = &quot;abs(var1)&lt;0.5 &amp;&amp; abs(var2-0.5)&lt;1&quot;;</span></div><div class="line">   <a class="code" href="classTCut.html">TCut</a> mycutb = <span class="stringliteral">&quot;&quot;</span>; <span class="comment">// for example: TCut mycutb = &quot;abs(var1)&lt;0.5&quot;;</span></div><div class="line"></div><div class="line">   <span class="comment">// Tell the dataloader how to use the training and testing events</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// If no numbers of events are given, half of the events in the tree are used</span></div><div class="line">   <span class="comment">// for training, and the other half for testing:</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//    dataloader-&gt;PrepareTrainingAndTestTree( mycut, &quot;SplitMode=random:!V&quot; );</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// To also specify the number of testing events, use:</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//    dataloader-&gt;PrepareTrainingAndTestTree( mycut,</span></div><div class="line">   <span class="comment">//         &quot;NSigTrain=3000:NBkgTrain=3000:NSigTest=3000:NBkgTest=3000:SplitMode=Random:!V&quot; );</span></div><div class="line">   dataloader-&gt;<a class="code" href="classTMVA_1_1DataLoader.html#a742cf7f305d881b261acc137fd6d84c1">PrepareTrainingAndTestTree</a>( mycuts, mycutb,</div><div class="line">                                        <span class="stringliteral">&quot;nTrain_Signal=1000:nTrain_Background=1000:SplitMode=Random:NormMode=NumEvents:!V&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// ### Book MVA methods</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Please lookup the various method configuration options in the corresponding cxx files, eg:</span></div><div class="line">   <span class="comment">// src/MethoCuts.cxx, etc, or here: http://tmva.sourceforge.net/optionRef.html</span></div><div class="line">   <span class="comment">// it is possible to preset ranges in the option string in which the cut optimisation should be done:</span></div><div class="line">   <span class="comment">// &quot;...:CutRangeMin[2]=-1:CutRangeMax[2]=1&quot;...&quot;, where [2] is the third input variable</span></div><div class="line"></div><div class="line">   <span class="comment">// Cut optimisation</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;Cuts&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a806bede9cf4ac1a8e748a94eecd78ce1">TMVA::Types::kCuts</a>, <span class="stringliteral">&quot;Cuts&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:FitMethod=MC:EffSel:SampleSize=200000:VarProp=FSmart&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;CutsD&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a806bede9cf4ac1a8e748a94eecd78ce1">TMVA::Types::kCuts</a>, <span class="stringliteral">&quot;CutsD&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:FitMethod=MC:EffSel:SampleSize=200000:VarProp=FSmart:VarTransform=Decorrelate&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;CutsPCA&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a806bede9cf4ac1a8e748a94eecd78ce1">TMVA::Types::kCuts</a>, <span class="stringliteral">&quot;CutsPCA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:FitMethod=MC:EffSel:SampleSize=200000:VarProp=FSmart:VarTransform=PCA&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;CutsGA&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a806bede9cf4ac1a8e748a94eecd78ce1">TMVA::Types::kCuts</a>, <span class="stringliteral">&quot;CutsGA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:FitMethod=GA:CutRangeMin[0]=-10:CutRangeMax[0]=10:VarProp[1]=FMax:EffSel:Steps=30:Cycles=3:PopSize=400:SC_steps=10:SC_rate=5:SC_factor=0.95&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;CutsSA&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a806bede9cf4ac1a8e748a94eecd78ce1">TMVA::Types::kCuts</a>, <span class="stringliteral">&quot;CutsSA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:FitMethod=SA:EffSel:MaxCalls=150000:KernelTemp=IncAdaptive:InitialTemp=1e+6:MinTemp=1e-6:Eps=1e-10:UseDefaultScale&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Likelihood (&quot;naive Bayes estimator&quot;)</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;Likelihood&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a7714dc1bffecd499511751038b5c856c">TMVA::Types::kLikelihood</a>, <span class="stringliteral">&quot;Likelihood&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmoothBkg[1]=10:NSmooth=1:NAvEvtPerBin=50&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Decorrelated likelihood</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;LikelihoodD&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a7714dc1bffecd499511751038b5c856c">TMVA::Types::kLikelihood</a>, <span class="stringliteral">&quot;LikelihoodD&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmooth=5:NAvEvtPerBin=50:VarTransform=Decorrelate&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// PCA-transformed likelihood</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;LikelihoodPCA&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a7714dc1bffecd499511751038b5c856c">TMVA::Types::kLikelihood</a>, <span class="stringliteral">&quot;LikelihoodPCA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:!TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmooth=5:NAvEvtPerBin=50:VarTransform=PCA&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Use a kernel density estimator to approximate the PDFs</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;LikelihoodKDE&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a7714dc1bffecd499511751038b5c856c">TMVA::Types::kLikelihood</a>, <span class="stringliteral">&quot;LikelihoodKDE&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:!TransformOutput:PDFInterpol=KDE:KDEtype=Gauss:KDEiter=Adaptive:KDEFineFactor=0.3:KDEborder=None:NAvEvtPerBin=50&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Use a variable-dependent mix of splines and kernel density estimator</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;LikelihoodMIX&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a7714dc1bffecd499511751038b5c856c">TMVA::Types::kLikelihood</a>, <span class="stringliteral">&quot;LikelihoodMIX&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:!TransformOutput:PDFInterpolSig[0]=KDE:PDFInterpolBkg[0]=KDE:PDFInterpolSig[1]=KDE:PDFInterpolBkg[1]=KDE:PDFInterpolSig[2]=Spline2:PDFInterpolBkg[2]=Spline2:PDFInterpolSig[3]=Spline2:PDFInterpolBkg[3]=Spline2:KDEtype=Gauss:KDEiter=Nonadaptive:KDEborder=None:NAvEvtPerBin=50&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Test the multi-dimensional probability density estimator</span></div><div class="line">   <span class="comment">// here are the options strings for the MinMax and RMS methods, respectively:</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//      &quot;!H:!V:VolumeRangeMode=MinMax:DeltaFrac=0.2:KernelEstimator=Gauss:GaussSigma=0.3&quot; );</span></div><div class="line">   <span class="comment">//      &quot;!H:!V:VolumeRangeMode=RMS:DeltaFrac=3:KernelEstimator=Gauss:GaussSigma=0.3&quot; );</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;PDERS&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a4bf8ee43e81a294ab0f7344cc6e52bc1">TMVA::Types::kPDERS</a>, <span class="stringliteral">&quot;PDERS&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:NormTree=T:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=400:NEventsMax=600&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;PDERSD&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a4bf8ee43e81a294ab0f7344cc6e52bc1">TMVA::Types::kPDERS</a>, <span class="stringliteral">&quot;PDERSD&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=400:NEventsMax=600:VarTransform=Decorrelate&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;PDERSPCA&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a4bf8ee43e81a294ab0f7344cc6e52bc1">TMVA::Types::kPDERS</a>, <span class="stringliteral">&quot;PDERSPCA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=400:NEventsMax=600:VarTransform=PCA&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Multi-dimensional likelihood estimator using self-adapting phase-space binning</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;PDEFoam&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a70d3b2a6fbd11efcb41d4afe0114b8a9">TMVA::Types::kPDEFoam</a>, <span class="stringliteral">&quot;PDEFoam&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:SigBgSeparate=F:TailCut=0.001:VolFrac=0.0666:nActiveCells=500:nSampl=2000:nBin=5:Nmin=100:Kernel=None:Compress=T&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;PDEFoamBoost&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a70d3b2a6fbd11efcb41d4afe0114b8a9">TMVA::Types::kPDEFoam</a>, <span class="stringliteral">&quot;PDEFoamBoost&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:Boost_Num=30:Boost_Transform=linear:SigBgSeparate=F:MaxDepth=4:UseYesNoCell=T:DTLogic=MisClassificationError:FillFoamWithOrigWeights=F:TailCut=0:nActiveCells=500:nBin=20:Nmin=400:Kernel=None:Compress=T&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// K-Nearest Neighbour classifier (KNN)</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;KNN&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4ae1b897fc18d826ada2e388b5b1a1c811">TMVA::Types::kKNN</a>, <span class="stringliteral">&quot;KNN&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:nkNN=20:ScaleFrac=0.8:SigmaFact=1.0:Kernel=Gaus:UseKernel=F:UseWeight=T:!Trim&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// H-Matrix (chi2-squared) method</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;HMatrix&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a9f211176139e5851691513c5cc96cfe3">TMVA::Types::kHMatrix</a>, <span class="stringliteral">&quot;HMatrix&quot;</span>, <span class="stringliteral">&quot;!H:!V:VarTransform=None&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Linear discriminant (same as Fisher discriminant)</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;LD&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a9703cef4f79c5512307bcf79d5468cb1">TMVA::Types::kLD</a>, <span class="stringliteral">&quot;LD&quot;</span>, <span class="stringliteral">&quot;H:!V:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Fisher discriminant (same as LD)</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;Fisher&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a0284b43ce457b9b105fdfe0fc32dc5c8">TMVA::Types::kFisher</a>, <span class="stringliteral">&quot;Fisher&quot;</span>, <span class="stringliteral">&quot;H:!V:Fisher:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Fisher with Gauss-transformed input variables</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FisherG&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a0284b43ce457b9b105fdfe0fc32dc5c8">TMVA::Types::kFisher</a>, <span class="stringliteral">&quot;FisherG&quot;</span>, <span class="stringliteral">&quot;H:!V:VarTransform=Gauss&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Composite classifier: ensemble (tree) of boosted Fisher classifiers</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;BoostedFisher&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a0284b43ce457b9b105fdfe0fc32dc5c8">TMVA::Types::kFisher</a>, <span class="stringliteral">&quot;BoostedFisher&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Boost_Num=20:Boost_Transform=log:Boost_Type=AdaBoost:Boost_AdaBoostBeta=0.2:!Boost_DetailedMonitoring&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Function discrimination analysis (FDA) -- test of various fitters - the recommended one is Minuit (or GA or SA)</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FDA_MC&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a467ff5fbcffabbed1884541c63e1954d">TMVA::Types::kFDA</a>, <span class="stringliteral">&quot;FDA_MC&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=MC:SampleSize=100000:Sigma=0.1&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FDA_GA&quot;</span>]) <span class="comment">// can also use Simulated Annealing (SA) algorithm (see Cuts_SA options])</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a467ff5fbcffabbed1884541c63e1954d">TMVA::Types::kFDA</a>, <span class="stringliteral">&quot;FDA_GA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=GA:PopSize=100:Cycles=2:Steps=5:Trim=True:SaveBestGen=1&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FDA_SA&quot;</span>]) <span class="comment">// can also use Simulated Annealing (SA) algorithm (see Cuts_SA options])</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a467ff5fbcffabbed1884541c63e1954d">TMVA::Types::kFDA</a>, <span class="stringliteral">&quot;FDA_SA&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=SA:MaxCalls=15000:KernelTemp=IncAdaptive:InitialTemp=1e+6:MinTemp=1e-6:Eps=1e-10:UseDefaultScale&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FDA_MT&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a467ff5fbcffabbed1884541c63e1954d">TMVA::Types::kFDA</a>, <span class="stringliteral">&quot;FDA_MT&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=2:UseImprove:UseMinos:SetBatch&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FDA_GAMT&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a467ff5fbcffabbed1884541c63e1954d">TMVA::Types::kFDA</a>, <span class="stringliteral">&quot;FDA_GAMT&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=GA:Converger=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=0:!UseImprove:!UseMinos:SetBatch:Cycles=1:PopSize=5:Steps=5:Trim&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;FDA_MCMT&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a467ff5fbcffabbed1884541c63e1954d">TMVA::Types::kFDA</a>, <span class="stringliteral">&quot;FDA_MCMT&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:Formula=(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3:ParRanges=(-1,1);(-10,10);(-10,10);(-10,10);(-10,10):FitMethod=MC:Converger=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=0:!UseImprove:!UseMinos:SetBatch:SampleSize=20&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// TMVA ANN: MLP (recommended ANN) -- all ANNs in TMVA are Multilayer Perceptrons</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;MLP&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4aeb53e99f5495027fc36aac2e16fe78b0">TMVA::Types::kMLP</a>, <span class="stringliteral">&quot;MLP&quot;</span>, <span class="stringliteral">&quot;H:!V:NeuronType=tanh:VarTransform=N:NCycles=600:HiddenLayers=N+5:TestRate=5:!UseRegulator&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;MLPBFGS&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4aeb53e99f5495027fc36aac2e16fe78b0">TMVA::Types::kMLP</a>, <span class="stringliteral">&quot;MLPBFGS&quot;</span>, <span class="stringliteral">&quot;H:!V:NeuronType=tanh:VarTransform=N:NCycles=600:HiddenLayers=N+5:TestRate=5:TrainingMethod=BFGS:!UseRegulator&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;MLPBNN&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4aeb53e99f5495027fc36aac2e16fe78b0">TMVA::Types::kMLP</a>, <span class="stringliteral">&quot;MLPBNN&quot;</span>, <span class="stringliteral">&quot;H:!V:NeuronType=tanh:VarTransform=N:NCycles=60:HiddenLayers=N+5:TestRate=5:TrainingMethod=BFGS:UseRegulator&quot;</span> ); <span class="comment">// BFGS training with bayesian regulators</span></div><div class="line"></div><div class="line"></div><div class="line">   <span class="comment">// Multi-architecture DNN implementation.</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;DNN_CPU&quot;</span>] or Use[<span class="stringliteral">&quot;DNN_GPU&quot;</span>]) {</div><div class="line">      <span class="comment">// General layout.</span></div><div class="line">      <a class="code" href="classTString.html">TString</a> layoutString (<span class="stringliteral">&quot;Layout=TANH|128,TANH|128,TANH|128,LINEAR&quot;</span>);</div><div class="line"></div><div class="line">      <span class="comment">// Training strategies.</span></div><div class="line">      <a class="code" href="classTString.html">TString</a> training0(<span class="stringliteral">&quot;LearningRate=1e-2,Momentum=0.9,Repetitions=1,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;ConvergenceSteps=30,BatchSize=256,TestRepetitions=10,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;WeightDecay=1e-4,Regularization=None,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;DropConfig=0.0+0.5+0.5+0.5, Multithreading=True&quot;</span>);</div><div class="line">      <a class="code" href="classTString.html">TString</a> training1(<span class="stringliteral">&quot;LearningRate=1e-2,Momentum=0.9,Repetitions=1,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;WeightDecay=1e-4,Regularization=L2,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;DropConfig=0.0+0.0+0.0+0.0, Multithreading=True&quot;</span>);</div><div class="line">      <a class="code" href="classTString.html">TString</a> training2(<span class="stringliteral">&quot;LearningRate=1e-3,Momentum=0.0,Repetitions=1,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;ConvergenceSteps=20,BatchSize=256,TestRepetitions=10,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;WeightDecay=1e-4,Regularization=L2,&quot;</span></div><div class="line">                        <span class="stringliteral">&quot;DropConfig=0.0+0.0+0.0+0.0, Multithreading=True&quot;</span>);</div><div class="line">      <a class="code" href="classTString.html">TString</a> trainingStrategyString (<span class="stringliteral">&quot;TrainingStrategy=&quot;</span>);</div><div class="line">      trainingStrategyString += training0 + <span class="stringliteral">&quot;|&quot;</span> + training1 + <span class="stringliteral">&quot;|&quot;</span> + training2;</div><div class="line"></div><div class="line">      <span class="comment">// General Options.</span></div><div class="line">      <a class="code" href="classTString.html">TString</a> dnnOptions (<span class="stringliteral">&quot;!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:&quot;</span></div><div class="line">                          <span class="stringliteral">&quot;WeightInitialization=XAVIERUNIFORM&quot;</span>);</div><div class="line">      dnnOptions.Append (<span class="stringliteral">&quot;:&quot;</span>); dnnOptions.Append (layoutString);</div><div class="line">      dnnOptions.Append (<span class="stringliteral">&quot;:&quot;</span>); dnnOptions.Append (trainingStrategyString);</div><div class="line"></div><div class="line">      <span class="comment">// Cuda implementation.</span></div><div class="line">      <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;DNN_GPU&quot;</span>]) {</div><div class="line">         <a class="code" href="classTString.html">TString</a> gpuOptions = dnnOptions + <span class="stringliteral">&quot;:Architecture=GPU&quot;</span>;</div><div class="line">         factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>(dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a6031ecb75dc6a656a910cba27f648b5c">TMVA::Types::kDL</a>, <span class="stringliteral">&quot;DNN_GPU&quot;</span>, gpuOptions);</div><div class="line">      }</div><div class="line">      <span class="comment">// Multi-core CPU implementation.</span></div><div class="line">      <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;DNN_CPU&quot;</span>]) {</div><div class="line">         <a class="code" href="classTString.html">TString</a> cpuOptions = dnnOptions + <span class="stringliteral">&quot;:Architecture=CPU&quot;</span>;</div><div class="line">         factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>(dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a6031ecb75dc6a656a910cba27f648b5c">TMVA::Types::kDL</a>, <span class="stringliteral">&quot;DNN_CPU&quot;</span>, cpuOptions);</div><div class="line">      }</div><div class="line">   }</div><div class="line"></div><div class="line">   <span class="comment">// CF(Clermont-Ferrand)ANN</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;CFMlpANN&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4ac726d6cbe69eaa63b19c8b3e6a18980e">TMVA::Types::kCFMlpANN</a>, <span class="stringliteral">&quot;CFMlpANN&quot;</span>, <span class="stringliteral">&quot;!H:!V:NCycles=200:HiddenLayers=N+1,N&quot;</span>  ); <span class="comment">// n_cycles:#nodes:#nodes:...</span></div><div class="line"></div><div class="line">   <span class="comment">// Tmlp(Root)ANN</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;TMlpANN&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a3f1d13692d5783512e84e7a08e65532b">TMVA::Types::kTMlpANN</a>, <span class="stringliteral">&quot;TMlpANN&quot;</span>, <span class="stringliteral">&quot;!H:!V:NCycles=200:HiddenLayers=N+1,N:LearningMethod=BFGS:ValidationFraction=0.3&quot;</span>  ); <span class="comment">// n_cycles:#nodes:#nodes:...</span></div><div class="line"></div><div class="line">   <span class="comment">// Support Vector Machine</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;SVM&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4aab53e6318fcdac6dbe6fbb49833f4a99">TMVA::Types::kSVM</a>, <span class="stringliteral">&quot;SVM&quot;</span>, <span class="stringliteral">&quot;Gamma=0.25:Tol=0.001:VarTransform=Norm&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// Boosted Decision Trees</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;BDTG&quot;</span>]) <span class="comment">// Gradient Boost</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a46c14cfe1e0a9775c970561a4f978365">TMVA::Types::kBDT</a>, <span class="stringliteral">&quot;BDTG&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad:Shrinkage=0.10:UseBaggedBoost:BaggedSampleFraction=0.5:nCuts=20:MaxDepth=2&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;BDT&quot;</span>])  <span class="comment">// Adaptive Boost</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a46c14cfe1e0a9775c970561a4f978365">TMVA::Types::kBDT</a>, <span class="stringliteral">&quot;BDT&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:NTrees=850:MinNodeSize=2.5%:MaxDepth=3:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;BDTB&quot;</span>]) <span class="comment">// Bagging</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a46c14cfe1e0a9775c970561a4f978365">TMVA::Types::kBDT</a>, <span class="stringliteral">&quot;BDTB&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:NTrees=400:BoostType=Bagging:SeparationType=GiniIndex:nCuts=20&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;BDTD&quot;</span>]) <span class="comment">// Decorrelation + Adaptive Boost</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a46c14cfe1e0a9775c970561a4f978365">TMVA::Types::kBDT</a>, <span class="stringliteral">&quot;BDTD&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:NTrees=400:MinNodeSize=5%:MaxDepth=3:BoostType=AdaBoost:SeparationType=GiniIndex:nCuts=20:VarTransform=Decorrelate&quot;</span> );</div><div class="line"></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;BDTF&quot;</span>])  <span class="comment">// Allow Using Fisher discriminant in node splitting for (strong) linearly correlated variables</span></div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4a46c14cfe1e0a9775c970561a4f978365">TMVA::Types::kBDT</a>, <span class="stringliteral">&quot;BDTF&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;!H:!V:NTrees=50:MinNodeSize=2.5%:UseFisherCuts:MaxDepth=3:BoostType=AdaBoost:AdaBoostBeta=0.5:SeparationType=GiniIndex:nCuts=20&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// RuleFit -- TMVA implementation of Friedman&#39;s method</span></div><div class="line">   <span class="keywordflow">if</span> (Use[<span class="stringliteral">&quot;RuleFit&quot;</span>])</div><div class="line">      factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a35c42e83410f857150bb2c150bb97474">BookMethod</a>( dataloader, <a class="code" href="classTMVA_1_1Types.html#a7d01ee235ade56ae570e2c9f83464fc4ac4f0714d5f4e528e679b472fcbbff9c8">TMVA::Types::kRuleFit</a>, <span class="stringliteral">&quot;RuleFit&quot;</span>,</div><div class="line">                           <span class="stringliteral">&quot;H:!V:RuleFitModule=RFTMVA:Model=ModRuleLinear:MinImp=0.001:RuleMinDist=0.001:NTrees=20:fEventsMin=0.01:fEventsMax=0.5:GDTau=-1.0:GDTauPrec=0.01:GDStep=0.01:GDNSteps=10000:GDErrScale=1.02&quot;</span> );</div><div class="line"></div><div class="line">   <span class="comment">// For an example of the category classifier usage, see: TMVAClassificationCategory</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// --------------------------------------------------------------------------------------------------</span></div><div class="line">   <span class="comment">//  Now you can optimize the setting (configuration) of the MVAs using the set of training events</span></div><div class="line">   <span class="comment">// STILL EXPERIMENTAL and only implemented for BDT&#39;s !</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">//     factory-&gt;OptimizeAllMethods(&quot;SigEffAt001&quot;,&quot;Scan&quot;);</span></div><div class="line">   <span class="comment">//     factory-&gt;OptimizeAllMethods(&quot;ROCIntegral&quot;,&quot;FitGA&quot;);</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// --------------------------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line">   <span class="comment">// Now you can tell the factory to train, test, and evaluate the MVAs</span></div><div class="line">   <span class="comment">//</span></div><div class="line">   <span class="comment">// Train MVAs using the set of training events</span></div><div class="line">   factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a1f15a459cb39f164ede2679ce065b0b6">TrainAllMethods</a>();</div><div class="line"></div><div class="line">   <span class="comment">// Evaluate all MVAs using the set of test events</span></div><div class="line">   factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a3c9b841c84de61b062b2ede5eac44731">TestAllMethods</a>();</div><div class="line"></div><div class="line">   <span class="comment">// Evaluate and compare performance of all configured MVAs</span></div><div class="line">   factory-&gt;<a class="code" href="classTMVA_1_1Factory.html#a4505a3bcad6a5540cd955e41a0f36c74">EvaluateAllMethods</a>();</div><div class="line"></div><div class="line">   <span class="comment">// --------------------------------------------------------------</span></div><div class="line"></div><div class="line">   <span class="comment">// Save the output</span></div><div class="line">   outputFile-&gt;<a class="code" href="classTFile.html#a1eaf64e1803291558efe5d3238c661a4">Close</a>();</div><div class="line"></div><div class="line">   std::cout &lt;&lt; <span class="stringliteral">&quot;==&gt; Wrote root file: &quot;</span> &lt;&lt; outputFile-&gt;<a class="code" href="classTNamed.html#a42e3142d30b08fed1b07216d4a36b090">GetName</a>() &lt;&lt; std::endl;</div><div class="line">   std::cout &lt;&lt; <span class="stringliteral">&quot;==&gt; TMVAClassification is done!&quot;</span> &lt;&lt; std::endl;</div><div class="line"></div><div class="line">   <span class="keyword">delete</span> factory;</div><div class="line">   <span class="keyword">delete</span> dataloader;</div><div class="line">   <span class="comment">// Launch the GUI for the root macros</span></div><div class="line">   <span class="keywordflow">if</span> (!<a class="code" href="TROOT_8h.html#a851dd11b3478372a25ba6eff6dcfa5b1">gROOT</a>-&gt;IsBatch()) <a class="code" href="namespaceTMVA.html#aed22b7f962ad35546df7cc0a1e6705df">TMVA::TMVAGui</a>( outfileName );</div><div class="line"></div><div class="line">   <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> <a class="code" href="histspeedtest_8cxx.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a>( <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv )</div><div class="line">{</div><div class="line">   <span class="comment">// Select methods (don&#39;t look at this code - not of interest)</span></div><div class="line">   <a class="code" href="classTString.html">TString</a> methodList;</div><div class="line">   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=1; i&lt;argc; i++) {</div><div class="line">      <a class="code" href="classTString.html">TString</a> regMethod(argv[i]);</div><div class="line">      <span class="keywordflow">if</span>(regMethod==<span class="stringliteral">&quot;-b&quot;</span> || regMethod==<span class="stringliteral">&quot;--batch&quot;</span>) <span class="keywordflow">continue</span>;</div><div class="line">      <span class="keywordflow">if</span> (!methodList.<a class="code" href="classTString.html#a85b40d2d4ea6be7b6d3881145bb178b8">IsNull</a>()) methodList += <a class="code" href="classTString.html">TString</a>(<span class="stringliteral">&quot;,&quot;</span>);</div><div class="line">      methodList += regMethod;</div><div class="line">   }</div><div class="line">   <span class="keywordflow">return</span> TMVAClassification(methodList);</div><div class="line">}</div></div><!-- fragment --> <dl class="section author"><dt>Author</dt><dd>Andreas Hoecker </dd></dl>

<p class="definition">Definition in file <a class="el" href="TMVAClassification_8C_source.html">TMVAClassification.C</a>.</p>
</div></div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:10:30 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
