<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: tmva/tmva/inc/TMVA/NeuralNet.icc Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a647c3f16b21786eaaa28427c9c80e3e.html">tmva</a></li><li class="navelem"><a class="el" href="dir_ed3dab6383bd5f321850908cd5a1281f.html">tmva</a></li><li class="navelem"><a class="el" href="dir_e5f324a990c4e53e87e3a4847f1d2164.html">inc</a></li><li class="navelem"><a class="el" href="dir_b2d93ebd3f51b5d9cf703b0851621985.html">TMVA</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">NeuralNet.icc</div>  </div>
</div><!--header-->
<div class="contents">
<a href="NeuralNet_8icc.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef TMVA_NEURAL_NET_I</span></div><div class="line"><a name="l00002"></a><span class="lineno"><a class="line" href="NeuralNet_8icc.html#a42de3343898a9faa403d840e975c6766">    2</a></span>&#160;<span class="preprocessor">#define TMVA_NEURAL_NET_I</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#ifndef TMVA_NEURAL_NET</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#error &quot;Do not use NeuralNet.icc directly. #include \&quot;NeuralNet.h\&quot; instead.&quot;</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#endif // TMVA_NEURAL_NET</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="preprocessor">#pragma once</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#pragma GCC diagnostic ignored &quot;-Wunused-variable&quot;</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Util_8h.html">Math/Util.h</a>&quot;</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Pattern_8h.html">TMVA/Pattern.h</a>&quot;</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="MethodBase_8h.html">TMVA/MethodBase.h</a>&quot;</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &lt;tuple&gt;</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &lt;future&gt;</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &lt;random&gt;</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceTMVA.html">TMVA</a></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;{</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;    <span class="keyword">namespace </span>DNN</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;    {</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00032"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a287a9e9a038386fa89fc29218489fbc6">   32</a></span>&#160;            <a class="code" href="namespaceROOT_1_1Math_1_1Chebyshev.html#ae8cd7615ee993748f2b39d07561f83ba">T</a> <a class="code" href="namespaceTMVA_1_1DNN.html#a287a9e9a038386fa89fc29218489fbc6">uniformFromTo</a> (<a class="code" href="namespaceROOT_1_1Math_1_1Chebyshev.html#ae8cd7615ee993748f2b39d07561f83ba">T</a> from, <a class="code" href="namespaceROOT_1_1Math_1_1Chebyshev.html#ae8cd7615ee993748f2b39d07561f83ba">T</a> to)</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;        {</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;            <span class="keywordflow">return</span> from + (rand ()* (to - from)/RAND_MAX);</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;        }</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Container, <span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a0e40f9b676b53c362c27a8e2f346fb23">   40</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a0a3ba2e5a24d8d3926f97996f272f17b">uniformDouble</a> (Container&amp; container, <a class="code" href="namespaceROOT_1_1Math_1_1Chebyshev.html#ae8cd7615ee993748f2b39d07561f83ba">T</a> maxValue)</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;        {</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span> it = begin (container), itEnd = end (container); it != itEnd; ++it)</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;            {</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="comment">//        (*it) = uniformFromTo (-1.0*maxValue, 1.0*maxValue);</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;                (*it) = <a class="code" href="namespaceTMVA_1_1DNN.html#a287a9e9a038386fa89fc29218489fbc6">TMVA::DNN::uniformFromTo</a> (-1.0*maxValue, 1.0*maxValue);</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;            }</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        }</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a45506efcf9b231dde8e08a3c152434ce">ZeroFnc</a>;</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a92bced0322f6ee9c19ff2385872cfb75">Sigmoid</a>;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a1c0c6e0e3ec7f8b0bb7f1110bb0556a4">InvSigmoid</a>;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a0e9c3469fbae7cf3f216e6d9af423be7">Tanh</a>;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a720af9a9f89efda79f18e0ffe9a4b332">InvTanh</a>;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a733fa12c77cf4deaff866bcfbb4c8886">Linear</a>;</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#afadce78ec74a80216b114641306de48e">InvLinear</a>;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a0d19ad105e33c9a289a082cc199ee83f">SymmReLU</a>;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#af238176d602b24f8ad98e2a27ecb600a">InvSymmReLU</a>;</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#ac548aac0604377dcd2c357723697d21d">ReLU</a>;</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a820ce0367e972d467d4a854268e608b0">InvReLU</a>;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a3aec1440295bd8b8731d79a44488acc4">SoftPlus</a>;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#abe48507f3532940d85b67db6c08ead47">InvSoftPlus</a>;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a0e977b2ce282ee0ff9d7db323493d0f1">TanhShift</a>;</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#adf11e852a174d69f35a5080c2f785355">InvTanhShift</a>;</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#aaabb0a3d4c7440097e4911a9b0bdc90a">SoftSign</a>;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a4ec6c7bcfa2a903aa0eca9f9ba1c1c73">InvSoftSign</a>;</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a8c836f41af6a7a0798e60ddd1262f074">Gauss</a>;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a042311ead1df58db2448f9617e502351">InvGauss</a>;</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a849b4ea12faeb3e858c29ed5444f3c2b">GaussComplement</a>;</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;        <span class="keyword">extern</span> std::shared_ptr&lt;std::function&lt;double(double)&gt;&gt; <a class="code" href="namespaceTMVA_1_1DNN.html#a5d72c8746b3f8ee6284a09e5a4079ac7">InvGaussComplement</a>;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment">/*! \brief apply weights using drop-out; for no drop out, provide (&amp;bool = true) to itDrop such that *itDrop becomes &quot;true&quot;</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment"> * itDrop correlates with itSourceBegin </span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="keyword">template</span> &lt;<span class="keywordtype">bool</span> HasDropOut, <span class="keyword">typename</span> ItSource, <span class="keyword">typename</span> ItWeight, <span class="keyword">typename</span> ItTarget, <span class="keyword">typename</span> ItDrop&gt;</div><div class="line"><a name="l00089"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#aab1598c6526e2c7ed46f66f3d1bb5182">   89</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#acc94d2d0eb781e8b20508ed3ac5331e4">applyWeights</a> (ItSource itSourceBegin, ItSource itSourceEnd,</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                               ItWeight itWeight,</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                               ItTarget itTargetBegin, ItTarget itTargetEnd,</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;                               ItDrop itDrop)</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;        {</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span> itSource = itSourceBegin; itSource != itSourceEnd; ++itSource)</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;            {</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span> itTarget = itTargetBegin; itTarget != itTargetEnd; ++itTarget)</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                {</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;            <span class="keywordflow">if</span> (!HasDropOut || *itDrop)</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;                        (*itTarget) += (*itSource) * (*itWeight);</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;                    ++itWeight;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;                }</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        <span class="keywordflow">if</span> (HasDropOut) ++itDrop;        </div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;            }</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        }</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment">/*! \brief apply weights backwards (for backprop); for no drop out, provide (&amp;bool = true) to itDrop such that *itDrop becomes &quot;true&quot;</span></div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="comment"> * itDrop correlates with itPrev (to be in agreement with &quot;applyWeights&quot; where it correlates with itSources (same node as itTarget here in applyBackwards)</span></div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="keyword">template</span> &lt;<span class="keywordtype">bool</span> HasDropOut, <span class="keyword">typename</span> ItSource, <span class="keyword">typename</span> ItWeight, <span class="keyword">typename</span> ItPrev, <span class="keyword">typename</span> ItDrop&gt;</div><div class="line"><a name="l00116"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a7773108a99da4fb1299fa03171187b4e">  116</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#af0cd4d8dcbdd5c6f5acfac8e9cadf9d4">applyWeightsBackwards</a> (ItSource itCurrBegin, ItSource itCurrEnd,</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;                                        ItWeight itWeight,</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;                            ItPrev itPrevBegin, ItPrev itPrevEnd,</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;                            ItDrop itDrop)</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        {</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span> itPrev = itPrevBegin; itPrev != itPrevEnd; ++itPrev)</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;            {</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span> itCurr = itCurrBegin; itCurr != itCurrEnd; ++itCurr)</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                {</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                   <span class="keywordflow">if</span> (!HasDropOut || *itDrop)</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;                      (*itPrev) += (*itCurr) * (*itWeight);</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;                    ++itWeight;</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;                }</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;        <span class="keywordflow">if</span> (HasDropOut) ++itDrop;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;            }</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;        }</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment">/*! \brief apply the activation functions </span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItValue, <span class="keyword">typename</span> Fnc&gt;</div><div class="line"><a name="l00145"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a643878920179396ac3bacac010eb142d">  145</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a1e2e55b912c7f2266d2ef39a08cfea43">applyFunctions</a> (ItValue itValue, ItValue itValueEnd, Fnc fnc)</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;        {</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;            <span class="keywordflow">while</span> (itValue != itValueEnd)</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;            {</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;                <span class="keyword">auto</span>&amp; value = (*itValue);</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                value = (*fnc.get ()) (value);</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;                ++itValue; </div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;            }</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        }</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment">/*! \brief apply the activation functions and compute the gradient</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItValue, <span class="keyword">typename</span> Fnc, <span class="keyword">typename</span> InvFnc, <span class="keyword">typename</span> ItGradient&gt;</div><div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#ac95a40a7b81572976adc4fa725825c39">  162</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a1e2e55b912c7f2266d2ef39a08cfea43">applyFunctions</a> (ItValue itValue, ItValue itValueEnd, Fnc fnc, InvFnc invFnc, ItGradient itGradient)</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        {</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;            <span class="keywordflow">while</span> (itValue != itValueEnd)</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;            {</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;                <span class="keyword">auto</span>&amp; value = (*itValue);</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;                value = (*fnc.get ()) (value);</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;                (*itGradient) = (*invFnc.get ()) (value);</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        </div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;                ++itValue; ++itGradient;</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;            }</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        }</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="comment">/*! \brief update the gradients</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItSource, <span class="keyword">typename</span> ItDelta, <span class="keyword">typename</span> ItTargetGradient, <span class="keyword">typename</span> ItGradient&gt;</div><div class="line"><a name="l00181"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">  181</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">update</a> (ItSource itSource, ItSource itSourceEnd, </div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;                         ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, </div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;                         ItTargetGradient itTargetGradientBegin, </div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                         ItGradient itGradient)</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;        {</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;            <span class="keywordflow">while</span> (itSource != itSourceEnd)</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;            {</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;                <span class="keyword">auto</span> itTargetDelta = itTargetDeltaBegin;</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;                <span class="keyword">auto</span> itTargetGradient = itTargetGradientBegin;</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;                <span class="keywordflow">while</span> (itTargetDelta != itTargetDeltaEnd)</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;                {</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;            (*itGradient) -= (*itTargetDelta) * (*itSource) * (*itTargetGradient);</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;                    ++itTargetDelta; ++itTargetGradient; ++itGradient;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;                }</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;                ++itSource; </div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;            }</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;        }</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="comment">/*! \brief compute the regularization (L1, L2)</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;        <span class="keyword">template</span> &lt;EnumRegularization Regularization&gt;</div><div class="line"><a name="l00207"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#ac9141fa0b81942df6b52c57650b8013f">  207</a></span>&#160;            <span class="keyword">inline</span> <span class="keywordtype">double</span> <a class="code" href="namespaceTMVA_1_1DNN.html#ac9141fa0b81942df6b52c57650b8013f">computeRegularization</a> (<span class="keywordtype">double</span> weight, <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; factorWeightDecay)</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;        {</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;           <a class="code" href="Util_8h.html#addc4ff313880673f5f81049d16e837da">MATH_UNUSED</a>(weight);</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;           <a class="code" href="Util_8h.html#addc4ff313880673f5f81049d16e837da">MATH_UNUSED</a>(factorWeightDecay);</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;              </div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;            <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        }</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment">// L1 regularization</span></div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        <span class="keyword">template</span> &lt;&gt;</div><div class="line"><a name="l00217"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a2ded235d31ec167a183c4b819fc53359">  217</a></span>&#160;            <span class="keyword">inline</span> <span class="keywordtype">double</span> computeRegularization&lt;EnumRegularization::L1&gt; (<span class="keywordtype">double</span> weight, <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; factorWeightDecay)</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        {</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;            <span class="keywordflow">return</span> weight == 0.0 ? 0.0 : std::copysign (factorWeightDecay, weight);</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;        }</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment">// L2 regularization</span></div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;        <span class="keyword">template</span> &lt;&gt;</div><div class="line"><a name="l00224"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a5de3b3e1b35b1099f884e63d500d2554">  224</a></span>&#160;            <span class="keyword">inline</span> <span class="keywordtype">double</span> computeRegularization&lt;EnumRegularization::L2&gt; (<span class="keywordtype">double</span> weight, <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; factorWeightDecay)</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        {</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;            <span class="keywordflow">return</span> factorWeightDecay * weight;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;        }</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="comment">/*! \brief update the gradients, using regularization</span></div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;        <span class="keyword">template</span> &lt;EnumRegularization Regularization, <span class="keyword">typename</span> ItSource, <span class="keyword">typename</span> ItDelta, <span class="keyword">typename</span> ItTargetGradient, <span class="keyword">typename</span> ItGradient, <span class="keyword">typename</span> ItWeight&gt;</div><div class="line"><a name="l00235"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a0a3997c507aaea077dfac39830429d2f">  235</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">update</a> (ItSource itSource, ItSource itSourceEnd, </div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;                         ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, </div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;                         ItTargetGradient itTargetGradientBegin, </div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;                         ItGradient itGradient, </div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;                         ItWeight itWeight, <span class="keywordtype">double</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>)</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;        {</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;            <span class="comment">// ! the factor weightDecay has to be already scaled by 1/n where n is the number of weights</span></div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;            <span class="keywordflow">while</span> (itSource != itSourceEnd)</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;            {</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;                <span class="keyword">auto</span> itTargetDelta = itTargetDeltaBegin;</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;                <span class="keyword">auto</span> itTargetGradient = itTargetGradientBegin;</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;                <span class="keywordflow">while</span> (itTargetDelta != itTargetDeltaEnd)</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;                {</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;                    (*itGradient) -= + (*itTargetDelta) * (*itSource) * (*itTargetGradient) + computeRegularization&lt;Regularization&gt;(*itWeight,<a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a>);</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;                    ++itTargetDelta; ++itTargetGradient; ++itGradient; ++itWeight;</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;                }</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;                ++itSource; </div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;            }</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;        }</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;</div><div class="line"><a name="l00260"></a><span class="lineno"><a class="line" href="NeuralNet_8icc.html#ae68dda13e57dd98117b450ec6fe3719a">  260</a></span>&#160;<span class="preprocessor">#define USELOCALWEIGHTS 1</span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;<span class="comment">/*! \brief implementation of the steepest gradient descent algorithm</span></div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="comment"> * Can be used with multithreading (i.e. &quot;HogWild!&quot; style); see call in trainCycle</span></div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Function, <span class="keyword">typename</span> Weights, <span class="keyword">typename</span> PassThrough&gt;</div><div class="line"><a name="l00269"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Steepest.html#a787ad72a6f8892e98ed68f00332255d7">  269</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a787ad72a6f8892e98ed68f00332255d7">Steepest::operator() </a>(<a class="code" href="bindings_2r_2tests_2Functor_8C.html#a0c577f19f0476bcfd51080f86326db0f">Function</a>&amp; fitnessFunction, Weights&amp; weights, PassThrough&amp; passThrough) </div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        {</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;            <span class="keywordtype">size_t</span> numWeights = weights.size ();</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;            <span class="comment">// std::vector&lt;double&gt; gradients (numWeights, 0.0);</span></div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>.assign (numWeights, 0.0);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;            <span class="comment">// std::vector&lt;double&gt; localWeights (begin (weights), end (weights));</span></div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;            <span class="comment">// m_localWeights.reserve (numWeights);</span></div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a748c8e8570ce7eabe68bfdfef6b654be">m_localWeights</a>.assign (begin (weights), end (weights));</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;            <span class="keywordtype">double</span> <a class="code" href="namespaceTMath.html#a8a8fbe07e94608dbed9e9260283a442f">E</a> = 1e10;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;            <span class="keywordflow">if</span> (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>.size () != numWeights)</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;            {</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>.clear ();</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>.assign (weights.size (), 0);</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;            }</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;            <span class="keywordtype">bool</span> success = <span class="keyword">true</span>;</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;            <span class="keywordtype">size_t</span> currentRepetition = 0;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;            <span class="keywordflow">while</span> (success)</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;            {</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;                <span class="keywordflow">if</span> (currentRepetition &gt;= <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a2a75add87ac1f2bdf58c98b29ad83061">m_repetitions</a>)</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;                    <span class="keywordflow">break</span>;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;                <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>.assign (numWeights, 0.0);</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;                <span class="comment">// --- nesterov momentum ---</span></div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;                <span class="comment">// apply momentum before computing the new gradient</span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;                <span class="keyword">auto</span> itPrevG = begin (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>);</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;                <span class="keyword">auto</span> itPrevGEnd = end (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>);</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;                <span class="keyword">auto</span> itLocWeight = begin (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a748c8e8570ce7eabe68bfdfef6b654be">m_localWeights</a>);</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;                <span class="keywordflow">for</span> (; itPrevG != itPrevGEnd; ++itPrevG, ++itLocWeight)</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;                {</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;                    (*itPrevG) *= <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a3394b8036ca48698ad7a46c8da2998fc">m_beta</a>;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;                    (*itLocWeight) += (*itPrevG);</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;                }</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;                <a class="code" href="namespaceTMath.html#a8a8fbe07e94608dbed9e9260283a442f">E</a> = fitnessFunction (passThrough, <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a748c8e8570ce7eabe68bfdfef6b654be">m_localWeights</a>, <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>);</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="comment">//            plotGradients (gradients);</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="comment">//            plotWeights (localWeights);</span></div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                <span class="keywordtype">double</span> alpha = <a class="code" href="namespaceTMVA_1_1DNN.html#a950e579aacb6827a2704dc698d90852d">gaussDouble</a> (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a677db9c1dba0e4e3a26fb4a9323627a9">m_alpha</a>, <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a677db9c1dba0e4e3a26fb4a9323627a9">m_alpha</a>/2.0);</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">//                double alpha = m_alpha;</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;                <span class="keyword">auto</span> itG = begin (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>);</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;                <span class="keyword">auto</span> itGEnd = end (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>);</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;                itPrevG = begin (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>);</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;                <span class="keywordtype">double</span> maxGrad = 0.0;</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;                <span class="keywordflow">for</span> (; itG != itGEnd; ++itG, ++itPrevG)</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;                {</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;                    <span class="keywordtype">double</span> currGrad = (*itG);</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;                    <span class="keywordtype">double</span> prevGrad = (*itPrevG);</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                    currGrad *= alpha;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                </div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                    <span class="comment">//(*itPrevG) = m_beta * (prevGrad + currGrad);</span></div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                    currGrad += prevGrad;</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                    (*itG) = currGrad;</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                    (*itPrevG) = currGrad;</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                    </div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                    <span class="keywordflow">if</span> (<a class="code" href="namespaceROOT_1_1Math.html#a09dbf6c9318d826cd59ed8abb44dc4d0">std::fabs</a> (currGrad) &gt; maxGrad)</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;                        maxGrad = currGrad;</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;                }</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;                <span class="keywordflow">if</span> (maxGrad &gt; 1)</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;                {</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;                    <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a677db9c1dba0e4e3a26fb4a9323627a9">m_alpha</a> /= 2;</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;                    std::cout &lt;&lt; <span class="stringliteral">&quot;\nlearning rate reduced to &quot;</span> &lt;&lt; <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a677db9c1dba0e4e3a26fb4a9323627a9">m_alpha</a> &lt;&lt; std::endl;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;                    std::for_each (weights.begin (), weights.end (), [maxGrad](<span class="keywordtype">double</span>&amp; w)</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;                                   {</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;                                       w /= maxGrad;</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                                   });</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;                    <a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">m_prevGradients</a>.clear ();</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;                }</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;                {</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;                    <span class="keyword">auto</span> itW = std::begin (weights);</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;                    std::for_each (std::begin (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>), std::end (<a class="code" href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">m_localGradients</a>), [&amp;itW](<span class="keywordtype">double</span>&amp; <a class="code" href="RSha256_8hxx.html#a9608045402267746965fa49d90bbada4">g</a>)</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;                                   {</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;                                       *itW += <a class="code" href="RSha256_8hxx.html#a9608045402267746965fa49d90bbada4">g</a>;</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                                       ++itW;</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;                                   });</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                }</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;                ++currentRepetition;</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            }</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="namespaceTMath.html#a8a8fbe07e94608dbed9e9260283a442f">E</a>;</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;        }</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;<span class="comment">/*! \brief sum of squares error function</span></div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItOutput, <span class="keyword">typename</span> ItTruth, <span class="keyword">typename</span> ItDelta, <span class="keyword">typename</span> InvFnc&gt;</div><div class="line"><a name="l00380"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a8c89c244ef6cb694aca7d4a70582bcd4">  380</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a06dbb6605302256fcadab7b7f6a1178b">sumOfSquares</a> (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth <span class="comment">/*itTruthEnd*/</span>, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, <span class="keywordtype">double</span> patternWeight) </div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;        {</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;            <span class="keywordtype">double</span> errorSum = 0.0;</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;            <span class="comment">// output - truth</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;            ItTruth itTruth = itTruthBegin;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;            <span class="keywordtype">bool</span> hasDeltas = (itDelta != itDeltaEnd);</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;            <span class="keywordflow">for</span> (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth)</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;            {</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;<span class="comment">// assert (itTruth != itTruthEnd);</span></div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;                <span class="keywordtype">double</span> <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a> = (*itOutput);</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;                <span class="keywordtype">double</span> error = <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a> - (*itTruth);</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;                <span class="keywordflow">if</span> (hasDeltas)</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;                {</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;                    (*itDelta) = (*invFnc.get ()) (<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>) * error * patternWeight;</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;                    ++itDelta; </div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;                }</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;                errorSum += error*error  * patternWeight;</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;            }</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;            <span class="keywordflow">return</span> 0.5*errorSum;</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;        }</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;<span class="comment">/*! \brief cross entropy error function</span></div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItProbability, <span class="keyword">typename</span> ItTruth, <span class="keyword">typename</span> ItDelta, <span class="keyword">typename</span> ItInvActFnc&gt;</div><div class="line"><a name="l00410"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a3dafd45dcc339aced1c2ff418d084efa">  410</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a3dafd45dcc339aced1c2ff418d084efa">crossEntropy</a> (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth <span class="comment">/*itTruthEnd*/</span>, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc <span class="comment">/*itInvActFnc*/</span>, <span class="keywordtype">double</span> patternWeight) </div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;        {</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;            <span class="keywordtype">bool</span> hasDeltas = (itDelta != itDeltaEnd);</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;    </div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;            <span class="keywordtype">double</span> errorSum = 0.0;</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;            <span class="keywordflow">for</span> (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability)</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;            {</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;                <span class="keywordtype">double</span> probability = *itProbability;</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;                <span class="keywordtype">double</span> truth = *itTruthBegin;</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;                <span class="comment">/* truth = truth &lt; 0.1 ? 0.1 : truth; */</span></div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;                <span class="comment">/* truth = truth &gt; 0.9 ? 0.9 : truth; */</span></div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;                truth = truth &lt; 0.5 ? 0.1 : 0.9;</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;                <span class="keywordflow">if</span> (hasDeltas)</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;                {</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;                    <span class="keywordtype">double</span> delta = probability - truth;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;                    (*itDelta) = delta*patternWeight;</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment">//     (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;</span></div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;                    ++itDelta;</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                }</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;                <span class="keywordtype">double</span> error (0);</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;                <span class="keywordflow">if</span> (probability == 0) <span class="comment">// protection against log (0)</span></div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;                {</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;                    <span class="keywordflow">if</span> (truth &gt;= 0.5)</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;                        error += 1.0;</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;                }</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;                <span class="keywordflow">else</span> <span class="keywordflow">if</span> (probability == 1)</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;                {</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;                    <span class="keywordflow">if</span> (truth &lt; 0.5)</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;                        error += 1.0;</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;                }</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;                    error += - (truth * <a class="code" href="TMath_8h.html#afa752f47ff073d8639c631f079670788">log</a> (probability) + (1.0-truth) * <a class="code" href="TMath_8h.html#afa752f47ff073d8639c631f079670788">log</a> (1.0-probability)); <span class="comment">// cross entropy function</span></div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;                errorSum += error * patternWeight;</div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;        </div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;            }</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;            <span class="keywordflow">return</span> errorSum;</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;        }</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;<span class="comment">/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy)</span></div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItOutput, <span class="keyword">typename</span> ItTruth, <span class="keyword">typename</span> ItDelta, <span class="keyword">typename</span> ItInvActFnc&gt;</div><div class="line"><a name="l00456"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a6deb480416293c92508bd8534275a1a4">  456</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a6deb480416293c92508bd8534275a1a4">softMaxCrossEntropy</a> (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth <span class="comment">/*itTruthEnd*/</span>, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc <span class="comment">/*itInvActFnc*/</span>, <span class="keywordtype">double</span> patternWeight) </div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;        {</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;            <span class="keywordtype">double</span> errorSum = 0.0;</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;            <span class="keywordtype">bool</span> hasDeltas = (itDelta != itDeltaEnd);</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;            <span class="comment">// output - truth</span></div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;            ItTruth itTruth = itTruthBegin;</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span> itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth)</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;            {</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;<span class="comment">// assert (itTruth != itTruthEnd);</span></div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;                <span class="keywordtype">double</span> probability = (*itProbability);</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;                <span class="keywordtype">double</span> truth = (*itTruth);</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;                <span class="keywordflow">if</span> (hasDeltas)</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;                {</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                    (*itDelta) = probability - truth;</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;<span class="comment">//     (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;</span></div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;                    ++itDelta; <span class="comment">//++itInvActFnc;</span></div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;                }</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;                <span class="keywordtype">double</span> error (0);</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;                error += truth * <a class="code" href="TMath_8h.html#afa752f47ff073d8639c631f079670788">log</a> (probability);</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;                errorSum += error;</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;            }</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;            <span class="keywordflow">return</span> -errorSum * patternWeight;</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;        }</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;</div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;<span class="comment">/*! \brief compute the weight decay for regularization (L1 or L2)</span></div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItWeight&gt;</div><div class="line"><a name="l00496"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">  496</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a> (<span class="keywordtype">double</span> error, ItWeight itWeight, ItWeight itWeightEnd, <span class="keywordtype">double</span> factorWeightDecay, <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195">EnumRegularization</a> eRegularization)</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;        {</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;            <span class="keywordflow">if</span> (eRegularization == <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195a9ec4c0afd450ceac7adb81c3bcfc9732">EnumRegularization::L1</a>)</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;            {</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;                <span class="comment">// weight decay (regularization)</span></div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;                <span class="keywordtype">double</span> w = 0;</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;                <span class="keywordtype">size_t</span> <a class="code" href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a> = 0;</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;                <span class="keywordflow">for</span> (; itWeight != itWeightEnd; ++itWeight, ++<a class="code" href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a>)</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;                {</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;                    <span class="keywordtype">double</span> weight = (*itWeight);</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;                    w += <a class="code" href="namespaceROOT_1_1Math.html#a09dbf6c9318d826cd59ed8abb44dc4d0">std::fabs</a> (weight);</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;                }</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;                <span class="keywordflow">return</span> error + 0.5 * w * factorWeightDecay / <a class="code" href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a>;</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;            }</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (eRegularization == <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195a7e6aa2d53f6ee2b1a34b017fa403cb76">EnumRegularization::L2</a>)</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;            {</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;                <span class="comment">// weight decay (regularization)</span></div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;                <span class="keywordtype">double</span> w = 0;</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;                <span class="keywordtype">size_t</span> <a class="code" href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a> = 0;</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;                <span class="keywordflow">for</span> (; itWeight != itWeightEnd; ++itWeight, ++<a class="code" href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a>)</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;                {</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;                    <span class="keywordtype">double</span> weight = (*itWeight);</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;                    w += weight*weight;</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;                }</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;                <span class="keywordflow">return</span> error + 0.5 * w * factorWeightDecay / <a class="code" href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a>;</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;            }</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;            <span class="keywordflow">else</span></div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;                <span class="keywordflow">return</span> error;</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;        }</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;<span class="comment">/*! \brief apply the weights (and functions) in forward direction of the DNN</span></div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> LAYERDATA&gt;</div><div class="line"><a name="l00544"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a1c5ba59d5d3a4d5acba28e4a6a772994">  544</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a1c5ba59d5d3a4d5acba28e4a6a772994">forward</a> (<span class="keyword">const</span> LAYERDATA&amp; prevLayerData, LAYERDATA&amp; currLayerData)</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;        {</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;            <span class="keywordflow">if</span> (prevLayerData.hasDropOut ())</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;            {        </div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;        applyWeights&lt;true&gt; (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (), </div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;                              currLayerData.weightsBegin (), </div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;                              currLayerData.valuesBegin (), currLayerData.valuesEnd (),</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;                              prevLayerData.dropOut ());</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;            }</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;            <span class="keywordflow">else</span></div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;            {</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;        <span class="keywordtype">bool</span> <a class="code" href="RooMathCoreReg_8cxx.html#a9ade5aa78cf41af74bbde701922393a6">dummy</a> = <span class="keyword">true</span>;</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;        applyWeights&lt;false&gt; (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (), </div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;                              currLayerData.weightsBegin (), </div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;                             currLayerData.valuesBegin (), currLayerData.valuesEnd (),</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;                             &amp;<a class="code" href="RooMathCoreReg_8cxx.html#a9ade5aa78cf41af74bbde701922393a6">dummy</a>); <span class="comment">// dummy to turn on all nodes (no drop out)</span></div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;            }</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;        }</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;<span class="comment">/*! \brief backward application of the weights (back-propagation of the error)</span></div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> LAYERDATA&gt;</div><div class="line"><a name="l00570"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a3edd2f7dbfbebc56db5d4fcc42e2d2cf">  570</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a3edd2f7dbfbebc56db5d4fcc42e2d2cf">backward</a> (LAYERDATA&amp; prevLayerData, LAYERDATA&amp; currLayerData)</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;{</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;    <span class="keywordflow">if</span> (prevLayerData.hasDropOut ())</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;    {</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;        applyWeightsBackwards&lt;true&gt; (currLayerData.deltasBegin (), currLayerData.deltasEnd (), </div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;                                     currLayerData.weightsBegin (), </div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;                                     prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;                                     prevLayerData.dropOut ());</div><div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;    }</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;    <span class="keywordflow">else</span></div><div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;    {</div><div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;        <span class="keywordtype">bool</span> <a class="code" href="RooMathCoreReg_8cxx.html#a9ade5aa78cf41af74bbde701922393a6">dummy</a> = <span class="keyword">true</span>;</div><div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;        applyWeightsBackwards&lt;false&gt; (currLayerData.deltasBegin (), currLayerData.deltasEnd (), </div><div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;                                      currLayerData.weightsBegin (), </div><div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;                                      prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;                                      &amp;<a class="code" href="RooMathCoreReg_8cxx.html#a9ade5aa78cf41af74bbde701922393a6">dummy</a>); <span class="comment">// dummy to use all nodes (no drop out)</span></div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;    }</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;}</div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;<span class="comment">/*! \brief update the node values</span></div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> LAYERDATA&gt;</div><div class="line"><a name="l00598"></a><span class="lineno"><a class="line" href="namespaceTMVA_1_1DNN.html#a544d14c4c42b4e37587e509f57614d4f">  598</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">update</a> (<span class="keyword">const</span> LAYERDATA&amp; prevLayerData, LAYERDATA&amp; currLayerData, <span class="keywordtype">double</span> factorWeightDecay, <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195">EnumRegularization</a> <a class="code" href="namespaceTMVA_1_1DNN.html#a5df4065ab69e1d6a0018509927c38d55">regularization</a>)</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;        {</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;            <span class="comment">// ! the &quot;factorWeightDecay&quot; has already to be scaled by 1/n where n is the number of weights</span></div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;            <span class="keywordflow">if</span> (factorWeightDecay != 0.0) <span class="comment">// has weight regularization</span></div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;                <span class="keywordflow">if</span> (<a class="code" href="namespaceTMVA_1_1DNN.html#a5df4065ab69e1d6a0018509927c38d55">regularization</a> == <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195a9ec4c0afd450ceac7adb81c3bcfc9732">EnumRegularization::L1</a>)  <span class="comment">// L1 regularization ( sum(|w|) )</span></div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;                {</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;                    update&lt;EnumRegularization::L1&gt; (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (), </div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;                                                    currLayerData.deltasBegin (), currLayerData.deltasEnd (), </div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;                                                    currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (), </div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;                                                    currLayerData.weightsBegin (), factorWeightDecay);</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;                }</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;                <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="namespaceTMVA_1_1DNN.html#a5df4065ab69e1d6a0018509927c38d55">regularization</a> == <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195a7e6aa2d53f6ee2b1a34b017fa403cb76">EnumRegularization::L2</a>) <span class="comment">// L2 regularization ( sum(w^2) )</span></div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;                {</div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;                    update&lt;EnumRegularization::L2&gt; (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (), </div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;                                                    currLayerData.deltasBegin (), currLayerData.deltasEnd (), </div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;                                                    currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (), </div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;                                                    currLayerData.weightsBegin (), factorWeightDecay);</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;                }</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;                <span class="keywordflow">else</span> </div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;                {</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;                    <a class="code" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">update</a> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (), </div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;                            currLayerData.deltasBegin (), currLayerData.deltasEnd (), </div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;                            currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;                }</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;    </div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;            <span class="keywordflow">else</span></div><div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;            { <span class="comment">// no weight regularization</span></div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;                <a class="code" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">update</a> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (), </div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;                        currLayerData.deltasBegin (), currLayerData.deltasEnd (), </div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;                        currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;            }</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;        }</div><div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;</div><div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;</div><div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;</div><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;</div><div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;</div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;</div><div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;</div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;<span class="comment">/*! \brief compute the drop-out-weight factor</span></div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;<span class="comment"> * when using drop-out a fraction of the nodes is turned off at each cycle of the computation</span></div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;<span class="comment"> * once all nodes are turned on again (for instances when the test samples are evaluated), </span></div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;<span class="comment"> * the weights have to be adjusted to account for the different number of active nodes</span></div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;<span class="comment"> * this function computes the factor and applies it to the weights</span></div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> WeightsType, <span class="keyword">typename</span> DropProbabilities&gt;</div><div class="line"><a name="l00650"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#add342ccb8a72b10787090429a1353b5e">  650</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#add342ccb8a72b10787090429a1353b5e">Net::dropOutWeightFactor</a> (WeightsType&amp; weights,</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;                                           <span class="keyword">const</span> DropProbabilities&amp; drops, </div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;                                           <span class="keywordtype">bool</span> inverse)</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;        {</div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;            <span class="keywordflow">if</span> (drops.empty () || weights.empty ())</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;                <span class="keywordflow">return</span>;</div><div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;</div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;            <span class="keyword">auto</span> itWeight = std::begin (weights);</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;            <span class="keyword">auto</span> itWeightEnd = std::end (weights);</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;            <span class="keyword">auto</span> itDrop = std::begin (drops);</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;            <span class="keyword">auto</span> itDropEnd = std::end (drops);</div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;            <span class="keywordtype">size_t</span> numNodesPrev = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;            <span class="keywordtype">double</span> dropFractionPrev = *itDrop;</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;            ++itDrop;</div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer : <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a95a7200fe9a64f6b9887bc2ff7e064e4">layers</a> ())</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;            {</div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;                <span class="keywordflow">if</span> (itDrop == itDropEnd)</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;                    <span class="keywordflow">break</span>;</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;                <span class="keywordtype">size_t</span> _numNodes = layer.numNodes ();</div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;                <span class="keywordtype">double</span> dropFraction = *itDrop;</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;                <span class="keywordtype">double</span> pPrev = 1.0 - dropFractionPrev;</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;                <span class="keywordtype">double</span> p = 1.0 - dropFraction;</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;                p *= pPrev;</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;                <span class="keywordflow">if</span> (inverse)</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;                {</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;                    p = 1.0/p;</div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;                }</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;                <span class="keywordtype">size_t</span> _numWeights = layer.numWeights (numNodesPrev);</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> iWeight = 0; iWeight &lt; _numWeights; ++iWeight)</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;                {</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;                    <span class="keywordflow">if</span> (itWeight == itWeightEnd)</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;                        <span class="keywordflow">break</span>;</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;                </div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;                    *itWeight *= p;</div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;                    ++itWeight;</div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;                }</div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;                numNodesPrev = _numNodes;</div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;                dropFractionPrev = dropFraction;</div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;                ++itDrop;</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;            }</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;        }</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;        </div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;    </div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;<span class="comment">/*! \brief execute the training until convergence emerges</span></div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;<span class="comment"> * \param weights the container with the weights (synapses)</span></div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;<span class="comment"> * \param trainPattern the pattern for the training</span></div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;<span class="comment"> * \param testPattern the pattern for the testing</span></div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;<span class="comment"> * \param minimizer the minimizer (e.g. steepest gradient descent) to be used</span></div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;<span class="comment"> * \param settings the settings for the training (e.g. multithreading or not, regularization etc.)</span></div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Minimizer&gt;</div><div class="line"><a name="l00710"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a6cd34fe7c9b4873728cb1ff37dc90e47">  710</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a6cd34fe7c9b4873728cb1ff37dc90e47">Net::train</a> (std::vector&lt;double&gt;&amp; weights, </div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;                               std::vector&lt;Pattern&gt;&amp; trainPattern, </div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;                               <span class="keyword">const</span> std::vector&lt;Pattern&gt;&amp; testPattern, </div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;                           <a class="code" href="namespaceRooFit.html#afac78d31d10b7e7396b999e4ea3af76c">Minimizer</a>&amp; minimizer,</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;                           <a class="code" href="classTMVA_1_1DNN_1_1Settings.html">Settings</a>&amp; settings)</div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;        {</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;<span class="comment">//        std::cout &lt;&lt; &quot;START TRAINING&quot; &lt;&lt; std::endl;</span></div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#aa7f231286a2f1df255a42a88afac2784">startTrainCycle</a> ();</div><div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;            <span class="comment">// JsMVA progress bar maximum (100%)</span></div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;            <span class="keywordflow">if</span> (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a33a6d3e3d2179f667c7d3e7aed649ea2">fIPyMaxIter</a>) *<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a33a6d3e3d2179f667c7d3e7aed649ea2">fIPyMaxIter</a> = 100;</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;</div><div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#acac1fd6a3ebeec2aba7303e6a4d35319">pads</a> (4);</div><div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#adf951f491ff26d922eb9559581478d00">create</a> (<span class="stringliteral">&quot;trainErrors&quot;</span>, 100, 0, 100, 100, 0,1);</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#adf951f491ff26d922eb9559581478d00">create</a> (<span class="stringliteral">&quot;testErrors&quot;</span>, 100, 0, 100, 100, 0,1);</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;            <span class="keywordtype">size_t</span> cycleCount = 0;</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;            <span class="keywordtype">size_t</span> testCycleCount = 0;</div><div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;            <span class="keywordtype">double</span> testError = 1e20;</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;            <span class="keywordtype">double</span> trainError = 1e20;</div><div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;            <span class="keywordtype">size_t</span> dropOutChangeCount = 0;</div><div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;</div><div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;            <a class="code" href="namespaceTMVA_1_1DNN.html#ae1bb14a8b9c6de194c25e9c74c1615e5">DropContainer</a> dropContainer;</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;            <a class="code" href="namespaceTMVA_1_1DNN.html#ae1bb14a8b9c6de194c25e9c74c1615e5">DropContainer</a> dropContainerTest;</div><div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;            <span class="keyword">const</span> std::vector&lt;double&gt;&amp; dropFractions = settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a2f5fbbd7cdb0ab7d280d915b0517cf6e">dropFractions</a> ();</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;            <span class="keywordtype">bool</span> isWeightsForDrop = <span class="keyword">false</span>;</div><div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;</div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;        </div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;            <span class="comment">// until convergence</span></div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;            <span class="keywordflow">do</span></div><div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;            {</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;                ++cycleCount;</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;</div><div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;                <span class="comment">// if dropOut enabled</span></div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;                <span class="keywordtype">size_t</span> dropIndex = 0;</div><div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;                <span class="keywordflow">if</span> (!dropFractions.empty () &amp;&amp; dropOutChangeCount % settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#add7c38bf156c102943f56316f3925275">dropRepetitions</a> () == 0)</div><div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;                {</div><div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;                    <span class="comment">// fill the dropOut-container</span></div><div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;                    dropContainer.clear ();</div><div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;                    <span class="keywordtype">size_t</span> _numNodes = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;                    <span class="keywordtype">double</span> dropFraction = 0.0;</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;                    dropFraction = dropFractions.at (dropIndex);</div><div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;                    ++dropIndex;</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;                    <a class="code" href="classTMVA_1_1DNN_1_1Net.html#adf27219d98b2f02ca36741f82ffd1c9d">fillDropContainer</a> (dropContainer, dropFraction, _numNodes);</div><div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;                    <span class="keywordflow">for</span> (<span class="keyword">auto</span> itLayer = begin (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>), itLayerEnd = end (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>); itLayer != itLayerEnd; ++itLayer, ++dropIndex)</div><div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;                    {</div><div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;                        <span class="keyword">auto</span>&amp; layer = *itLayer;</div><div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;                        _numNodes = layer.numNodes ();</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;                        <span class="comment">// how many nodes have to be dropped</span></div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;                        dropFraction = 0.0;</div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;                        <span class="keywordflow">if</span> (dropFractions.size () &gt; dropIndex)</div><div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;                            dropFraction = dropFractions.at (dropIndex);</div><div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;                    </div><div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#adf27219d98b2f02ca36741f82ffd1c9d">fillDropContainer</a> (dropContainer, dropFraction, _numNodes);</div><div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;                    }</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;                    isWeightsForDrop = <span class="keyword">true</span>;</div><div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;                }</div><div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;</div><div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;                <span class="comment">// execute training cycle</span></div><div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;                trainError = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#ac9e20e4ffd6fe02e32f118a9f99bde2d">trainCycle</a> (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;       </div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;</div><div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;       <span class="comment">// ------ check if we have to execute a test ------------------</span></div><div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;                <span class="keywordtype">bool</span> hasConverged = <span class="keyword">false</span>;</div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;            <span class="keywordflow">if</span> (testCycleCount % settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a1e13178948b917abdf6bb9f88aff8596">testRepetitions</a> () == 0) <span class="comment">// we test only everye &quot;testRepetitions&quot; repetition</span></div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;                {</div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;                    <span class="keywordflow">if</span> (isWeightsForDrop)</div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;                    {</div><div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#add342ccb8a72b10787090429a1353b5e">dropOutWeightFactor</a> (weights, dropFractions);</div><div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;                        isWeightsForDrop = <span class="keyword">false</span>;</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;                    }</div><div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;</div><div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;                    testError = 0;</div><div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;                    <span class="comment">//double weightSum = 0;</span></div><div class="line"><a name="l00785"></a><span class="lineno">  785</span>&#160;                    settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#affa1a067ee41e6346b0d76f194244d9c">startTestCycle</a> ();</div><div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160;                    <span class="keywordflow">if</span> (settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a0d854a5073f42f43427379989fdf911e">useMultithreading</a> ())</div><div class="line"><a name="l00787"></a><span class="lineno">  787</span>&#160;                    {</div><div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160;                        <span class="keywordtype">size_t</span> numThreads = std::thread::hardware_concurrency ();</div><div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;                        <span class="keywordtype">size_t</span> patternPerThread = testPattern.size () / numThreads;</div><div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;                        std::vector&lt;Batch&gt; batches;</div><div class="line"><a name="l00791"></a><span class="lineno">  791</span>&#160;                        <span class="keyword">auto</span> itPat = testPattern.begin ();</div><div class="line"><a name="l00792"></a><span class="lineno">  792</span>&#160;                        <span class="comment">// auto itPatEnd = testPattern.end ();</span></div><div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;                        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idxThread = 0; idxThread &lt; numThreads-1; ++idxThread)</div><div class="line"><a name="l00794"></a><span class="lineno">  794</span>&#160;                        {</div><div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;                            batches.push_back (<a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a> (itPat, itPat + patternPerThread));</div><div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;                            itPat += patternPerThread;</div><div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;                        }</div><div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;                        <span class="keywordflow">if</span> (itPat != testPattern.end ())</div><div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;                            batches.push_back (<a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a> (itPat, testPattern.end ()));</div><div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;</div><div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;                        std::vector&lt;std::future&lt;std::tuple&lt;double,std::vector&lt;double&gt;&gt;&gt;&gt; futures;</div><div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;                        <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; batch : batches)</div><div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;                        {</div><div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;                            <span class="comment">// -------------------- execute each of the batch ranges on a different thread -------------------------------</span></div><div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;                            futures.push_back (</div><div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;                                std::async (std::launch::async, [&amp;]() </div><div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;                                            {</div><div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;                                                std::vector&lt;double&gt; localOutput;</div><div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;                                                <a class="code" href="namespaceTMVA_1_1DNN.html#acd7081b3481c72ec441fbd77e624613b">pass_through_type</a> passThrough (settings, batch, dropContainerTest);</div><div class="line"><a name="l00810"></a><span class="lineno">  810</span>&#160;                                                <span class="keywordtype">double</span> testBatchError = (*this) (passThrough, weights, <a class="code" href="namespaceTMVA_1_1DNN.html#a2fe58f5bcff33ea6e0dc1a5ae8b1161aa1b5dc1b50bc6e304f044da1fdffe2578">ModeOutput::FETCH</a>, localOutput);</div><div class="line"><a name="l00811"></a><span class="lineno">  811</span>&#160;                                                <span class="keywordflow">return</span> std::make_tuple (testBatchError, localOutput);</div><div class="line"><a name="l00812"></a><span class="lineno">  812</span>&#160;                                            })</div><div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;                                );</div><div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;                        }</div><div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;</div><div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;                        <span class="keyword">auto</span> itBatch = batches.begin  ();</div><div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;                        <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; <a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a> : futures)</div><div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;                        {</div><div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;                            std::tuple&lt;double,std::vector&lt;double&gt;&gt; result = <a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>.get ();</div><div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;                            testError += std::get&lt;0&gt;(result) / batches.size ();</div><div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;                            std::vector&lt;double&gt; <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a> = std::get&lt;1&gt;(result);</div><div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;                            <span class="keywordflow">if</span> (<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>.size() == (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a7fd8f63f29343d003d876a2f590c32ba">outputSize</a>() - 1) * itBatch-&gt;size())</div><div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160;                            {</div><div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;                                <span class="keyword">auto</span> output_iterator = <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>.begin();</div><div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;                                <span class="keywordflow">for</span> (<span class="keyword">auto</span> pattern_it = itBatch-&gt;begin(); pattern_it != itBatch-&gt;end(); ++pattern_it) </div><div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;                                {</div><div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;                                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> output_index = 1; output_index &lt; <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a7fd8f63f29343d003d876a2f590c32ba">outputSize</a>(); ++output_index)</div><div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;                                    {</div><div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;                                        settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#aa3640ef5280a6f067100bbf236d7c4ba">testSample</a> (0, *output_iterator, (*pattern_it).output ().at (0),</div><div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;                                                                                  (*pattern_it).weight ());</div><div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160;                                        ++output_iterator;</div><div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;                                    }</div><div class="line"><a name="l00833"></a><span class="lineno">  833</span>&#160;                                }</div><div class="line"><a name="l00834"></a><span class="lineno">  834</span>&#160;                            }</div><div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;                        ++itBatch;</div><div class="line"><a name="l00836"></a><span class="lineno">  836</span>&#160;                        }</div><div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;                    </div><div class="line"><a name="l00838"></a><span class="lineno">  838</span>&#160;                    }</div><div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;                    <span class="keywordflow">else</span></div><div class="line"><a name="l00840"></a><span class="lineno">  840</span>&#160;                    {</div><div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160;                        std::vector&lt;double&gt; <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>;</div><div class="line"><a name="l00842"></a><span class="lineno">  842</span>&#160;                    <span class="comment">//for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it)</span></div><div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;                        {</div><div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;                        <span class="comment">//const Pattern&amp; p = (*it);</span></div><div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160;                        <span class="comment">//double weight = p.weight ();</span></div><div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;                        <span class="comment">//Batch batch (it, it+1);</span></div><div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a> batch (begin (testPattern), end (testPattern));</div><div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;                            <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>.clear ();</div><div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160;                        <a class="code" href="namespaceTMVA_1_1DNN.html#acd7081b3481c72ec441fbd77e624613b">pass_through_type</a> passThrough (settings, batch, dropContainerTest);</div><div class="line"><a name="l00850"></a><span class="lineno">  850</span>&#160;                            <span class="keywordtype">double</span> testPatternError = (*this) (passThrough, weights, <a class="code" href="namespaceTMVA_1_1DNN.html#a2fe58f5bcff33ea6e0dc1a5ae8b1161aa1b5dc1b50bc6e304f044da1fdffe2578">ModeOutput::FETCH</a>, <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>);</div><div class="line"><a name="l00851"></a><span class="lineno">  851</span>&#160;                        <span class="keywordflow">if</span> (<a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>.size() == (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a7fd8f63f29343d003d876a2f590c32ba">outputSize</a>() - 1) * batch.<a class="code" href="classTMVA_1_1DNN_1_1Batch.html#a93d8ed91fddf52d36362fad809125e0a">size</a>())</div><div class="line"><a name="l00852"></a><span class="lineno">  852</span>&#160;                        {</div><div class="line"><a name="l00853"></a><span class="lineno">  853</span>&#160;                            <span class="keyword">auto</span> output_iterator = <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>.begin();</div><div class="line"><a name="l00854"></a><span class="lineno">  854</span>&#160;                            <span class="keywordflow">for</span> (<span class="keyword">auto</span> pattern_it = batch.<a class="code" href="classTMVA_1_1DNN_1_1Batch.html#a1f1c71bd2af68e6ea1105d38b1e26e3e">begin</a>(); pattern_it != batch.<a class="code" href="classTMVA_1_1DNN_1_1Batch.html#a20d72553469a204881e81f7f7f77a98e">end</a>(); ++pattern_it) </div><div class="line"><a name="l00855"></a><span class="lineno">  855</span>&#160;                            {</div><div class="line"><a name="l00856"></a><span class="lineno">  856</span>&#160;                                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> output_index = 1; output_index &lt; <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a7fd8f63f29343d003d876a2f590c32ba">outputSize</a>(); ++output_index)</div><div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160;                                {</div><div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;                                    settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#aa3640ef5280a6f067100bbf236d7c4ba">testSample</a> (0, *output_iterator, (*pattern_it).output ().at (0),</div><div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;                                                                              (*pattern_it).weight ());</div><div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;                                    ++output_iterator;</div><div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;                                }</div><div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;                            }</div><div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;                        }</div><div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;                        testError += testPatternError; <span class="comment">/// batch.size ();</span></div><div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;<span class="comment"></span>                        }</div><div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;                    <span class="comment">// testError /= testPattern.size ();</span></div><div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;                    }</div><div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;                    settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a31b2996a3b88156a828ff7c0bc929b95">endTestCycle</a> ();</div><div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;<span class="comment">//                    testError /= weightSum;</span></div><div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;</div><div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;                    settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ad2ede1e2183a37e0c768df40a59581a6">computeResult</a> (*<span class="keyword">this</span>, weights);</div><div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;</div><div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;                    hasConverged = settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a4ed999b56834e118be62b4dfd20d2edc">hasConverged</a> (testError);</div><div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;                    <span class="keywordflow">if</span> (!hasConverged &amp;&amp; !isWeightsForDrop)</div><div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;                    {</div><div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;                        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#add342ccb8a72b10787090429a1353b5e">dropOutWeightFactor</a> (weights, dropFractions, <span class="keyword">true</span>); <span class="comment">// inverse</span></div><div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;                        isWeightsForDrop = <span class="keyword">true</span>;</div><div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160;                    }</div><div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;                }</div><div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;                ++testCycleCount;</div><div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160;                ++dropOutChangeCount;</div><div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;</div><div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;</div><div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;                <span class="keyword">static</span> <span class="keywordtype">double</span> <a class="code" href="legend1_8C.html#a13c6713ae496caa8195647f76887f926">x</a> = -1.0;</div><div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;                <a class="code" href="legend1_8C.html#a13c6713ae496caa8195647f76887f926">x</a> += 1.0;</div><div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;<span class="comment">//            settings.resetPlot (&quot;errors&quot;);</span></div><div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;                settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a950189f3903cf99be0ebd2bfe7a20e8e">addPoint</a> (<span class="stringliteral">&quot;trainErrors&quot;</span>, cycleCount, trainError);</div><div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;                settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a950189f3903cf99be0ebd2bfe7a20e8e">addPoint</a> (<span class="stringliteral">&quot;testErrors&quot;</span>, cycleCount, testError);</div><div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;                settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#aa6cbab9ba575a8055a11277bbad81aa7">plot</a> (<span class="stringliteral">&quot;trainErrors&quot;</span>, <span class="stringliteral">&quot;C&quot;</span>, 1, <a class="code" href="Rtypes_8h.html#ac31db05c6cb5891c704eae374f6926a8aab48c32302f7159d81e081c41dc2d3d2">kBlue</a>);</div><div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160;                settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#aa6cbab9ba575a8055a11277bbad81aa7">plot</a> (<span class="stringliteral">&quot;testErrors&quot;</span>, <span class="stringliteral">&quot;C&quot;</span>, 1, <a class="code" href="Rtypes_8h.html#ac31db05c6cb5891c704eae374f6926a8a951e8c9c29427097fd137e19a3300e03">kMagenta</a>);</div><div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;</div><div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160;</div><div class="line"><a name="l00893"></a><span class="lineno">  893</span>&#160;                <span class="comment">// setup error plots and progress bar variables for JsMVA</span></div><div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;                <span class="keywordflow">if</span> (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#aeb408087bfd3dba1614b5d8f291c12f8">fInteractive</a>){</div><div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;                  <a class="code" href="classTMVA_1_1DNN_1_1Net.html#aeb408087bfd3dba1614b5d8f291c12f8">fInteractive</a>-&gt;<a class="code" href="classTMVA_1_1IPythonInteractive.html#ae13888c9ca4d3bd97c36f38422c3364f">AddPoint</a>(cycleCount, trainError, testError);</div><div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;                  <span class="keywordflow">if</span> (*<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a1a62255a51643289090bb72884018f4d">fExitFromTraining</a>) <span class="keywordflow">break</span>;</div><div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;                  *<a class="code" href="classTMVA_1_1DNN_1_1Net.html#ac9eedb5ac24c3a0914533e93a0be361a">fIPyCurrentIter</a> = 100*(double)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ac5e78898db77521fdfd51e205098f870">maxConvergenceCount</a> () /(double)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ab95a90e7ede6423bf972b16de68cc174">convergenceSteps</a> ();</div><div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;                }</div><div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;</div><div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;                <span class="keywordflow">if</span> (hasConverged)</div><div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160;                    <span class="keywordflow">break</span>;</div><div class="line"><a name="l00902"></a><span class="lineno">  902</span>&#160;                </div><div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;                <span class="keywordflow">if</span> ((<span class="keywordtype">int</span>)cycleCount % 10 == 0) { </div><div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;</div><div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;                   <a class="code" href="classTString.html">TString</a> convText = <a class="code" href="TString_8h.html#acf18c5b91421ac53e91bd96ebc07dea7">Form</a>( <span class="stringliteral">&quot;(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d&quot;</span>,</div><div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;                                            trainError,</div><div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;                                            testError,</div><div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;                                            (<span class="keywordtype">int</span>)cycleCount,</div><div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;                                            (<span class="keywordtype">int</span>)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a12691199ebc2ef74717ad1da5fba87a4">convergenceCount</a> (),</div><div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;                                            (int)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ac5e78898db77521fdfd51e205098f870">maxConvergenceCount</a> ());</div><div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160;                   <span class="keywordtype">double</span> progress = 100*(double)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ac5e78898db77521fdfd51e205098f870">maxConvergenceCount</a> () /(double)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ab95a90e7ede6423bf972b16de68cc174">convergenceSteps</a> ();</div><div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;                   settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a55649ab61afefff55c73f01130068732">cycle</a> (progress, convText);</div><div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;                }</div><div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;            }</div><div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;            <span class="keywordflow">while</span> (<span class="keyword">true</span>);</div><div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a758301fff15727d14018c7442a9aedbc">endTrainCycle</a> (trainError);</div><div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;        </div><div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;            <a class="code" href="classTString.html">TString</a> convText = <a class="code" href="TString_8h.html#acf18c5b91421ac53e91bd96ebc07dea7">Form</a>( <span class="stringliteral">&quot;(train/test/epoch): %.4g/%.4g/%d&quot;</span>, trainError, testError, (<span class="keywordtype">int</span>)cycleCount);</div><div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;            <span class="keywordtype">double</span> progress = 100*(double)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ac5e78898db77521fdfd51e205098f870">maxConvergenceCount</a>() /(double)settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#ab95a90e7ede6423bf972b16de68cc174">convergenceSteps</a> ();</div><div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a55649ab61afefff55c73f01130068732">cycle</a> (progress, convText);</div><div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;</div><div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;            <span class="keywordflow">return</span> testError;</div><div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;        }</div><div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;</div><div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;</div><div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;<span class="comment">/*! \brief execute a single training cycle</span></div><div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160;<span class="comment"> * uses multithreading if turned on</span></div><div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;<span class="comment"> * \param minimizer the minimizer to be used (e.g. SGD)</span></div><div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160;<span class="comment"> * \param weights the weight container with all the synapse weights</span></div><div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;<span class="comment"> * \param itPatternBegin begin of the pattern container</span></div><div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;<span class="comment"> * \parama itPatternEnd the end of the pattern container</span></div><div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;<span class="comment"> * \param settings the settings for this training (e.g. multithreading or not, regularization, etc.)</span></div><div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;<span class="comment"> * \param dropContainer the data for dropping-out nodes (regularization technique)</span></div><div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Iterator, <span class="keyword">typename</span> Minimizer&gt;</div><div class="line"><a name="l00939"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#ac9e20e4ffd6fe02e32f118a9f99bde2d">  939</a></span>&#160;            <span class="keyword">inline</span> <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#ac9e20e4ffd6fe02e32f118a9f99bde2d">Net::trainCycle</a> (<a class="code" href="namespaceRooFit.html#afac78d31d10b7e7396b999e4ea3af76c">Minimizer</a>&amp; minimizer, std::vector&lt;double&gt;&amp; weights, </div><div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160;                                           Iterator itPatternBegin, Iterator itPatternEnd, <a class="code" href="classTMVA_1_1DNN_1_1Settings.html">Settings</a>&amp; settings, <a class="code" href="namespaceTMVA_1_1DNN.html#ae1bb14a8b9c6de194c25e9c74c1615e5">DropContainer</a>&amp; dropContainer)</div><div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;        {</div><div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;            <span class="keywordtype">double</span> error = 0.0;</div><div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160;            <span class="keywordtype">size_t</span> numPattern = std::distance (itPatternBegin, itPatternEnd);</div><div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;            <span class="keywordtype">size_t</span> numBatches = numPattern/settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#acf69c56affd5b534ddafd2e6ecc45336">batchSize</a> ();</div><div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;            <span class="keywordtype">size_t</span> numBatches_stored = numBatches;</div><div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;</div><div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;            std::shuffle(itPatternBegin, itPatternEnd, std::default_random_engine{});</div><div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160;            Iterator itPatternBatchBegin = itPatternBegin;</div><div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;            Iterator itPatternBatchEnd = itPatternBatchBegin;</div><div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;</div><div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160;            <span class="comment">// create batches</span></div><div class="line"><a name="l00952"></a><span class="lineno">  952</span>&#160;            std::vector&lt;Batch&gt; batches;</div><div class="line"><a name="l00953"></a><span class="lineno">  953</span>&#160;            <span class="keywordflow">while</span> (numBatches &gt; 0)</div><div class="line"><a name="l00954"></a><span class="lineno">  954</span>&#160;            {</div><div class="line"><a name="l00955"></a><span class="lineno">  955</span>&#160;                std::advance (itPatternBatchEnd, settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#acf69c56affd5b534ddafd2e6ecc45336">batchSize</a> ());</div><div class="line"><a name="l00956"></a><span class="lineno">  956</span>&#160;                batches.push_back (<a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a> (itPatternBatchBegin, itPatternBatchEnd));</div><div class="line"><a name="l00957"></a><span class="lineno">  957</span>&#160;                itPatternBatchBegin = itPatternBatchEnd;</div><div class="line"><a name="l00958"></a><span class="lineno">  958</span>&#160;                --numBatches;</div><div class="line"><a name="l00959"></a><span class="lineno">  959</span>&#160;            }</div><div class="line"><a name="l00960"></a><span class="lineno">  960</span>&#160;</div><div class="line"><a name="l00961"></a><span class="lineno">  961</span>&#160;            <span class="comment">// add the last pattern to the last batch</span></div><div class="line"><a name="l00962"></a><span class="lineno">  962</span>&#160;            <span class="keywordflow">if</span> (itPatternBatchEnd != itPatternEnd)</div><div class="line"><a name="l00963"></a><span class="lineno">  963</span>&#160;                batches.push_back (<a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a> (itPatternBatchEnd, itPatternEnd));</div><div class="line"><a name="l00964"></a><span class="lineno">  964</span>&#160;</div><div class="line"><a name="l00965"></a><span class="lineno">  965</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00966"></a><span class="lineno">  966</span>&#160;<span class="comment">            ///&lt; turn on multithreading if requested</span></div><div class="line"><a name="l00967"></a><span class="lineno">  967</span>&#160;<span class="comment"></span>            <span class="keywordflow">if</span> (settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a0d854a5073f42f43427379989fdf911e">useMultithreading</a> ())</div><div class="line"><a name="l00968"></a><span class="lineno">  968</span>&#160;            {</div><div class="line"><a name="l00969"></a><span class="lineno">  969</span>&#160;                <span class="comment">// -------------------- divide the batches into bunches for each thread --------------</span></div><div class="line"><a name="l00970"></a><span class="lineno">  970</span>&#160;                <span class="keywordtype">size_t</span> numThreads = std::thread::hardware_concurrency ();</div><div class="line"><a name="l00971"></a><span class="lineno">  971</span>&#160;                <span class="keywordtype">size_t</span> batchesPerThread = batches.size () / numThreads;</div><div class="line"><a name="l00972"></a><span class="lineno">  972</span>&#160;                <span class="keyword">typedef</span> std::vector&lt;Batch&gt;::iterator batch_iterator;</div><div class="line"><a name="l00973"></a><span class="lineno">  973</span>&#160;                std::vector&lt;std::pair&lt;batch_iterator,batch_iterator&gt;&gt; batchVec;</div><div class="line"><a name="l00974"></a><span class="lineno">  974</span>&#160;                batch_iterator itBatchBegin = std::begin (batches);</div><div class="line"><a name="l00975"></a><span class="lineno">  975</span>&#160;                batch_iterator itBatchCurrEnd = std::begin (batches);</div><div class="line"><a name="l00976"></a><span class="lineno">  976</span>&#160;                batch_iterator itBatchEnd = std::end (batches);</div><div class="line"><a name="l00977"></a><span class="lineno">  977</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> iT = 0; iT &lt; numThreads; ++iT)</div><div class="line"><a name="l00978"></a><span class="lineno">  978</span>&#160;                {</div><div class="line"><a name="l00979"></a><span class="lineno">  979</span>&#160;                    <span class="keywordflow">if</span> (iT == numThreads-1)</div><div class="line"><a name="l00980"></a><span class="lineno">  980</span>&#160;                        itBatchCurrEnd = itBatchEnd;</div><div class="line"><a name="l00981"></a><span class="lineno">  981</span>&#160;                    <span class="keywordflow">else</span></div><div class="line"><a name="l00982"></a><span class="lineno">  982</span>&#160;                        std::advance (itBatchCurrEnd, batchesPerThread);</div><div class="line"><a name="l00983"></a><span class="lineno">  983</span>&#160;                    batchVec.push_back (std::make_pair (itBatchBegin, itBatchCurrEnd));</div><div class="line"><a name="l00984"></a><span class="lineno">  984</span>&#160;                    itBatchBegin = itBatchCurrEnd;</div><div class="line"><a name="l00985"></a><span class="lineno">  985</span>&#160;                }</div><div class="line"><a name="l00986"></a><span class="lineno">  986</span>&#160;        </div><div class="line"><a name="l00987"></a><span class="lineno">  987</span>&#160;                <span class="comment">// -------------------- loop  over batches -------------------------------------------</span></div><div class="line"><a name="l00988"></a><span class="lineno">  988</span>&#160;                std::vector&lt;std::future&lt;double&gt;&gt; futures;</div><div class="line"><a name="l00989"></a><span class="lineno">  989</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; batchRange : batchVec)</div><div class="line"><a name="l00990"></a><span class="lineno">  990</span>&#160;                {</div><div class="line"><a name="l00991"></a><span class="lineno">  991</span>&#160;                    <span class="comment">// -------------------- execute each of the batch ranges on a different thread -------------------------------</span></div><div class="line"><a name="l00992"></a><span class="lineno">  992</span>&#160;                    futures.push_back (</div><div class="line"><a name="l00993"></a><span class="lineno">  993</span>&#160;                        std::async (std::launch::async, [&amp;]() </div><div class="line"><a name="l00994"></a><span class="lineno">  994</span>&#160;                                    {</div><div class="line"><a name="l00995"></a><span class="lineno">  995</span>&#160;                                        <span class="keywordtype">double</span> localError = 0.0;</div><div class="line"><a name="l00996"></a><span class="lineno">  996</span>&#160;                                        <span class="keywordflow">for</span> (<span class="keyword">auto</span> it = batchRange.first, itEnd = batchRange.second; it != itEnd; ++it)</div><div class="line"><a name="l00997"></a><span class="lineno">  997</span>&#160;                                        {</div><div class="line"><a name="l00998"></a><span class="lineno">  998</span>&#160;                                            Batch&amp; batch = *it;</div><div class="line"><a name="l00999"></a><span class="lineno">  999</span>&#160;                                            pass_through_type settingsAndBatch (settings, batch, dropContainer);</div><div class="line"><a name="l01000"></a><span class="lineno"> 1000</span>&#160;                                            Minimizer minimizerClone (minimizer);</div><div class="line"><a name="l01001"></a><span class="lineno"> 1001</span>&#160;                                            localError += minimizerClone ((*this), weights, settingsAndBatch); <span class="comment">/// call the minimizer</span></div><div class="line"><a name="l01002"></a><span class="lineno"> 1002</span>&#160;<span class="comment"></span>                                        }</div><div class="line"><a name="l01003"></a><span class="lineno"> 1003</span>&#160;                                        <span class="keywordflow">return</span> localError;</div><div class="line"><a name="l01004"></a><span class="lineno"> 1004</span>&#160;                                    })</div><div class="line"><a name="l01005"></a><span class="lineno"> 1005</span>&#160;                        );</div><div class="line"><a name="l01006"></a><span class="lineno"> 1006</span>&#160;                }</div><div class="line"><a name="l01007"></a><span class="lineno"> 1007</span>&#160;</div><div class="line"><a name="l01008"></a><span class="lineno"> 1008</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; <a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a> : futures)</div><div class="line"><a name="l01009"></a><span class="lineno"> 1009</span>&#160;                    error += <a class="code" href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a>.get ();</div><div class="line"><a name="l01010"></a><span class="lineno"> 1010</span>&#160;            }</div><div class="line"><a name="l01011"></a><span class="lineno"> 1011</span>&#160;            <span class="keywordflow">else</span></div><div class="line"><a name="l01012"></a><span class="lineno"> 1012</span>&#160;            {</div><div class="line"><a name="l01013"></a><span class="lineno"> 1013</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; batch : batches)</div><div class="line"><a name="l01014"></a><span class="lineno"> 1014</span>&#160;                {</div><div class="line"><a name="l01015"></a><span class="lineno"> 1015</span>&#160;                    std::tuple&lt;Settings&amp;, Batch&amp;, DropContainer&amp;&gt; settingsAndBatch (settings, batch, dropContainer);</div><div class="line"><a name="l01016"></a><span class="lineno"> 1016</span>&#160;                    error += minimizer ((*<span class="keyword">this</span>), weights, settingsAndBatch);</div><div class="line"><a name="l01017"></a><span class="lineno"> 1017</span>&#160;                }</div><div class="line"><a name="l01018"></a><span class="lineno"> 1018</span>&#160;            }</div><div class="line"><a name="l01019"></a><span class="lineno"> 1019</span>&#160;        </div><div class="line"><a name="l01020"></a><span class="lineno"> 1020</span>&#160;            numBatches_stored = std::max (numBatches_stored, <span class="keywordtype">size_t</span>(1)); <span class="comment">/// normalize the error</span></div><div class="line"><a name="l01021"></a><span class="lineno"> 1021</span>&#160;<span class="comment"></span>            error /= numBatches_stored;</div><div class="line"><a name="l01022"></a><span class="lineno"> 1022</span>&#160;            settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a3baf93535d76f3346f06ab74e6c3df8b">testIteration</a> ();</div><div class="line"><a name="l01023"></a><span class="lineno"> 1023</span>&#160;    </div><div class="line"><a name="l01024"></a><span class="lineno"> 1024</span>&#160;            <span class="keywordflow">return</span> error;</div><div class="line"><a name="l01025"></a><span class="lineno"> 1025</span>&#160;        }</div><div class="line"><a name="l01026"></a><span class="lineno"> 1026</span>&#160;</div><div class="line"><a name="l01027"></a><span class="lineno"> 1027</span>&#160;</div><div class="line"><a name="l01028"></a><span class="lineno"> 1028</span>&#160;</div><div class="line"><a name="l01029"></a><span class="lineno"> 1029</span>&#160;</div><div class="line"><a name="l01030"></a><span class="lineno"> 1030</span>&#160;<span class="comment"></span></div><div class="line"><a name="l01031"></a><span class="lineno"> 1031</span>&#160;<span class="comment">/*! \brief compute the neural net</span></div><div class="line"><a name="l01032"></a><span class="lineno"> 1032</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l01033"></a><span class="lineno"> 1033</span>&#160;<span class="comment"> * \param input the input data</span></div><div class="line"><a name="l01034"></a><span class="lineno"> 1034</span>&#160;<span class="comment"> * \param weights the weight data</span></div><div class="line"><a name="l01035"></a><span class="lineno"> 1035</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l01036"></a><span class="lineno"> 1036</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Weights&gt;</div><div class="line"><a name="l01037"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a3fa66ca13e04cd2d7a994210c2dc9885"> 1037</a></span>&#160;            std::vector&lt;double&gt; <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a3fa66ca13e04cd2d7a994210c2dc9885">Net::compute</a> (<span class="keyword">const</span> std::vector&lt;double&gt;&amp; input, <span class="keyword">const</span> Weights&amp; weights)<span class="keyword"> const</span></div><div class="line"><a name="l01038"></a><span class="lineno"> 1038</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01039"></a><span class="lineno"> 1039</span>&#160;            std::vector&lt;LayerData&gt; layerData;</div><div class="line"><a name="l01040"></a><span class="lineno"> 1040</span>&#160;            layerData.reserve (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>.size ()+1);</div><div class="line"><a name="l01041"></a><span class="lineno"> 1041</span>&#160;            <span class="keyword">auto</span> itWeight = begin (weights);</div><div class="line"><a name="l01042"></a><span class="lineno"> 1042</span>&#160;            <span class="keyword">auto</span> itInputBegin = begin (input);</div><div class="line"><a name="l01043"></a><span class="lineno"> 1043</span>&#160;            <span class="keyword">auto</span> itInputEnd = end (input);</div><div class="line"><a name="l01044"></a><span class="lineno"> 1044</span>&#160;            layerData.push_back (<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a> (itInputBegin, itInputEnd));</div><div class="line"><a name="l01045"></a><span class="lineno"> 1045</span>&#160;            <span class="keywordtype">size_t</span> numNodesPrev = input.size ();</div><div class="line"><a name="l01046"></a><span class="lineno"> 1046</span>&#160;        </div><div class="line"><a name="l01047"></a><span class="lineno"> 1047</span>&#160;        <span class="comment">// -------------------- prepare layer data with one pattern -------------------------------</span></div><div class="line"><a name="l01048"></a><span class="lineno"> 1048</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer: <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>)</div><div class="line"><a name="l01049"></a><span class="lineno"> 1049</span>&#160;            {</div><div class="line"><a name="l01050"></a><span class="lineno"> 1050</span>&#160;                layerData.push_back (<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a> (layer.numNodes (), itWeight, </div><div class="line"><a name="l01051"></a><span class="lineno"> 1051</span>&#160;                                                layer.activationFunction (),</div><div class="line"><a name="l01052"></a><span class="lineno"> 1052</span>&#160;                                                layer.modeOutputValues ()));</div><div class="line"><a name="l01053"></a><span class="lineno"> 1053</span>&#160;                <span class="keywordtype">size_t</span> _numWeights = layer.numWeights (numNodesPrev);</div><div class="line"><a name="l01054"></a><span class="lineno"> 1054</span>&#160;                itWeight += _numWeights;</div><div class="line"><a name="l01055"></a><span class="lineno"> 1055</span>&#160;                numNodesPrev = layer.numNodes ();</div><div class="line"><a name="l01056"></a><span class="lineno"> 1056</span>&#160;            }</div><div class="line"><a name="l01057"></a><span class="lineno"> 1057</span>&#160;       </div><div class="line"><a name="l01058"></a><span class="lineno"> 1058</span>&#160;</div><div class="line"><a name="l01059"></a><span class="lineno"> 1059</span>&#160;            <span class="comment">// --------- forward -------------</span></div><div class="line"><a name="l01060"></a><span class="lineno"> 1060</span>&#160;        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#afb9c3ed1294f3bcf3c17f1b9091e9889">forwardPattern</a> (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>, layerData);</div><div class="line"><a name="l01061"></a><span class="lineno"> 1061</span>&#160;</div><div class="line"><a name="l01062"></a><span class="lineno"> 1062</span>&#160;            <span class="comment">// ------------- fetch output ------------------</span></div><div class="line"><a name="l01063"></a><span class="lineno"> 1063</span>&#160;                std::vector&lt;double&gt; <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>;</div><div class="line"><a name="l01064"></a><span class="lineno"> 1064</span>&#160;        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b">fetchOutput</a> (layerData.back (), <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>);</div><div class="line"><a name="l01065"></a><span class="lineno"> 1065</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a>;</div><div class="line"><a name="l01066"></a><span class="lineno"> 1066</span>&#160;        }</div><div class="line"><a name="l01067"></a><span class="lineno"> 1067</span>&#160;</div><div class="line"><a name="l01068"></a><span class="lineno"> 1068</span>&#160;</div><div class="line"><a name="l01069"></a><span class="lineno"> 1069</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Weights, <span class="keyword">typename</span> PassThrough&gt;</div><div class="line"><a name="l01070"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#ad60351d50e38b22256356e73be138133"> 1070</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#ad60351d50e38b22256356e73be138133">Net::operator() </a>(PassThrough&amp; settingsAndBatch, <span class="keyword">const</span> Weights&amp; weights)<span class="keyword"> const</span></div><div class="line"><a name="l01071"></a><span class="lineno"> 1071</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01072"></a><span class="lineno"> 1072</span>&#160;            std::vector&lt;double&gt; nothing; <span class="comment">// empty gradients; no backpropagation is done, just forward</span></div><div class="line"><a name="l01073"></a><span class="lineno"> 1073</span>&#160;            assert (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#aea9c06caef41621ed569678d6ad50d1c">numWeights</a> () == weights.size ());</div><div class="line"><a name="l01074"></a><span class="lineno"> 1074</span>&#160;   <span class="keywordtype">double</span> error = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91">forward_backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, <span class="keyword">false</span>);</div><div class="line"><a name="l01075"></a><span class="lineno"> 1075</span>&#160;            <span class="keywordflow">return</span> error;</div><div class="line"><a name="l01076"></a><span class="lineno"> 1076</span>&#160;        }</div><div class="line"><a name="l01077"></a><span class="lineno"> 1077</span>&#160;</div><div class="line"><a name="l01078"></a><span class="lineno"> 1078</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Weights, <span class="keyword">typename</span> PassThrough, <span class="keyword">typename</span> OutContainer&gt;</div><div class="line"><a name="l01079"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#aec2106c2487f3ac64a2ed11a2a205640"> 1079</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#ad60351d50e38b22256356e73be138133">Net::operator() </a>(PassThrough&amp; settingsAndBatch, <span class="keyword">const</span> Weights&amp; weights, <a class="code" href="namespaceTMVA_1_1DNN.html#a2fe58f5bcff33ea6e0dc1a5ae8b1161a">ModeOutput</a> <span class="comment">/*eFetch*/</span>, OutContainer&amp; outputContainer)<span class="keyword"> const</span></div><div class="line"><a name="l01080"></a><span class="lineno"> 1080</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01081"></a><span class="lineno"> 1081</span>&#160;            std::vector&lt;double&gt; nothing; <span class="comment">// empty gradients; no backpropagation is done, just forward</span></div><div class="line"><a name="l01082"></a><span class="lineno"> 1082</span>&#160;            assert (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#aea9c06caef41621ed569678d6ad50d1c">numWeights</a> () == weights.size ());</div><div class="line"><a name="l01083"></a><span class="lineno"> 1083</span>&#160;   <span class="keywordtype">double</span> error = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91">forward_backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, <span class="keyword">true</span>);</div><div class="line"><a name="l01084"></a><span class="lineno"> 1084</span>&#160;            <span class="keywordflow">return</span> error;</div><div class="line"><a name="l01085"></a><span class="lineno"> 1085</span>&#160;        }</div><div class="line"><a name="l01086"></a><span class="lineno"> 1086</span>&#160;</div><div class="line"><a name="l01087"></a><span class="lineno"> 1087</span>&#160;    </div><div class="line"><a name="l01088"></a><span class="lineno"> 1088</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Weights, <span class="keyword">typename</span> Gradients, <span class="keyword">typename</span> PassThrough&gt;</div><div class="line"><a name="l01089"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a091f06fc27ca113f7db05ac321bdeaa2"> 1089</a></span>&#160;        <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#ad60351d50e38b22256356e73be138133">Net::operator() </a>(PassThrough&amp; settingsAndBatch, Weights&amp; weights, Gradients&amp; gradients)<span class="keyword"> const</span></div><div class="line"><a name="l01090"></a><span class="lineno"> 1090</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01091"></a><span class="lineno"> 1091</span>&#160;            std::vector&lt;double&gt; nothing;</div><div class="line"><a name="l01092"></a><span class="lineno"> 1092</span>&#160;            assert (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#aea9c06caef41621ed569678d6ad50d1c">numWeights</a> () == weights.size ());</div><div class="line"><a name="l01093"></a><span class="lineno"> 1093</span>&#160;            assert (weights.size () == gradients.size ());</div><div class="line"><a name="l01094"></a><span class="lineno"> 1094</span>&#160;   <span class="keywordtype">double</span> error = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91">forward_backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, <span class="keyword">false</span>);</div><div class="line"><a name="l01095"></a><span class="lineno"> 1095</span>&#160;            <span class="keywordflow">return</span> error;</div><div class="line"><a name="l01096"></a><span class="lineno"> 1096</span>&#160;        }</div><div class="line"><a name="l01097"></a><span class="lineno"> 1097</span>&#160;</div><div class="line"><a name="l01098"></a><span class="lineno"> 1098</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Weights, <span class="keyword">typename</span> Gradients, <span class="keyword">typename</span> PassThrough, <span class="keyword">typename</span> OutContainer&gt;</div><div class="line"><a name="l01099"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a027e20765860b6262ff7f556065d5b20"> 1099</a></span>&#160;        <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#ad60351d50e38b22256356e73be138133">Net::operator() </a>(PassThrough&amp; settingsAndBatch, Weights&amp; weights, Gradients&amp; gradients, <a class="code" href="namespaceTMVA_1_1DNN.html#a2fe58f5bcff33ea6e0dc1a5ae8b1161a">ModeOutput</a> eFetch, OutContainer&amp; outputContainer)<span class="keyword"> const</span></div><div class="line"><a name="l01100"></a><span class="lineno"> 1100</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01101"></a><span class="lineno"> 1101</span>&#160;            <a class="code" href="Util_8h.html#addc4ff313880673f5f81049d16e837da">MATH_UNUSED</a>(eFetch);</div><div class="line"><a name="l01102"></a><span class="lineno"> 1102</span>&#160;            assert (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#aea9c06caef41621ed569678d6ad50d1c">numWeights</a> () == weights.size ());</div><div class="line"><a name="l01103"></a><span class="lineno"> 1103</span>&#160;            assert (weights.size () == gradients.size ());</div><div class="line"><a name="l01104"></a><span class="lineno"> 1104</span>&#160;   <span class="keywordtype">double</span> error = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91">forward_backward</a>(<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">m_layers</a>, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, <span class="keyword">true</span>);</div><div class="line"><a name="l01105"></a><span class="lineno"> 1105</span>&#160;            <span class="keywordflow">return</span> error;</div><div class="line"><a name="l01106"></a><span class="lineno"> 1106</span>&#160;        }</div><div class="line"><a name="l01107"></a><span class="lineno"> 1107</span>&#160;</div><div class="line"><a name="l01108"></a><span class="lineno"> 1108</span>&#160;</div><div class="line"><a name="l01109"></a><span class="lineno"> 1109</span>&#160;</div><div class="line"><a name="l01110"></a><span class="lineno"> 1110</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> LayerContainer, <span class="keyword">typename</span> DropContainer, <span class="keyword">typename</span> ItWeight, <span class="keyword">typename</span> ItGradient&gt;</div><div class="line"><a name="l01111"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a77bcd2e07ff2c98832ffa70f4a415828"> 1111</a></span>&#160;        std::vector&lt;std::vector&lt;LayerData&gt;&gt; <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a77bcd2e07ff2c98832ffa70f4a415828">Net::prepareLayerData</a> (LayerContainer&amp; _layers,</div><div class="line"><a name="l01112"></a><span class="lineno"> 1112</span>&#160;                                                                   <a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a>&amp; batch,</div><div class="line"><a name="l01113"></a><span class="lineno"> 1113</span>&#160;                                                                   <span class="keyword">const</span> <a class="code" href="namespaceTMVA_1_1DNN.html#ae1bb14a8b9c6de194c25e9c74c1615e5">DropContainer</a>&amp; dropContainer,</div><div class="line"><a name="l01114"></a><span class="lineno"> 1114</span>&#160;                                                                   ItWeight itWeightBegin,</div><div class="line"><a name="l01115"></a><span class="lineno"> 1115</span>&#160;                                                                   ItWeight <span class="comment">/*itWeightEnd*/</span>, </div><div class="line"><a name="l01116"></a><span class="lineno"> 1116</span>&#160;                                                                   ItGradient itGradientBegin,</div><div class="line"><a name="l01117"></a><span class="lineno"> 1117</span>&#160;                                                                   ItGradient itGradientEnd,</div><div class="line"><a name="l01118"></a><span class="lineno"> 1118</span>&#160;                                                                   <span class="keywordtype">size_t</span>&amp; totalNumWeights)<span class="keyword"> const</span></div><div class="line"><a name="l01119"></a><span class="lineno"> 1119</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01120"></a><span class="lineno"> 1120</span>&#160;        <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#afbb04013581dbe91bfddbd2243559ec3">LayerData::const_dropout_iterator</a> itDropOut;</div><div class="line"><a name="l01121"></a><span class="lineno"> 1121</span>&#160;        <span class="keywordtype">bool</span> usesDropOut = !dropContainer.empty ();</div><div class="line"><a name="l01122"></a><span class="lineno"> 1122</span>&#160;        <span class="keywordflow">if</span> (usesDropOut)</div><div class="line"><a name="l01123"></a><span class="lineno"> 1123</span>&#160;            itDropOut = std::begin (dropContainer);</div><div class="line"><a name="l01124"></a><span class="lineno"> 1124</span>&#160;        </div><div class="line"><a name="l01125"></a><span class="lineno"> 1125</span>&#160;   <span class="keywordflow">if</span> (_layers.empty ())</div><div class="line"><a name="l01126"></a><span class="lineno"> 1126</span>&#160;       <span class="keywordflow">throw</span> std::string (<span class="stringliteral">&quot;no layers in this net&quot;</span>);</div><div class="line"><a name="l01127"></a><span class="lineno"> 1127</span>&#160;        </div><div class="line"><a name="l01128"></a><span class="lineno"> 1128</span>&#160;        </div><div class="line"><a name="l01129"></a><span class="lineno"> 1129</span>&#160;        <span class="comment">// ----------- create layer data -------------------------------------------------------</span></div><div class="line"><a name="l01130"></a><span class="lineno"> 1130</span>&#160;        <span class="comment">//LM- This assert not needed anymore (outputsize is actually numNodes+1)</span></div><div class="line"><a name="l01131"></a><span class="lineno"> 1131</span>&#160;        <span class="comment">//assert (_layers.back ().numNodes () == outputSize ());</span></div><div class="line"><a name="l01132"></a><span class="lineno"> 1132</span>&#160;        totalNumWeights = 0;</div><div class="line"><a name="l01133"></a><span class="lineno"> 1133</span>&#160;        <span class="keywordtype">size_t</span> totalNumNodes = 0;</div><div class="line"><a name="l01134"></a><span class="lineno"> 1134</span>&#160;        std::vector&lt;std::vector&lt;LayerData&gt;&gt; layerPatternData;</div><div class="line"><a name="l01135"></a><span class="lineno"> 1135</span>&#160;        layerPatternData.reserve (_layers.size ()+1);</div><div class="line"><a name="l01136"></a><span class="lineno"> 1136</span>&#160;        ItWeight itWeight = itWeightBegin;</div><div class="line"><a name="l01137"></a><span class="lineno"> 1137</span>&#160;        ItGradient itGradient = itGradientBegin;</div><div class="line"><a name="l01138"></a><span class="lineno"> 1138</span>&#160;        <span class="keywordtype">size_t</span> numNodesPrev = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l01139"></a><span class="lineno"> 1139</span>&#160;        <span class="keyword">typename</span> <a class="code" href="classPattern.html#ab3e1728f0a8c0934a4e4c8d12c27a0fe">Pattern::const_iterator</a> itInputBegin;</div><div class="line"><a name="l01140"></a><span class="lineno"> 1140</span>&#160;        <span class="keyword">typename</span> <a class="code" href="classPattern.html#ab3e1728f0a8c0934a4e4c8d12c27a0fe">Pattern::const_iterator</a> itInputEnd;</div><div class="line"><a name="l01141"></a><span class="lineno"> 1141</span>&#160;</div><div class="line"><a name="l01142"></a><span class="lineno"> 1142</span>&#160;        <span class="comment">// ItWeight itGammaBegin = itWeightBegin + numWeights ();</span></div><div class="line"><a name="l01143"></a><span class="lineno"> 1143</span>&#160;        <span class="comment">// ItWeight itBetaBegin = itWeightBegin + numWeights () + numNodes ();</span></div><div class="line"><a name="l01144"></a><span class="lineno"> 1144</span>&#160;        <span class="comment">// ItGradient itGradGammaBegin = itGradientBegin + numWeights ();</span></div><div class="line"><a name="l01145"></a><span class="lineno"> 1145</span>&#160;        <span class="comment">// ItGradient itGradBetaBegin = itGradientBegin + numWeights () + numNodes ();</span></div><div class="line"><a name="l01146"></a><span class="lineno"> 1146</span>&#160;</div><div class="line"><a name="l01147"></a><span class="lineno"> 1147</span>&#160;        </div><div class="line"><a name="l01148"></a><span class="lineno"> 1148</span>&#160;        <span class="comment">// --------------------- prepare layer data for input layer ----------------------------</span></div><div class="line"><a name="l01149"></a><span class="lineno"> 1149</span>&#160;        layerPatternData.push_back (std::vector&lt;LayerData&gt;());</div><div class="line"><a name="l01150"></a><span class="lineno"> 1150</span>&#160;   <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classPattern.html">Pattern</a>&amp; _pattern : batch)</div><div class="line"><a name="l01151"></a><span class="lineno"> 1151</span>&#160;        {</div><div class="line"><a name="l01152"></a><span class="lineno"> 1152</span>&#160;            std::vector&lt;LayerData&gt;&amp; layerData = layerPatternData.back ();</div><div class="line"><a name="l01153"></a><span class="lineno"> 1153</span>&#160;            layerData.push_back (<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a> (numNodesPrev));</div><div class="line"><a name="l01154"></a><span class="lineno"> 1154</span>&#160;</div><div class="line"><a name="l01155"></a><span class="lineno"> 1155</span>&#160;            itInputBegin = _pattern.beginInput ();</div><div class="line"><a name="l01156"></a><span class="lineno"> 1156</span>&#160;            itInputEnd = _pattern.endInput ();</div><div class="line"><a name="l01157"></a><span class="lineno"> 1157</span>&#160;            layerData.back ().setInput (itInputBegin, itInputEnd);</div><div class="line"><a name="l01158"></a><span class="lineno"> 1158</span>&#160;            </div><div class="line"><a name="l01159"></a><span class="lineno"> 1159</span>&#160;            <span class="keywordflow">if</span> (usesDropOut)</div><div class="line"><a name="l01160"></a><span class="lineno"> 1160</span>&#160;                layerData.back ().setDropOut (itDropOut);</div><div class="line"><a name="l01161"></a><span class="lineno"> 1161</span>&#160;</div><div class="line"><a name="l01162"></a><span class="lineno"> 1162</span>&#160;        }</div><div class="line"><a name="l01163"></a><span class="lineno"> 1163</span>&#160;</div><div class="line"><a name="l01164"></a><span class="lineno"> 1164</span>&#160;        </div><div class="line"><a name="l01165"></a><span class="lineno"> 1165</span>&#160;        <span class="keywordflow">if</span> (usesDropOut)</div><div class="line"><a name="l01166"></a><span class="lineno"> 1166</span>&#160;            itDropOut += _layers.back ().numNodes ();</div><div class="line"><a name="l01167"></a><span class="lineno"> 1167</span>&#160;</div><div class="line"><a name="l01168"></a><span class="lineno"> 1168</span>&#160;        <span class="comment">// ---------------- prepare subsequent layers ---------------------------------------------</span></div><div class="line"><a name="l01169"></a><span class="lineno"> 1169</span>&#160;        <span class="comment">// for each of the layers</span></div><div class="line"><a name="l01170"></a><span class="lineno"> 1170</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">auto</span> itLayer = begin (_layers), itLayerEnd = end (_layers); itLayer != itLayerEnd; ++itLayer)</div><div class="line"><a name="l01171"></a><span class="lineno"> 1171</span>&#160;        {</div><div class="line"><a name="l01172"></a><span class="lineno"> 1172</span>&#160;            <span class="keywordtype">bool</span> isOutputLayer = (itLayer+1 == itLayerEnd);</div><div class="line"><a name="l01173"></a><span class="lineno"> 1173</span>&#160;            <span class="keywordtype">bool</span> isFirstHiddenLayer = (itLayer == begin (_layers));</div><div class="line"><a name="l01174"></a><span class="lineno"> 1174</span>&#160;            </div><div class="line"><a name="l01175"></a><span class="lineno"> 1175</span>&#160;            <span class="keyword">auto</span>&amp; layer = *itLayer;</div><div class="line"><a name="l01176"></a><span class="lineno"> 1176</span>&#160;            layerPatternData.push_back (std::vector&lt;LayerData&gt;());</div><div class="line"><a name="l01177"></a><span class="lineno"> 1177</span>&#160;            <span class="comment">// for each pattern, prepare a layerData</span></div><div class="line"><a name="l01178"></a><span class="lineno"> 1178</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classPattern.html">Pattern</a>&amp; _pattern : batch)</div><div class="line"><a name="l01179"></a><span class="lineno"> 1179</span>&#160;            {</div><div class="line"><a name="l01180"></a><span class="lineno"> 1180</span>&#160;                std::vector&lt;LayerData&gt;&amp; layerData = layerPatternData.back ();</div><div class="line"><a name="l01181"></a><span class="lineno"> 1181</span>&#160;                <span class="comment">//layerData.push_back (LayerData (numNodesPrev));</span></div><div class="line"><a name="l01182"></a><span class="lineno"> 1182</span>&#160;</div><div class="line"><a name="l01183"></a><span class="lineno"> 1183</span>&#160;                <span class="keywordflow">if</span> (itGradientBegin == itGradientEnd)</div><div class="line"><a name="l01184"></a><span class="lineno"> 1184</span>&#160;                {</div><div class="line"><a name="l01185"></a><span class="lineno"> 1185</span>&#160;                    layerData.push_back (<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a> (layer.numNodes (), itWeight, </div><div class="line"><a name="l01186"></a><span class="lineno"> 1186</span>&#160;                                                    layer.activationFunction (),</div><div class="line"><a name="l01187"></a><span class="lineno"> 1187</span>&#160;                                                    layer.modeOutputValues ()));</div><div class="line"><a name="l01188"></a><span class="lineno"> 1188</span>&#160;                }</div><div class="line"><a name="l01189"></a><span class="lineno"> 1189</span>&#160;                <span class="keywordflow">else</span></div><div class="line"><a name="l01190"></a><span class="lineno"> 1190</span>&#160;                {</div><div class="line"><a name="l01191"></a><span class="lineno"> 1191</span>&#160;                    layerData.push_back (<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a> (layer.numNodes (), itWeight, itGradient, </div><div class="line"><a name="l01192"></a><span class="lineno"> 1192</span>&#160;                                                    layer.activationFunction (),</div><div class="line"><a name="l01193"></a><span class="lineno"> 1193</span>&#160;                                                    layer.inverseActivationFunction (),</div><div class="line"><a name="l01194"></a><span class="lineno"> 1194</span>&#160;                                                    layer.modeOutputValues ()));</div><div class="line"><a name="l01195"></a><span class="lineno"> 1195</span>&#160;                }</div><div class="line"><a name="l01196"></a><span class="lineno"> 1196</span>&#160;</div><div class="line"><a name="l01197"></a><span class="lineno"> 1197</span>&#160;                <span class="keywordflow">if</span> (usesDropOut)</div><div class="line"><a name="l01198"></a><span class="lineno"> 1198</span>&#160;                {</div><div class="line"><a name="l01199"></a><span class="lineno"> 1199</span>&#160;                    layerData.back ().setDropOut (itDropOut);</div><div class="line"><a name="l01200"></a><span class="lineno"> 1200</span>&#160;                }</div><div class="line"><a name="l01201"></a><span class="lineno"> 1201</span>&#160;</div><div class="line"><a name="l01202"></a><span class="lineno"> 1202</span>&#160;            }</div><div class="line"><a name="l01203"></a><span class="lineno"> 1203</span>&#160;</div><div class="line"><a name="l01204"></a><span class="lineno"> 1204</span>&#160;            <span class="keywordflow">if</span> (usesDropOut)</div><div class="line"><a name="l01205"></a><span class="lineno"> 1205</span>&#160;            {</div><div class="line"><a name="l01206"></a><span class="lineno"> 1206</span>&#160;                itDropOut += layer.numNodes ();</div><div class="line"><a name="l01207"></a><span class="lineno"> 1207</span>&#160;            }</div><div class="line"><a name="l01208"></a><span class="lineno"> 1208</span>&#160;            <span class="keywordtype">size_t</span> _numWeights = layer.numWeights (numNodesPrev);</div><div class="line"><a name="l01209"></a><span class="lineno"> 1209</span>&#160;            totalNumWeights += _numWeights;</div><div class="line"><a name="l01210"></a><span class="lineno"> 1210</span>&#160;            itWeight += _numWeights;</div><div class="line"><a name="l01211"></a><span class="lineno"> 1211</span>&#160;            itGradient += _numWeights;</div><div class="line"><a name="l01212"></a><span class="lineno"> 1212</span>&#160;            numNodesPrev = layer.numNodes ();</div><div class="line"><a name="l01213"></a><span class="lineno"> 1213</span>&#160;            totalNumNodes += numNodesPrev;</div><div class="line"><a name="l01214"></a><span class="lineno"> 1214</span>&#160;</div><div class="line"><a name="l01215"></a><span class="lineno"> 1215</span>&#160;        }</div><div class="line"><a name="l01216"></a><span class="lineno"> 1216</span>&#160;   assert (totalNumWeights &gt; 0);</div><div class="line"><a name="l01217"></a><span class="lineno"> 1217</span>&#160;        <span class="keywordflow">return</span> layerPatternData;</div><div class="line"><a name="l01218"></a><span class="lineno"> 1218</span>&#160;}</div><div class="line"><a name="l01219"></a><span class="lineno"> 1219</span>&#160;</div><div class="line"><a name="l01220"></a><span class="lineno"> 1220</span>&#160;</div><div class="line"><a name="l01221"></a><span class="lineno"> 1221</span>&#160;</div><div class="line"><a name="l01222"></a><span class="lineno"> 1222</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> LayerContainer&gt;</div><div class="line"><a name="l01223"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#afb9c3ed1294f3bcf3c17f1b9091e9889"> 1223</a></span>&#160;        <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#afb9c3ed1294f3bcf3c17f1b9091e9889">Net::forwardPattern</a> (<span class="keyword">const</span> LayerContainer&amp; _layers,</div><div class="line"><a name="l01224"></a><span class="lineno"> 1224</span>&#160;                                  std::vector&lt;LayerData&gt;&amp; layerData)<span class="keyword"> const</span></div><div class="line"><a name="l01225"></a><span class="lineno"> 1225</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01226"></a><span class="lineno"> 1226</span>&#160;   <span class="keywordtype">size_t</span> idxLayer = 0, idxLayerEnd = _layers.size ();</div><div class="line"><a name="l01227"></a><span class="lineno"> 1227</span>&#160;        <span class="keywordtype">size_t</span> cumulativeNodeCount = 0;</div><div class="line"><a name="l01228"></a><span class="lineno"> 1228</span>&#160;   <span class="keywordflow">for</span> (; idxLayer &lt; idxLayerEnd; ++idxLayer)</div><div class="line"><a name="l01229"></a><span class="lineno"> 1229</span>&#160;   {</div><div class="line"><a name="l01230"></a><span class="lineno"> 1230</span>&#160;       <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; prevLayerData = layerData.at (idxLayer);</div><div class="line"><a name="l01231"></a><span class="lineno"> 1231</span>&#160;       <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; currLayerData = layerData.at (idxLayer+1);</div><div class="line"><a name="l01232"></a><span class="lineno"> 1232</span>&#160;      </div><div class="line"><a name="l01233"></a><span class="lineno"> 1233</span>&#160;       <a class="code" href="namespaceTMVA_1_1DNN.html#a1c5ba59d5d3a4d5acba28e4a6a772994">forward</a> (prevLayerData, currLayerData);</div><div class="line"><a name="l01234"></a><span class="lineno"> 1234</span>&#160;</div><div class="line"><a name="l01235"></a><span class="lineno"> 1235</span>&#160;            <a class="code" href="namespaceTMVA_1_1DNN.html#a1e2e55b912c7f2266d2ef39a08cfea43">applyFunctions</a> (currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#afbb661b4ea410c550dc914f71bce11c2">valuesBegin</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a08a1450b225d1df574935b2f5fb66ca5">valuesEnd</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a04d1a3ffa1783bed8019baafde0a7356">activationFunction</a> ());</div><div class="line"><a name="l01236"></a><span class="lineno"> 1236</span>&#160;   }</div><div class="line"><a name="l01237"></a><span class="lineno"> 1237</span>&#160;    }</div><div class="line"><a name="l01238"></a><span class="lineno"> 1238</span>&#160;</div><div class="line"><a name="l01239"></a><span class="lineno"> 1239</span>&#160;</div><div class="line"><a name="l01240"></a><span class="lineno"> 1240</span>&#160;</div><div class="line"><a name="l01241"></a><span class="lineno"> 1241</span>&#160;</div><div class="line"><a name="l01242"></a><span class="lineno"> 1242</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> LayerContainer, <span class="keyword">typename</span> LayerPatternContainer&gt;</div><div class="line"><a name="l01243"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a1753608a2adb76f250d720a82a78b57e"> 1243</a></span>&#160;        <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a1753608a2adb76f250d720a82a78b57e">Net::forwardBatch</a> (<span class="keyword">const</span> LayerContainer&amp; _layers,</div><div class="line"><a name="l01244"></a><span class="lineno"> 1244</span>&#160;                                LayerPatternContainer&amp; layerPatternData,</div><div class="line"><a name="l01245"></a><span class="lineno"> 1245</span>&#160;                                std::vector&lt;double&gt;&amp; valuesMean,</div><div class="line"><a name="l01246"></a><span class="lineno"> 1246</span>&#160;                                std::vector&lt;double&gt;&amp; valuesStdDev,</div><div class="line"><a name="l01247"></a><span class="lineno"> 1247</span>&#160;                                <span class="keywordtype">size_t</span> trainFromLayer)<span class="keyword"> const</span></div><div class="line"><a name="l01248"></a><span class="lineno"> 1248</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01249"></a><span class="lineno"> 1249</span>&#160;        valuesMean.clear ();</div><div class="line"><a name="l01250"></a><span class="lineno"> 1250</span>&#160;        valuesStdDev.clear ();</div><div class="line"><a name="l01251"></a><span class="lineno"> 1251</span>&#160;        </div><div class="line"><a name="l01252"></a><span class="lineno"> 1252</span>&#160;        <span class="comment">// ---------------------------------- loop over layers and pattern -------------------------------------------------------</span></div><div class="line"><a name="l01253"></a><span class="lineno"> 1253</span>&#160;        <span class="keywordtype">size_t</span> cumulativeNodeCount = 0;</div><div class="line"><a name="l01254"></a><span class="lineno"> 1254</span>&#160;   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idxLayer = 0, idxLayerEnd = layerPatternData.size (); idxLayer &lt; idxLayerEnd-1; ++idxLayer) </div><div class="line"><a name="l01255"></a><span class="lineno"> 1255</span>&#160;   {</div><div class="line"><a name="l01256"></a><span class="lineno"> 1256</span>&#160;       <span class="keywordtype">bool</span> doTraining = idxLayer &gt;= trainFromLayer;</div><div class="line"><a name="l01257"></a><span class="lineno"> 1257</span>&#160;</div><div class="line"><a name="l01258"></a><span class="lineno"> 1258</span>&#160;            <span class="comment">// get layer-pattern data for this and the corresponding one from the next layer</span></div><div class="line"><a name="l01259"></a><span class="lineno"> 1259</span>&#160;            std::vector&lt;LayerData&gt;&amp; prevLayerPatternData = layerPatternData.at (idxLayer);</div><div class="line"><a name="l01260"></a><span class="lineno"> 1260</span>&#160;            std::vector&lt;LayerData&gt;&amp; currLayerPatternData = layerPatternData.at (idxLayer+1);</div><div class="line"><a name="l01261"></a><span class="lineno"> 1261</span>&#160;</div><div class="line"><a name="l01262"></a><span class="lineno"> 1262</span>&#160;            <span class="keywordtype">size_t</span> numPattern = prevLayerPatternData.size ();</div><div class="line"><a name="l01263"></a><span class="lineno"> 1263</span>&#160;            <span class="keywordtype">size_t</span> numNodesLayer = _layers.at (idxLayer).numNodes ();</div><div class="line"><a name="l01264"></a><span class="lineno"> 1264</span>&#160;</div><div class="line"><a name="l01265"></a><span class="lineno"> 1265</span>&#160;            std::vector&lt;MeanVariance&gt; means (numNodesLayer);</div><div class="line"><a name="l01266"></a><span class="lineno"> 1266</span>&#160;            <span class="comment">// ---------------- loop over layerDatas of pattern compute forward ----------------------------</span></div><div class="line"><a name="l01267"></a><span class="lineno"> 1267</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idxPattern = 0; idxPattern &lt; numPattern; ++idxPattern)</div><div class="line"><a name="l01268"></a><span class="lineno"> 1268</span>&#160;            {</div><div class="line"><a name="l01269"></a><span class="lineno"> 1269</span>&#160;      <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; prevLayerData = prevLayerPatternData.at (idxPattern);</div><div class="line"><a name="l01270"></a><span class="lineno"> 1270</span>&#160;      <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; currLayerData = currLayerPatternData.at (idxPattern);</div><div class="line"><a name="l01271"></a><span class="lineno"> 1271</span>&#160;                </div><div class="line"><a name="l01272"></a><span class="lineno"> 1272</span>&#160;            </div><div class="line"><a name="l01273"></a><span class="lineno"> 1273</span>&#160;                <a class="code" href="namespaceTMVA_1_1DNN.html#a1c5ba59d5d3a4d5acba28e4a6a772994">forward</a> (prevLayerData, currLayerData); <span class="comment">// feed forward</span></div><div class="line"><a name="l01274"></a><span class="lineno"> 1274</span>&#160;            }</div><div class="line"><a name="l01275"></a><span class="lineno"> 1275</span>&#160;            </div><div class="line"><a name="l01276"></a><span class="lineno"> 1276</span>&#160;            <span class="comment">// ---------------- loop over layerDatas of pattern apply non-linearities ----------------------------</span></div><div class="line"><a name="l01277"></a><span class="lineno"> 1277</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idxPattern = 0; idxPattern &lt; numPattern; ++idxPattern)</div><div class="line"><a name="l01278"></a><span class="lineno"> 1278</span>&#160;            {</div><div class="line"><a name="l01279"></a><span class="lineno"> 1279</span>&#160;      <span class="comment">//const LayerData&amp; prevLayerData = prevLayerPatternData.at (idxPattern);</span></div><div class="line"><a name="l01280"></a><span class="lineno"> 1280</span>&#160;      <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; currLayerData = currLayerPatternData.at (idxPattern);</div><div class="line"><a name="l01281"></a><span class="lineno"> 1281</span>&#160;                </div><div class="line"><a name="l01282"></a><span class="lineno"> 1282</span>&#160;      <span class="keywordflow">if</span> (doTraining)</div><div class="line"><a name="l01283"></a><span class="lineno"> 1283</span>&#160;                    <a class="code" href="namespaceTMVA_1_1DNN.html#a1e2e55b912c7f2266d2ef39a08cfea43">applyFunctions</a> (currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#afbb661b4ea410c550dc914f71bce11c2">valuesBegin</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a08a1450b225d1df574935b2f5fb66ca5">valuesEnd</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a04d1a3ffa1783bed8019baafde0a7356">activationFunction</a> (), </div><div class="line"><a name="l01284"></a><span class="lineno"> 1284</span>&#160;                                    currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#af0df1790cf8163734db09fa89182c8e9">inverseActivationFunction</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a3c5afad7c1a30b14d87436b0df39375b">valueGradientsBegin</a> ());</div><div class="line"><a name="l01285"></a><span class="lineno"> 1285</span>&#160;      <span class="keywordflow">else</span></div><div class="line"><a name="l01286"></a><span class="lineno"> 1286</span>&#160;                    <a class="code" href="namespaceTMVA_1_1DNN.html#a1e2e55b912c7f2266d2ef39a08cfea43">applyFunctions</a> (currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#afbb661b4ea410c550dc914f71bce11c2">valuesBegin</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a08a1450b225d1df574935b2f5fb66ca5">valuesEnd</a> (), currLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a04d1a3ffa1783bed8019baafde0a7356">activationFunction</a> ());</div><div class="line"><a name="l01287"></a><span class="lineno"> 1287</span>&#160;            }</div><div class="line"><a name="l01288"></a><span class="lineno"> 1288</span>&#160;</div><div class="line"><a name="l01289"></a><span class="lineno"> 1289</span>&#160;            <span class="comment">// accumulate node count</span></div><div class="line"><a name="l01290"></a><span class="lineno"> 1290</span>&#160;            cumulativeNodeCount += numNodesLayer;</div><div class="line"><a name="l01291"></a><span class="lineno"> 1291</span>&#160;        }</div><div class="line"><a name="l01292"></a><span class="lineno"> 1292</span>&#160;}</div><div class="line"><a name="l01293"></a><span class="lineno"> 1293</span>&#160;</div><div class="line"><a name="l01294"></a><span class="lineno"> 1294</span>&#160;</div><div class="line"><a name="l01295"></a><span class="lineno"> 1295</span>&#160;</div><div class="line"><a name="l01296"></a><span class="lineno"> 1296</span>&#160;</div><div class="line"><a name="l01297"></a><span class="lineno"> 1297</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> OutputContainer&gt;</div><div class="line"><a name="l01298"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b"> 1298</a></span>&#160;        <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b">Net::fetchOutput</a> (<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; lastLayerData, OutputContainer&amp; outputContainer)<span class="keyword"> const</span></div><div class="line"><a name="l01299"></a><span class="lineno"> 1299</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01300"></a><span class="lineno"> 1300</span>&#160;        <a class="code" href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738">ModeOutputValues</a> eModeOutput = lastLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a9b0f919dff3cfe96f4f1d0ad52ac8989">outputMode</a> ();</div><div class="line"><a name="l01301"></a><span class="lineno"> 1301</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="namespaceTMVA_1_1DNN.html#ad616a47ab4724777de7ffd191aef3db0">isFlagSet</a> (<a class="code" href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738a4c5d06b02c97731aaa976179c62dcf76">ModeOutputValues::DIRECT</a>, eModeOutput))</div><div class="line"><a name="l01302"></a><span class="lineno"> 1302</span>&#160;        {</div><div class="line"><a name="l01303"></a><span class="lineno"> 1303</span>&#160;            outputContainer.insert (outputContainer.end (), lastLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#afbb661b4ea410c550dc914f71bce11c2">valuesBegin</a> (), lastLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a08a1450b225d1df574935b2f5fb66ca5">valuesEnd</a> ());</div><div class="line"><a name="l01304"></a><span class="lineno"> 1304</span>&#160;        }</div><div class="line"><a name="l01305"></a><span class="lineno"> 1305</span>&#160;        <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="namespaceTMVA_1_1DNN.html#ad616a47ab4724777de7ffd191aef3db0">isFlagSet</a> (<a class="code" href="namespaceTMVA_1_1DNN.html#a5525640c6eea8d4e92aa42a8636daa9eab299f45b5de2a8f7c45192590290742b">ModeOutputValues::SIGMOID</a>, eModeOutput) ||</div><div class="line"><a name="l01306"></a><span class="lineno"> 1306</span>&#160;                 <a class="code" href="namespaceTMVA_1_1DNN.html#ad616a47ab4724777de7ffd191aef3db0">isFlagSet</a> (<a class="code" href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738a1d993169621e0855bad00d71c005cf1b">ModeOutputValues::SOFTMAX</a>, eModeOutput))</div><div class="line"><a name="l01307"></a><span class="lineno"> 1307</span>&#160;        {</div><div class="line"><a name="l01308"></a><span class="lineno"> 1308</span>&#160;            <span class="keyword">const</span> <span class="keyword">auto</span>&amp; prob = lastLayerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#aee6aa1e3d008947a36bbd9479a352f21">probabilities</a> ();</div><div class="line"><a name="l01309"></a><span class="lineno"> 1309</span>&#160;            outputContainer.insert (outputContainer.end (), prob.begin (), prob.end ()) ;</div><div class="line"><a name="l01310"></a><span class="lineno"> 1310</span>&#160;        }</div><div class="line"><a name="l01311"></a><span class="lineno"> 1311</span>&#160;        <span class="keywordflow">else</span></div><div class="line"><a name="l01312"></a><span class="lineno"> 1312</span>&#160;            assert (<span class="keyword">false</span>);</div><div class="line"><a name="l01313"></a><span class="lineno"> 1313</span>&#160;    }</div><div class="line"><a name="l01314"></a><span class="lineno"> 1314</span>&#160;</div><div class="line"><a name="l01315"></a><span class="lineno"> 1315</span>&#160;</div><div class="line"><a name="l01316"></a><span class="lineno"> 1316</span>&#160;</div><div class="line"><a name="l01317"></a><span class="lineno"> 1317</span>&#160;</div><div class="line"><a name="l01318"></a><span class="lineno"> 1318</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> OutputContainer&gt;</div><div class="line"><a name="l01319"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a4f05bad5dcab9fc7089d462072fa8bab"> 1319</a></span>&#160;        <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b">Net::fetchOutput</a> (<span class="keyword">const</span> std::vector&lt;LayerData&gt;&amp; lastLayerPatternData, OutputContainer&amp; outputContainer)<span class="keyword"> const</span></div><div class="line"><a name="l01320"></a><span class="lineno"> 1320</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01321"></a><span class="lineno"> 1321</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; lastLayerData : lastLayerPatternData)</div><div class="line"><a name="l01322"></a><span class="lineno"> 1322</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b">fetchOutput</a> (lastLayerData, outputContainer);</div><div class="line"><a name="l01323"></a><span class="lineno"> 1323</span>&#160;    }</div><div class="line"><a name="l01324"></a><span class="lineno"> 1324</span>&#160;</div><div class="line"><a name="l01325"></a><span class="lineno"> 1325</span>&#160;</div><div class="line"><a name="l01326"></a><span class="lineno"> 1326</span>&#160;</div><div class="line"><a name="l01327"></a><span class="lineno"> 1327</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> ItWeight&gt;</div><div class="line"><a name="l01328"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#af0f3c3cad3baaff09a113304a1fac413"> 1328</a></span>&#160;        std::tuple&lt;<span class="comment">/*sumError*/</span>double,<span class="comment">/*sumWeights*/</span><span class="keywordtype">double</span>&gt; <a class="code" href="classTMVA_1_1DNN_1_1Net.html#af0f3c3cad3baaff09a113304a1fac413">Net::computeError</a> (<span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1Settings.html">Settings</a>&amp; settings,</div><div class="line"><a name="l01329"></a><span class="lineno"> 1329</span>&#160;                                                                               std::vector&lt;LayerData&gt;&amp; lastLayerData,</div><div class="line"><a name="l01330"></a><span class="lineno"> 1330</span>&#160;                                                                               <a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a>&amp; batch,</div><div class="line"><a name="l01331"></a><span class="lineno"> 1331</span>&#160;                                                                               ItWeight itWeightBegin,</div><div class="line"><a name="l01332"></a><span class="lineno"> 1332</span>&#160;                                                                               ItWeight itWeightEnd)<span class="keyword"> const</span></div><div class="line"><a name="l01333"></a><span class="lineno"> 1333</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01334"></a><span class="lineno"> 1334</span>&#160;        <span class="keyword">typename</span> std::vector&lt;LayerData&gt;::iterator itLayerData    = lastLayerData.begin ();</div><div class="line"><a name="l01335"></a><span class="lineno"> 1335</span>&#160;<span class="comment">//        typename std::vector&lt;LayerData&gt;::iterator itLayerDataEnd = lastLayerData.end ();</span></div><div class="line"><a name="l01336"></a><span class="lineno"> 1336</span>&#160;</div><div class="line"><a name="l01337"></a><span class="lineno"> 1337</span>&#160;        <span class="keyword">typename</span> std::vector&lt;Pattern&gt;::const_iterator itPattern = batch.<a class="code" href="classTMVA_1_1DNN_1_1Batch.html#a1f1c71bd2af68e6ea1105d38b1e26e3e">begin</a> ();</div><div class="line"><a name="l01338"></a><span class="lineno"> 1338</span>&#160;        <span class="keyword">typename</span> std::vector&lt;Pattern&gt;::const_iterator itPatternEnd = batch.<a class="code" href="classTMVA_1_1DNN_1_1Batch.html#a20d72553469a204881e81f7f7f77a98e">end</a> ();</div><div class="line"><a name="l01339"></a><span class="lineno"> 1339</span>&#160;</div><div class="line"><a name="l01340"></a><span class="lineno"> 1340</span>&#160;        <span class="keywordtype">double</span> sumWeights (0.0);</div><div class="line"><a name="l01341"></a><span class="lineno"> 1341</span>&#160;        <span class="keywordtype">double</span> sumError (0.0);</div><div class="line"><a name="l01342"></a><span class="lineno"> 1342</span>&#160;        </div><div class="line"><a name="l01343"></a><span class="lineno"> 1343</span>&#160;        <span class="keywordtype">size_t</span> idxPattern = 0;</div><div class="line"><a name="l01344"></a><span class="lineno"> 1344</span>&#160;<span class="comment">// FIXME: check that iteration doesn&#39;t go beyond itLayerDataEnd!</span></div><div class="line"><a name="l01345"></a><span class="lineno"> 1345</span>&#160;        <span class="keywordflow">for</span> ( ; itPattern != itPatternEnd; ++itPattern, ++itLayerData)</div><div class="line"><a name="l01346"></a><span class="lineno"> 1346</span>&#160;        {</div><div class="line"><a name="l01347"></a><span class="lineno"> 1347</span>&#160;            ++idxPattern;</div><div class="line"><a name="l01348"></a><span class="lineno"> 1348</span>&#160;                </div><div class="line"><a name="l01349"></a><span class="lineno"> 1349</span>&#160;            <span class="comment">// compute E and the deltas of the computed output and the true output</span></div><div class="line"><a name="l01350"></a><span class="lineno"> 1350</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; layerData = (*itLayerData);</div><div class="line"><a name="l01351"></a><span class="lineno"> 1351</span>&#160;            <span class="keyword">const</span> <a class="code" href="classPattern.html">Pattern</a>&amp; _pattern = (*itPattern);</div><div class="line"><a name="l01352"></a><span class="lineno"> 1352</span>&#160;            <span class="keywordtype">double</span> error = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a850543a9454e8cd69c78279f5f9619cc">errorFunction</a> (layerData, _pattern.<a class="code" href="classPattern.html#a38ce7794374830dcfaf90b78764be4cd">output</a> (), </div><div class="line"><a name="l01353"></a><span class="lineno"> 1353</span>&#160;                                          itWeightBegin, itWeightEnd, </div><div class="line"><a name="l01354"></a><span class="lineno"> 1354</span>&#160;                                          _pattern.<a class="code" href="classPattern.html#a3ed111744fc0641dffebd2e9b3b79452">weight</a> (), settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#abe90b94087ad72335813101a562dbd3f">factorWeightDecay</a> (),</div><div class="line"><a name="l01355"></a><span class="lineno"> 1355</span>&#160;                                          settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a0fa4b86e4b25221d0881db8c36646697">regularization</a> ());</div><div class="line"><a name="l01356"></a><span class="lineno"> 1356</span>&#160;            sumWeights += <a class="code" href="namespaceROOT_1_1Math.html#a09dbf6c9318d826cd59ed8abb44dc4d0">fabs</a> (_pattern.<a class="code" href="classPattern.html#a3ed111744fc0641dffebd2e9b3b79452">weight</a> ());</div><div class="line"><a name="l01357"></a><span class="lineno"> 1357</span>&#160;            sumError += error;</div><div class="line"><a name="l01358"></a><span class="lineno"> 1358</span>&#160;        }</div><div class="line"><a name="l01359"></a><span class="lineno"> 1359</span>&#160;        <span class="keywordflow">return</span> std::make_tuple (sumError, sumWeights);</div><div class="line"><a name="l01360"></a><span class="lineno"> 1360</span>&#160;    }</div><div class="line"><a name="l01361"></a><span class="lineno"> 1361</span>&#160;</div><div class="line"><a name="l01362"></a><span class="lineno"> 1362</span>&#160;</div><div class="line"><a name="l01363"></a><span class="lineno"> 1363</span>&#160;</div><div class="line"><a name="l01364"></a><span class="lineno"> 1364</span>&#160;    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Settings&gt;</div><div class="line"><a name="l01365"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a6f8505127caaa2ff0832e521b56b633e"> 1365</a></span>&#160;        <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a6f8505127caaa2ff0832e521b56b633e">Net::backPropagate</a> (std::vector&lt;std::vector&lt;LayerData&gt;&gt;&amp; layerPatternData,</div><div class="line"><a name="l01366"></a><span class="lineno"> 1366</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classTMVA_1_1DNN_1_1Settings.html">Settings</a>&amp; settings,</div><div class="line"><a name="l01367"></a><span class="lineno"> 1367</span>&#160;                                 <span class="keywordtype">size_t</span> trainFromLayer,</div><div class="line"><a name="l01368"></a><span class="lineno"> 1368</span>&#160;                                 <span class="keywordtype">size_t</span> totalNumWeights)<span class="keyword"> const</span></div><div class="line"><a name="l01369"></a><span class="lineno"> 1369</span>&#160;<span class="keyword">    </span>{</div><div class="line"><a name="l01370"></a><span class="lineno"> 1370</span>&#160;        <span class="keywordtype">bool</span> doTraining = layerPatternData.size () &gt; trainFromLayer;</div><div class="line"><a name="l01371"></a><span class="lineno"> 1371</span>&#160;        <span class="keywordflow">if</span> (doTraining) <span class="comment">// training</span></div><div class="line"><a name="l01372"></a><span class="lineno"> 1372</span>&#160;        {</div><div class="line"><a name="l01373"></a><span class="lineno"> 1373</span>&#160;            <span class="comment">// ------------- backpropagation -------------</span></div><div class="line"><a name="l01374"></a><span class="lineno"> 1374</span>&#160;            <span class="keywordtype">size_t</span> idxLayer = layerPatternData.size ();</div><div class="line"><a name="l01375"></a><span class="lineno"> 1375</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span> itLayerPatternData = layerPatternData.rbegin (), itLayerPatternDataBegin = layerPatternData.rend ();</div><div class="line"><a name="l01376"></a><span class="lineno"> 1376</span>&#160;                 itLayerPatternData != itLayerPatternDataBegin; ++itLayerPatternData)</div><div class="line"><a name="l01377"></a><span class="lineno"> 1377</span>&#160;            {</div><div class="line"><a name="l01378"></a><span class="lineno"> 1378</span>&#160;                --idxLayer;</div><div class="line"><a name="l01379"></a><span class="lineno"> 1379</span>&#160;                <span class="keywordflow">if</span> (idxLayer &lt;= trainFromLayer) <span class="comment">// no training</span></div><div class="line"><a name="l01380"></a><span class="lineno"> 1380</span>&#160;                    <span class="keywordflow">break</span>;</div><div class="line"><a name="l01381"></a><span class="lineno"> 1381</span>&#160;</div><div class="line"><a name="l01382"></a><span class="lineno"> 1382</span>&#160;                std::vector&lt;LayerData&gt;&amp; currLayerDataColl = *(itLayerPatternData);</div><div class="line"><a name="l01383"></a><span class="lineno"> 1383</span>&#160;                std::vector&lt;LayerData&gt;&amp; prevLayerDataColl = *(itLayerPatternData+1);</div><div class="line"><a name="l01384"></a><span class="lineno"> 1384</span>&#160;                </div><div class="line"><a name="l01385"></a><span class="lineno"> 1385</span>&#160;                <span class="keywordtype">size_t</span> idxPattern = 0;</div><div class="line"><a name="l01386"></a><span class="lineno"> 1386</span>&#160;<span class="comment">// FIXME: check that itPrevLayerData doesn&#39;t go beyond itPrevLayerDataEnd!</span></div><div class="line"><a name="l01387"></a><span class="lineno"> 1387</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">typename</span> std::vector&lt;LayerData&gt;::iterator itCurrLayerData = begin (currLayerDataColl), itCurrLayerDataEnd = end (currLayerDataColl),</div><div class="line"><a name="l01388"></a><span class="lineno"> 1388</span>&#160;                     itPrevLayerData = begin (prevLayerDataColl) <span class="comment">/*, itPrevLayerDataEnd = end (prevLayerDataColl)*/</span>;</div><div class="line"><a name="l01389"></a><span class="lineno"> 1389</span>&#160;                     itCurrLayerData != itCurrLayerDataEnd; ++itCurrLayerData, ++itPrevLayerData, ++idxPattern)</div><div class="line"><a name="l01390"></a><span class="lineno"> 1390</span>&#160;                {</div><div class="line"><a name="l01391"></a><span class="lineno"> 1391</span>&#160;                    <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; currLayerData = (*itCurrLayerData);</div><div class="line"><a name="l01392"></a><span class="lineno"> 1392</span>&#160;                    <a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; prevLayerData = *(itPrevLayerData);</div><div class="line"><a name="l01393"></a><span class="lineno"> 1393</span>&#160;</div><div class="line"><a name="l01394"></a><span class="lineno"> 1394</span>&#160;                    <a class="code" href="namespaceTMVA_1_1DNN.html#a3edd2f7dbfbebc56db5d4fcc42e2d2cf">backward</a> (prevLayerData, currLayerData);</div><div class="line"><a name="l01395"></a><span class="lineno"> 1395</span>&#160;</div><div class="line"><a name="l01396"></a><span class="lineno"> 1396</span>&#160;                    <span class="comment">// the factorWeightDecay has to be scaled by 1/n where n is the number of weights (synapses)</span></div><div class="line"><a name="l01397"></a><span class="lineno"> 1397</span>&#160;                    <span class="comment">// because L1 and L2 regularization</span></div><div class="line"><a name="l01398"></a><span class="lineno"> 1398</span>&#160;                    <span class="comment">//</span></div><div class="line"><a name="l01399"></a><span class="lineno"> 1399</span>&#160;                    <span class="comment">//  http://neuralnetworksanddeeplearning.com/chap3.html#overfitting_and_regularization</span></div><div class="line"><a name="l01400"></a><span class="lineno"> 1400</span>&#160;                    <span class="comment">//</span></div><div class="line"><a name="l01401"></a><span class="lineno"> 1401</span>&#160;                    <span class="comment">// L1 : -factorWeightDecay*sgn(w)/numWeights</span></div><div class="line"><a name="l01402"></a><span class="lineno"> 1402</span>&#160;                    <span class="comment">// L2 : -factorWeightDecay/numWeights</span></div><div class="line"><a name="l01403"></a><span class="lineno"> 1403</span>&#160;                    <a class="code" href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">update</a> (prevLayerData, currLayerData, settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#abe90b94087ad72335813101a562dbd3f">factorWeightDecay</a> ()/totalNumWeights, settings.<a class="code" href="classTMVA_1_1DNN_1_1Settings.html#a0fa4b86e4b25221d0881db8c36646697">regularization</a> ());</div><div class="line"><a name="l01404"></a><span class="lineno"> 1404</span>&#160;                }</div><div class="line"><a name="l01405"></a><span class="lineno"> 1405</span>&#160;            }</div><div class="line"><a name="l01406"></a><span class="lineno"> 1406</span>&#160;        }</div><div class="line"><a name="l01407"></a><span class="lineno"> 1407</span>&#160;    }</div><div class="line"><a name="l01408"></a><span class="lineno"> 1408</span>&#160;</div><div class="line"><a name="l01409"></a><span class="lineno"> 1409</span>&#160;</div><div class="line"><a name="l01410"></a><span class="lineno"> 1410</span>&#160;<span class="comment"></span></div><div class="line"><a name="l01411"></a><span class="lineno"> 1411</span>&#160;<span class="comment">/*! \brief forward propagation and backward propagation</span></div><div class="line"><a name="l01412"></a><span class="lineno"> 1412</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l01413"></a><span class="lineno"> 1413</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l01414"></a><span class="lineno"> 1414</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l01415"></a><span class="lineno"> 1415</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> LayerContainer, <span class="keyword">typename</span> PassThrough, <span class="keyword">typename</span> ItWeight, <span class="keyword">typename</span> ItGradient, <span class="keyword">typename</span> OutContainer&gt;</div><div class="line"><a name="l01416"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91"> 1416</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91">Net::forward_backward</a> (LayerContainer&amp; _layers, PassThrough&amp; settingsAndBatch, </div><div class="line"><a name="l01417"></a><span class="lineno"> 1417</span>&#160;                                      ItWeight itWeightBegin, ItWeight itWeightEnd,</div><div class="line"><a name="l01418"></a><span class="lineno"> 1418</span>&#160;                                          ItGradient itGradientBegin, ItGradient itGradientEnd, </div><div class="line"><a name="l01419"></a><span class="lineno"> 1419</span>&#160;                                          <span class="keywordtype">size_t</span> trainFromLayer, </div><div class="line"><a name="l01420"></a><span class="lineno"> 1420</span>&#160;                                      OutContainer&amp; outputContainer, <span class="keywordtype">bool</span> doFetchOutput)<span class="keyword"> const</span></div><div class="line"><a name="l01421"></a><span class="lineno"> 1421</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01422"></a><span class="lineno"> 1422</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1Settings.html">Settings</a>&amp; settings = std::get&lt;0&gt;(settingsAndBatch);</div><div class="line"><a name="l01423"></a><span class="lineno"> 1423</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1Batch.html">Batch</a>&amp; batch = std::get&lt;1&gt;(settingsAndBatch);</div><div class="line"><a name="l01424"></a><span class="lineno"> 1424</span>&#160;            <a class="code" href="namespaceTMVA_1_1DNN.html#ae1bb14a8b9c6de194c25e9c74c1615e5">DropContainer</a>&amp; dropContainer = std::get&lt;2&gt;(settingsAndBatch);</div><div class="line"><a name="l01425"></a><span class="lineno"> 1425</span>&#160;</div><div class="line"><a name="l01426"></a><span class="lineno"> 1426</span>&#160;            <span class="keywordtype">double</span> sumError = 0.0;</div><div class="line"><a name="l01427"></a><span class="lineno"> 1427</span>&#160;            <span class="keywordtype">double</span> sumWeights = 0.0;   <span class="comment">// -------------</span></div><div class="line"><a name="l01428"></a><span class="lineno"> 1428</span>&#160;</div><div class="line"><a name="l01429"></a><span class="lineno"> 1429</span>&#160;</div><div class="line"><a name="l01430"></a><span class="lineno"> 1430</span>&#160;        <span class="comment">// ----------------------------- prepare layer data -------------------------------------</span></div><div class="line"><a name="l01431"></a><span class="lineno"> 1431</span>&#160;        <span class="keywordtype">size_t</span> totalNumWeights (0);</div><div class="line"><a name="l01432"></a><span class="lineno"> 1432</span>&#160;        std::vector&lt;std::vector&lt;LayerData&gt;&gt; layerPatternData = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a77bcd2e07ff2c98832ffa70f4a415828">prepareLayerData</a> (_layers,</div><div class="line"><a name="l01433"></a><span class="lineno"> 1433</span>&#160;                                                                                 batch,</div><div class="line"><a name="l01434"></a><span class="lineno"> 1434</span>&#160;                                                                                 dropContainer,</div><div class="line"><a name="l01435"></a><span class="lineno"> 1435</span>&#160;                                                                                 itWeightBegin,</div><div class="line"><a name="l01436"></a><span class="lineno"> 1436</span>&#160;                                                                                 itWeightEnd, </div><div class="line"><a name="l01437"></a><span class="lineno"> 1437</span>&#160;                                                                                 itGradientBegin,</div><div class="line"><a name="l01438"></a><span class="lineno"> 1438</span>&#160;                                                                                 itGradientEnd,</div><div class="line"><a name="l01439"></a><span class="lineno"> 1439</span>&#160;                                                                                 totalNumWeights);</div><div class="line"><a name="l01440"></a><span class="lineno"> 1440</span>&#160;</div><div class="line"><a name="l01441"></a><span class="lineno"> 1441</span>&#160;            </div><div class="line"><a name="l01442"></a><span class="lineno"> 1442</span>&#160;</div><div class="line"><a name="l01443"></a><span class="lineno"> 1443</span>&#160;        <span class="comment">// ---------------------------------- propagate forward ------------------------------------------------------------------</span></div><div class="line"><a name="l01444"></a><span class="lineno"> 1444</span>&#160;        std::vector&lt;double&gt; valuesMean;</div><div class="line"><a name="l01445"></a><span class="lineno"> 1445</span>&#160;        std::vector&lt;double&gt; valuesStdDev;</div><div class="line"><a name="l01446"></a><span class="lineno"> 1446</span>&#160;        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a1753608a2adb76f250d720a82a78b57e">forwardBatch</a> (_layers, layerPatternData, valuesMean, valuesStdDev, trainFromLayer);</div><div class="line"><a name="l01447"></a><span class="lineno"> 1447</span>&#160;</div><div class="line"><a name="l01448"></a><span class="lineno"> 1448</span>&#160;        </div><div class="line"><a name="l01449"></a><span class="lineno"> 1449</span>&#160;            <span class="comment">// ------------- fetch output ------------------</span></div><div class="line"><a name="l01450"></a><span class="lineno"> 1450</span>&#160;        <span class="keywordflow">if</span> (doFetchOutput)</div><div class="line"><a name="l01451"></a><span class="lineno"> 1451</span>&#160;            {</div><div class="line"><a name="l01452"></a><span class="lineno"> 1452</span>&#160;            <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b">fetchOutput</a> (layerPatternData.back (), outputContainer);</div><div class="line"><a name="l01453"></a><span class="lineno"> 1453</span>&#160;            }</div><div class="line"><a name="l01454"></a><span class="lineno"> 1454</span>&#160;</div><div class="line"><a name="l01455"></a><span class="lineno"> 1455</span>&#160;</div><div class="line"><a name="l01456"></a><span class="lineno"> 1456</span>&#160;            <span class="comment">// ------------- error computation -------------</span></div><div class="line"><a name="l01457"></a><span class="lineno"> 1457</span>&#160;        std::tie (sumError, sumWeights) = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#af0f3c3cad3baaff09a113304a1fac413">computeError</a> (settings, layerPatternData.back (), batch, itWeightBegin, itWeightBegin + totalNumWeights);</div><div class="line"><a name="l01458"></a><span class="lineno"> 1458</span>&#160;</div><div class="line"><a name="l01459"></a><span class="lineno"> 1459</span>&#160;</div><div class="line"><a name="l01460"></a><span class="lineno"> 1460</span>&#160;                <span class="comment">// ------------- backpropagation -------------</span></div><div class="line"><a name="l01461"></a><span class="lineno"> 1461</span>&#160;        <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a6f8505127caaa2ff0832e521b56b633e">backPropagate</a> (layerPatternData, settings, trainFromLayer, totalNumWeights);</div><div class="line"><a name="l01462"></a><span class="lineno"> 1462</span>&#160;</div><div class="line"><a name="l01463"></a><span class="lineno"> 1463</span>&#160;                </div><div class="line"><a name="l01464"></a><span class="lineno"> 1464</span>&#160;        <span class="comment">// --- compile the measures</span></div><div class="line"><a name="l01465"></a><span class="lineno"> 1465</span>&#160;            <span class="keywordtype">double</span> batchSize = std::distance (std::begin (batch), std::end (batch));</div><div class="line"><a name="l01466"></a><span class="lineno"> 1466</span>&#160;            <span class="keywordflow">for</span> (<span class="keyword">auto</span> it = itGradientBegin; it != itGradientEnd; ++it)</div><div class="line"><a name="l01467"></a><span class="lineno"> 1467</span>&#160;                (*it) /= batchSize;</div><div class="line"><a name="l01468"></a><span class="lineno"> 1468</span>&#160;</div><div class="line"><a name="l01469"></a><span class="lineno"> 1469</span>&#160;</div><div class="line"><a name="l01470"></a><span class="lineno"> 1470</span>&#160;            sumError /= sumWeights;</div><div class="line"><a name="l01471"></a><span class="lineno"> 1471</span>&#160;            <span class="keywordflow">return</span> sumError;</div><div class="line"><a name="l01472"></a><span class="lineno"> 1472</span>&#160;        }</div><div class="line"><a name="l01473"></a><span class="lineno"> 1473</span>&#160;</div><div class="line"><a name="l01474"></a><span class="lineno"> 1474</span>&#160;</div><div class="line"><a name="l01475"></a><span class="lineno"> 1475</span>&#160;<span class="comment"></span></div><div class="line"><a name="l01476"></a><span class="lineno"> 1476</span>&#160;<span class="comment">/*! \brief initialization of the weights</span></div><div class="line"><a name="l01477"></a><span class="lineno"> 1477</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l01478"></a><span class="lineno"> 1478</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l01479"></a><span class="lineno"> 1479</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l01480"></a><span class="lineno"> 1480</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> OutIterator&gt;</div><div class="line"><a name="l01481"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a7e639acc1f9997436236bb3de7f2a2b9"> 1481</a></span>&#160;            <span class="keywordtype">void</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a7e639acc1f9997436236bb3de7f2a2b9">Net::initializeWeights</a> (<a class="code" href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1">WeightInitializationStrategy</a> eInitStrategy, OutIterator itWeight)</div><div class="line"><a name="l01482"></a><span class="lineno"> 1482</span>&#160;        {</div><div class="line"><a name="l01483"></a><span class="lineno"> 1483</span>&#160;            <span class="keywordflow">if</span> (eInitStrategy == <a class="code" href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1a8086fb8fd14889fa45664c844ed9780b">WeightInitializationStrategy::XAVIER</a>)</div><div class="line"><a name="l01484"></a><span class="lineno"> 1484</span>&#160;            {</div><div class="line"><a name="l01485"></a><span class="lineno"> 1485</span>&#160;                <span class="comment">// input and output properties</span></div><div class="line"><a name="l01486"></a><span class="lineno"> 1486</span>&#160;                <span class="keywordtype">int</span> numInput = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l01487"></a><span class="lineno"> 1487</span>&#160;</div><div class="line"><a name="l01488"></a><span class="lineno"> 1488</span>&#160;                <span class="comment">// compute variance and mean of input and output</span></div><div class="line"><a name="l01489"></a><span class="lineno"> 1489</span>&#160;                <span class="comment">//...</span></div><div class="line"><a name="l01490"></a><span class="lineno"> 1490</span>&#160;   </div><div class="line"><a name="l01491"></a><span class="lineno"> 1491</span>&#160;</div><div class="line"><a name="l01492"></a><span class="lineno"> 1492</span>&#160;                <span class="comment">// compute the weights</span></div><div class="line"><a name="l01493"></a><span class="lineno"> 1493</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer: <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a95a7200fe9a64f6b9887bc2ff7e064e4">layers</a> ())</div><div class="line"><a name="l01494"></a><span class="lineno"> 1494</span>&#160;                {</div><div class="line"><a name="l01495"></a><span class="lineno"> 1495</span>&#160;                    <span class="keywordtype">double</span> nIn = numInput;</div><div class="line"><a name="l01496"></a><span class="lineno"> 1496</span>&#160;                    <span class="keywordtype">double</span> stdDev = <a class="code" href="TMath_8h.html#acdb55c1010a6c379a49db0201bf55d89">sqrt</a> (2.0/nIn);</div><div class="line"><a name="l01497"></a><span class="lineno"> 1497</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight &lt; iWeightEnd; ++iWeight)</div><div class="line"><a name="l01498"></a><span class="lineno"> 1498</span>&#160;                    {</div><div class="line"><a name="l01499"></a><span class="lineno"> 1499</span>&#160;                        (*itWeight) = <a class="code" href="namespaceTMVA_1_1DNN.html#a950e579aacb6827a2704dc698d90852d">DNN::gaussDouble</a> (0.0, stdDev); <span class="comment">// factor 2.0 for ReLU</span></div><div class="line"><a name="l01500"></a><span class="lineno"> 1500</span>&#160;                        ++itWeight;</div><div class="line"><a name="l01501"></a><span class="lineno"> 1501</span>&#160;                    }</div><div class="line"><a name="l01502"></a><span class="lineno"> 1502</span>&#160;                    numInput = layer.numNodes ();</div><div class="line"><a name="l01503"></a><span class="lineno"> 1503</span>&#160;                }</div><div class="line"><a name="l01504"></a><span class="lineno"> 1504</span>&#160;                <span class="keywordflow">return</span>;</div><div class="line"><a name="l01505"></a><span class="lineno"> 1505</span>&#160;            }</div><div class="line"><a name="l01506"></a><span class="lineno"> 1506</span>&#160;</div><div class="line"><a name="l01507"></a><span class="lineno"> 1507</span>&#160;            <span class="keywordflow">if</span> (eInitStrategy == <a class="code" href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1a196ea3a4149e7ad0f389d75950e0f160">WeightInitializationStrategy::XAVIERUNIFORM</a>)</div><div class="line"><a name="l01508"></a><span class="lineno"> 1508</span>&#160;            {</div><div class="line"><a name="l01509"></a><span class="lineno"> 1509</span>&#160;                <span class="comment">// input and output properties</span></div><div class="line"><a name="l01510"></a><span class="lineno"> 1510</span>&#160;                <span class="keywordtype">int</span> numInput = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l01511"></a><span class="lineno"> 1511</span>&#160;</div><div class="line"><a name="l01512"></a><span class="lineno"> 1512</span>&#160;                <span class="comment">// compute variance and mean of input and output</span></div><div class="line"><a name="l01513"></a><span class="lineno"> 1513</span>&#160;                <span class="comment">//...</span></div><div class="line"><a name="l01514"></a><span class="lineno"> 1514</span>&#160;   </div><div class="line"><a name="l01515"></a><span class="lineno"> 1515</span>&#160;</div><div class="line"><a name="l01516"></a><span class="lineno"> 1516</span>&#160;                <span class="comment">// compute the weights</span></div><div class="line"><a name="l01517"></a><span class="lineno"> 1517</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer: <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a95a7200fe9a64f6b9887bc2ff7e064e4">layers</a> ())</div><div class="line"><a name="l01518"></a><span class="lineno"> 1518</span>&#160;                {</div><div class="line"><a name="l01519"></a><span class="lineno"> 1519</span>&#160;                    <span class="keywordtype">double</span> nIn = numInput;</div><div class="line"><a name="l01520"></a><span class="lineno"> 1520</span>&#160;                    <span class="keywordtype">double</span> minVal = -<a class="code" href="TMath_8h.html#acdb55c1010a6c379a49db0201bf55d89">sqrt</a>(2.0/nIn);</div><div class="line"><a name="l01521"></a><span class="lineno"> 1521</span>&#160;                    <span class="keywordtype">double</span> maxVal = <a class="code" href="TMath_8h.html#acdb55c1010a6c379a49db0201bf55d89">sqrt</a> (2.0/nIn);</div><div class="line"><a name="l01522"></a><span class="lineno"> 1522</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight &lt; iWeightEnd; ++iWeight)</div><div class="line"><a name="l01523"></a><span class="lineno"> 1523</span>&#160;                    {</div><div class="line"><a name="l01524"></a><span class="lineno"> 1524</span>&#160;                    </div><div class="line"><a name="l01525"></a><span class="lineno"> 1525</span>&#160;                        (*itWeight) = <a class="code" href="namespaceTMVA_1_1DNN.html#a0a3ba2e5a24d8d3926f97996f272f17b">DNN::uniformDouble</a> (minVal, maxVal); <span class="comment">// factor 2.0 for ReLU</span></div><div class="line"><a name="l01526"></a><span class="lineno"> 1526</span>&#160;                        ++itWeight;</div><div class="line"><a name="l01527"></a><span class="lineno"> 1527</span>&#160;                    }</div><div class="line"><a name="l01528"></a><span class="lineno"> 1528</span>&#160;                    numInput = layer.numNodes ();</div><div class="line"><a name="l01529"></a><span class="lineno"> 1529</span>&#160;                }</div><div class="line"><a name="l01530"></a><span class="lineno"> 1530</span>&#160;                <span class="keywordflow">return</span>;</div><div class="line"><a name="l01531"></a><span class="lineno"> 1531</span>&#160;            }</div><div class="line"><a name="l01532"></a><span class="lineno"> 1532</span>&#160;        </div><div class="line"><a name="l01533"></a><span class="lineno"> 1533</span>&#160;            <span class="keywordflow">if</span> (eInitStrategy == <a class="code" href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1a033bd94b1168d7e4f0d644c3c95e35bf">WeightInitializationStrategy::TEST</a>)</div><div class="line"><a name="l01534"></a><span class="lineno"> 1534</span>&#160;            {</div><div class="line"><a name="l01535"></a><span class="lineno"> 1535</span>&#160;                <span class="comment">// input and output properties</span></div><div class="line"><a name="l01536"></a><span class="lineno"> 1536</span>&#160;                <span class="keywordtype">int</span> numInput = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l01537"></a><span class="lineno"> 1537</span>&#160;</div><div class="line"><a name="l01538"></a><span class="lineno"> 1538</span>&#160;                <span class="comment">// compute variance and mean of input and output</span></div><div class="line"><a name="l01539"></a><span class="lineno"> 1539</span>&#160;                <span class="comment">//...</span></div><div class="line"><a name="l01540"></a><span class="lineno"> 1540</span>&#160;   </div><div class="line"><a name="l01541"></a><span class="lineno"> 1541</span>&#160;</div><div class="line"><a name="l01542"></a><span class="lineno"> 1542</span>&#160;                <span class="comment">// compute the weights</span></div><div class="line"><a name="l01543"></a><span class="lineno"> 1543</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer: <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a95a7200fe9a64f6b9887bc2ff7e064e4">layers</a> ())</div><div class="line"><a name="l01544"></a><span class="lineno"> 1544</span>&#160;                {</div><div class="line"><a name="l01545"></a><span class="lineno"> 1545</span>&#160;<span class="comment">//                double nIn = numInput;</span></div><div class="line"><a name="l01546"></a><span class="lineno"> 1546</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight &lt; iWeightEnd; ++iWeight)</div><div class="line"><a name="l01547"></a><span class="lineno"> 1547</span>&#160;                    {</div><div class="line"><a name="l01548"></a><span class="lineno"> 1548</span>&#160;                        (*itWeight) = <a class="code" href="namespaceTMVA_1_1DNN.html#a950e579aacb6827a2704dc698d90852d">DNN::gaussDouble</a> (0.0, 0.1);</div><div class="line"><a name="l01549"></a><span class="lineno"> 1549</span>&#160;                        ++itWeight;</div><div class="line"><a name="l01550"></a><span class="lineno"> 1550</span>&#160;                    }</div><div class="line"><a name="l01551"></a><span class="lineno"> 1551</span>&#160;                    numInput = layer.numNodes ();</div><div class="line"><a name="l01552"></a><span class="lineno"> 1552</span>&#160;                }</div><div class="line"><a name="l01553"></a><span class="lineno"> 1553</span>&#160;                <span class="keywordflow">return</span>;</div><div class="line"><a name="l01554"></a><span class="lineno"> 1554</span>&#160;            }</div><div class="line"><a name="l01555"></a><span class="lineno"> 1555</span>&#160;</div><div class="line"><a name="l01556"></a><span class="lineno"> 1556</span>&#160;            <span class="keywordflow">if</span> (eInitStrategy == <a class="code" href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1afcf586bdbf33622592d7fa01b7a559d2">WeightInitializationStrategy::LAYERSIZE</a>)</div><div class="line"><a name="l01557"></a><span class="lineno"> 1557</span>&#160;            {</div><div class="line"><a name="l01558"></a><span class="lineno"> 1558</span>&#160;                <span class="comment">// input and output properties</span></div><div class="line"><a name="l01559"></a><span class="lineno"> 1559</span>&#160;                <span class="keywordtype">int</span> numInput = <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">inputSize</a> ();</div><div class="line"><a name="l01560"></a><span class="lineno"> 1560</span>&#160;</div><div class="line"><a name="l01561"></a><span class="lineno"> 1561</span>&#160;                <span class="comment">// compute variance and mean of input and output</span></div><div class="line"><a name="l01562"></a><span class="lineno"> 1562</span>&#160;                <span class="comment">//...</span></div><div class="line"><a name="l01563"></a><span class="lineno"> 1563</span>&#160;   </div><div class="line"><a name="l01564"></a><span class="lineno"> 1564</span>&#160;</div><div class="line"><a name="l01565"></a><span class="lineno"> 1565</span>&#160;                <span class="comment">// compute the weights</span></div><div class="line"><a name="l01566"></a><span class="lineno"> 1566</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; layer: <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a95a7200fe9a64f6b9887bc2ff7e064e4">layers</a> ())</div><div class="line"><a name="l01567"></a><span class="lineno"> 1567</span>&#160;                {</div><div class="line"><a name="l01568"></a><span class="lineno"> 1568</span>&#160;                    <span class="keywordtype">double</span> nIn = numInput;</div><div class="line"><a name="l01569"></a><span class="lineno"> 1569</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight &lt; iWeightEnd; ++iWeight)</div><div class="line"><a name="l01570"></a><span class="lineno"> 1570</span>&#160;                    {</div><div class="line"><a name="l01571"></a><span class="lineno"> 1571</span>&#160;                        (*itWeight) = <a class="code" href="namespaceTMVA_1_1DNN.html#a950e579aacb6827a2704dc698d90852d">DNN::gaussDouble</a> (0.0, <a class="code" href="TMath_8h.html#acdb55c1010a6c379a49db0201bf55d89">sqrt</a> (layer.numWeights (nIn))); <span class="comment">// factor 2.0 for ReLU</span></div><div class="line"><a name="l01572"></a><span class="lineno"> 1572</span>&#160;                        ++itWeight;</div><div class="line"><a name="l01573"></a><span class="lineno"> 1573</span>&#160;                    }</div><div class="line"><a name="l01574"></a><span class="lineno"> 1574</span>&#160;                    numInput = layer.numNodes ();</div><div class="line"><a name="l01575"></a><span class="lineno"> 1575</span>&#160;                }</div><div class="line"><a name="l01576"></a><span class="lineno"> 1576</span>&#160;                <span class="keywordflow">return</span>;</div><div class="line"><a name="l01577"></a><span class="lineno"> 1577</span>&#160;            }</div><div class="line"><a name="l01578"></a><span class="lineno"> 1578</span>&#160;</div><div class="line"><a name="l01579"></a><span class="lineno"> 1579</span>&#160;        }</div><div class="line"><a name="l01580"></a><span class="lineno"> 1580</span>&#160;</div><div class="line"><a name="l01581"></a><span class="lineno"> 1581</span>&#160;</div><div class="line"><a name="l01582"></a><span class="lineno"> 1582</span>&#160;    </div><div class="line"><a name="l01583"></a><span class="lineno"> 1583</span>&#160;</div><div class="line"><a name="l01584"></a><span class="lineno"> 1584</span>&#160;<span class="comment"></span></div><div class="line"><a name="l01585"></a><span class="lineno"> 1585</span>&#160;<span class="comment">/*! \brief compute the error function</span></div><div class="line"><a name="l01586"></a><span class="lineno"> 1586</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l01587"></a><span class="lineno"> 1587</span>&#160;<span class="comment"> * </span></div><div class="line"><a name="l01588"></a><span class="lineno"> 1588</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l01589"></a><span class="lineno"> 1589</span>&#160;        <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Container, <span class="keyword">typename</span> ItWeight&gt;</div><div class="line"><a name="l01590"></a><span class="lineno"><a class="line" href="classTMVA_1_1DNN_1_1Net.html#a850543a9454e8cd69c78279f5f9619cc"> 1590</a></span>&#160;            <span class="keywordtype">double</span> <a class="code" href="classTMVA_1_1DNN_1_1Net.html#a850543a9454e8cd69c78279f5f9619cc">Net::errorFunction</a> (<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html">LayerData</a>&amp; layerData,</div><div class="line"><a name="l01591"></a><span class="lineno"> 1591</span>&#160;                                       Container truth,</div><div class="line"><a name="l01592"></a><span class="lineno"> 1592</span>&#160;                                       ItWeight itWeight,</div><div class="line"><a name="l01593"></a><span class="lineno"> 1593</span>&#160;                                       ItWeight itWeightEnd,</div><div class="line"><a name="l01594"></a><span class="lineno"> 1594</span>&#160;                                       <span class="keywordtype">double</span> patternWeight,</div><div class="line"><a name="l01595"></a><span class="lineno"> 1595</span>&#160;                                       <span class="keywordtype">double</span> factorWeightDecay,</div><div class="line"><a name="l01596"></a><span class="lineno"> 1596</span>&#160;                                       <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195">EnumRegularization</a> eRegularization)<span class="keyword"> const</span></div><div class="line"><a name="l01597"></a><span class="lineno"> 1597</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l01598"></a><span class="lineno"> 1598</span>&#160;            <span class="keywordtype">double</span> error (0);</div><div class="line"><a name="l01599"></a><span class="lineno"> 1599</span>&#160;            <span class="keywordflow">switch</span> (<a class="code" href="classTMVA_1_1DNN_1_1Net.html#a63369b32c79e532cbc1f9c73126ffcd7">m_eErrorFunction</a>)</div><div class="line"><a name="l01600"></a><span class="lineno"> 1600</span>&#160;            {</div><div class="line"><a name="l01601"></a><span class="lineno"> 1601</span>&#160;            <span class="keywordflow">case</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a603069ca8a68e8f4b10f93ab5d8e19b2a82481d5e97d96d9cc385f34a4eb1555b">ModeErrorFunction::SUMOFSQUARES</a>:</div><div class="line"><a name="l01602"></a><span class="lineno"> 1602</span>&#160;            {</div><div class="line"><a name="l01603"></a><span class="lineno"> 1603</span>&#160;                error = <a class="code" href="namespaceTMVA_1_1DNN.html#a06dbb6605302256fcadab7b7f6a1178b">sumOfSquares</a> (layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#afbb661b4ea410c550dc914f71bce11c2">valuesBegin</a> (), layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a08a1450b225d1df574935b2f5fb66ca5">valuesEnd</a> (), begin (truth), end (truth), </div><div class="line"><a name="l01604"></a><span class="lineno"> 1604</span>&#160;                                      layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a63b07f0b496b4c9162d7a19d19635cbe">deltasBegin</a> (), layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#aba4807516c013acf168eaa8c6757f2c3">deltasEnd</a> (), </div><div class="line"><a name="l01605"></a><span class="lineno"> 1605</span>&#160;                                      layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#af0df1790cf8163734db09fa89182c8e9">inverseActivationFunction</a> (), </div><div class="line"><a name="l01606"></a><span class="lineno"> 1606</span>&#160;                                      patternWeight);</div><div class="line"><a name="l01607"></a><span class="lineno"> 1607</span>&#160;                <span class="keywordflow">break</span>;</div><div class="line"><a name="l01608"></a><span class="lineno"> 1608</span>&#160;            }</div><div class="line"><a name="l01609"></a><span class="lineno"> 1609</span>&#160;            <span class="keywordflow">case</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a603069ca8a68e8f4b10f93ab5d8e19b2a5e82cffcf0e5145d2be9ea45d87a1b1b">ModeErrorFunction::CROSSENTROPY</a>:</div><div class="line"><a name="l01610"></a><span class="lineno"> 1610</span>&#160;            {</div><div class="line"><a name="l01611"></a><span class="lineno"> 1611</span>&#160;                assert (!<a class="code" href="namespaceTMVA_1_1DNN.html#ad616a47ab4724777de7ffd191aef3db0">TMVA::DNN::isFlagSet</a> (<a class="code" href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738a4c5d06b02c97731aaa976179c62dcf76">ModeOutputValues::DIRECT</a>, layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a9b0f919dff3cfe96f4f1d0ad52ac8989">outputMode</a> ()));</div><div class="line"><a name="l01612"></a><span class="lineno"> 1612</span>&#160;                std::vector&lt;double&gt; probabilities = layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#aee6aa1e3d008947a36bbd9479a352f21">probabilities</a> ();</div><div class="line"><a name="l01613"></a><span class="lineno"> 1613</span>&#160;                error = <a class="code" href="namespaceTMVA_1_1DNN.html#a3dafd45dcc339aced1c2ff418d084efa">crossEntropy</a> (begin (probabilities), end (probabilities), </div><div class="line"><a name="l01614"></a><span class="lineno"> 1614</span>&#160;                                      begin (truth), end (truth), </div><div class="line"><a name="l01615"></a><span class="lineno"> 1615</span>&#160;                                      layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a63b07f0b496b4c9162d7a19d19635cbe">deltasBegin</a> (), layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#aba4807516c013acf168eaa8c6757f2c3">deltasEnd</a> (), </div><div class="line"><a name="l01616"></a><span class="lineno"> 1616</span>&#160;                                      layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#af0df1790cf8163734db09fa89182c8e9">inverseActivationFunction</a> (), </div><div class="line"><a name="l01617"></a><span class="lineno"> 1617</span>&#160;                                      patternWeight);</div><div class="line"><a name="l01618"></a><span class="lineno"> 1618</span>&#160;                <span class="keywordflow">break</span>;</div><div class="line"><a name="l01619"></a><span class="lineno"> 1619</span>&#160;            }</div><div class="line"><a name="l01620"></a><span class="lineno"> 1620</span>&#160;            <span class="keywordflow">case</span> <a class="code" href="namespaceTMVA_1_1DNN.html#a603069ca8a68e8f4b10f93ab5d8e19b2aea638c8589ccb3c053553c0f2242521e">ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE</a>:</div><div class="line"><a name="l01621"></a><span class="lineno"> 1621</span>&#160;            {</div><div class="line"><a name="l01622"></a><span class="lineno"> 1622</span>&#160;                std::cout &lt;&lt; <span class="stringliteral">&quot;softmax.&quot;</span> &lt;&lt; std::endl;</div><div class="line"><a name="l01623"></a><span class="lineno"> 1623</span>&#160;                assert (!<a class="code" href="namespaceTMVA_1_1DNN.html#ad616a47ab4724777de7ffd191aef3db0">TMVA::DNN::isFlagSet</a> (<a class="code" href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738a4c5d06b02c97731aaa976179c62dcf76">ModeOutputValues::DIRECT</a>, layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a9b0f919dff3cfe96f4f1d0ad52ac8989">outputMode</a> ()));</div><div class="line"><a name="l01624"></a><span class="lineno"> 1624</span>&#160;                std::vector&lt;double&gt; probabilities = layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#aee6aa1e3d008947a36bbd9479a352f21">probabilities</a> ();</div><div class="line"><a name="l01625"></a><span class="lineno"> 1625</span>&#160;                error = <a class="code" href="namespaceTMVA_1_1DNN.html#a6deb480416293c92508bd8534275a1a4">softMaxCrossEntropy</a> (begin (probabilities), end (probabilities), </div><div class="line"><a name="l01626"></a><span class="lineno"> 1626</span>&#160;                                             begin (truth), end (truth), </div><div class="line"><a name="l01627"></a><span class="lineno"> 1627</span>&#160;                                             layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#a63b07f0b496b4c9162d7a19d19635cbe">deltasBegin</a> (), layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#aba4807516c013acf168eaa8c6757f2c3">deltasEnd</a> (), </div><div class="line"><a name="l01628"></a><span class="lineno"> 1628</span>&#160;                                             layerData.<a class="code" href="classTMVA_1_1DNN_1_1LayerData.html#af0df1790cf8163734db09fa89182c8e9">inverseActivationFunction</a> (), </div><div class="line"><a name="l01629"></a><span class="lineno"> 1629</span>&#160;                                             patternWeight);</div><div class="line"><a name="l01630"></a><span class="lineno"> 1630</span>&#160;                <span class="keywordflow">break</span>;</div><div class="line"><a name="l01631"></a><span class="lineno"> 1631</span>&#160;            }</div><div class="line"><a name="l01632"></a><span class="lineno"> 1632</span>&#160;            }</div><div class="line"><a name="l01633"></a><span class="lineno"> 1633</span>&#160;            <span class="keywordflow">if</span> (factorWeightDecay != 0 &amp;&amp; eRegularization != <a class="code" href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195ab50339a10e1de285ac99d4c3990b8693">EnumRegularization::NONE</a>)</div><div class="line"><a name="l01634"></a><span class="lineno"> 1634</span>&#160;            {</div><div class="line"><a name="l01635"></a><span class="lineno"> 1635</span>&#160;                error = <a class="code" href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">weightDecay</a> (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);</div><div class="line"><a name="l01636"></a><span class="lineno"> 1636</span>&#160;            }</div><div class="line"><a name="l01637"></a><span class="lineno"> 1637</span>&#160;            <span class="keywordflow">return</span> error;</div><div class="line"><a name="l01638"></a><span class="lineno"> 1638</span>&#160;        } </div><div class="line"><a name="l01639"></a><span class="lineno"> 1639</span>&#160;</div><div class="line"><a name="l01640"></a><span class="lineno"> 1640</span>&#160;</div><div class="line"><a name="l01641"></a><span class="lineno"> 1641</span>&#160;</div><div class="line"><a name="l01642"></a><span class="lineno"> 1642</span>&#160;</div><div class="line"><a name="l01643"></a><span class="lineno"> 1643</span>&#160;</div><div class="line"><a name="l01644"></a><span class="lineno"> 1644</span>&#160;</div><div class="line"><a name="l01645"></a><span class="lineno"> 1645</span>&#160;</div><div class="line"><a name="l01646"></a><span class="lineno"> 1646</span>&#160;<span class="comment">// /*! \brief pre-training</span></div><div class="line"><a name="l01647"></a><span class="lineno"> 1647</span>&#160;<span class="comment">//  *</span></div><div class="line"><a name="l01648"></a><span class="lineno"> 1648</span>&#160;<span class="comment">//  * in development</span></div><div class="line"><a name="l01649"></a><span class="lineno"> 1649</span>&#160;<span class="comment">//  */</span></div><div class="line"><a name="l01650"></a><span class="lineno"> 1650</span>&#160;<span class="comment">//         template &lt;typename Minimizer&gt;</span></div><div class="line"><a name="l01651"></a><span class="lineno"> 1651</span>&#160;<span class="comment">//             void Net::preTrain (std::vector&lt;double&gt;&amp; weights,</span></div><div class="line"><a name="l01652"></a><span class="lineno"> 1652</span>&#160;<span class="comment">//                                 std::vector&lt;Pattern&gt;&amp; trainPattern,</span></div><div class="line"><a name="l01653"></a><span class="lineno"> 1653</span>&#160;<span class="comment">//                                 const std::vector&lt;Pattern&gt;&amp; testPattern,</span></div><div class="line"><a name="l01654"></a><span class="lineno"> 1654</span>&#160;<span class="comment">//                                 Minimizer&amp; minimizer, Settings&amp; settings)</span></div><div class="line"><a name="l01655"></a><span class="lineno"> 1655</span>&#160;<span class="comment">//         {</span></div><div class="line"><a name="l01656"></a><span class="lineno"> 1656</span>&#160;<span class="comment">//             auto itWeightGeneral = std::begin (weights);</span></div><div class="line"><a name="l01657"></a><span class="lineno"> 1657</span>&#160;<span class="comment">//             std::vector&lt;Pattern&gt; prePatternTrain (trainPattern.size ());</span></div><div class="line"><a name="l01658"></a><span class="lineno"> 1658</span>&#160;<span class="comment">//             std::vector&lt;Pattern&gt; prePatternTest (testPattern.size ());</span></div><div class="line"><a name="l01659"></a><span class="lineno"> 1659</span>&#160;</div><div class="line"><a name="l01660"></a><span class="lineno"> 1660</span>&#160;<span class="comment">//             size_t _inputSize = inputSize ();</span></div><div class="line"><a name="l01661"></a><span class="lineno"> 1661</span>&#160;</div><div class="line"><a name="l01662"></a><span class="lineno"> 1662</span>&#160;<span class="comment">//             // transform pattern using the created preNet</span></div><div class="line"><a name="l01663"></a><span class="lineno"> 1663</span>&#160;<span class="comment">//             auto initializePrePattern = [&amp;](const std::vector&lt;Pattern&gt;&amp; pttrnInput, std::vector&lt;Pattern&gt;&amp; pttrnOutput)</span></div><div class="line"><a name="l01664"></a><span class="lineno"> 1664</span>&#160;<span class="comment">//                 {</span></div><div class="line"><a name="l01665"></a><span class="lineno"> 1665</span>&#160;<span class="comment">//                     pttrnOutput.clear ();</span></div><div class="line"><a name="l01666"></a><span class="lineno"> 1666</span>&#160;<span class="comment">//                     std::transform (std::begin (pttrnInput), std::end (pttrnInput),</span></div><div class="line"><a name="l01667"></a><span class="lineno"> 1667</span>&#160;<span class="comment">//                                     std::back_inserter (pttrnOutput), </span></div><div class="line"><a name="l01668"></a><span class="lineno"> 1668</span>&#160;<span class="comment">//                                     [](const Pattern&amp; p)</span></div><div class="line"><a name="l01669"></a><span class="lineno"> 1669</span>&#160;<span class="comment">//             {</span></div><div class="line"><a name="l01670"></a><span class="lineno"> 1670</span>&#160;<span class="comment">//                 Pattern pat (p.input (), p.input (), p.weight ());</span></div><div class="line"><a name="l01671"></a><span class="lineno"> 1671</span>&#160;<span class="comment">//                 return pat;</span></div><div class="line"><a name="l01672"></a><span class="lineno"> 1672</span>&#160;<span class="comment">//             });</span></div><div class="line"><a name="l01673"></a><span class="lineno"> 1673</span>&#160;<span class="comment">//                 };</span></div><div class="line"><a name="l01674"></a><span class="lineno"> 1674</span>&#160;</div><div class="line"><a name="l01675"></a><span class="lineno"> 1675</span>&#160;<span class="comment">//             initializePrePattern (trainPattern, prePatternTrain);</span></div><div class="line"><a name="l01676"></a><span class="lineno"> 1676</span>&#160;<span class="comment">//             initializePrePattern (testPattern, prePatternTest);</span></div><div class="line"><a name="l01677"></a><span class="lineno"> 1677</span>&#160;</div><div class="line"><a name="l01678"></a><span class="lineno"> 1678</span>&#160;<span class="comment">//             std::vector&lt;double&gt; originalDropFractions = settings.dropFractions ();</span></div><div class="line"><a name="l01679"></a><span class="lineno"> 1679</span>&#160;</div><div class="line"><a name="l01680"></a><span class="lineno"> 1680</span>&#160;<span class="comment">//             for (auto&amp; _layer : layers ())</span></div><div class="line"><a name="l01681"></a><span class="lineno"> 1681</span>&#160;<span class="comment">//             {</span></div><div class="line"><a name="l01682"></a><span class="lineno"> 1682</span>&#160;<span class="comment">//                 // compute number of weights (as a function of the number of incoming nodes)</span></div><div class="line"><a name="l01683"></a><span class="lineno"> 1683</span>&#160;<span class="comment">//                 // fetch number of nodes</span></div><div class="line"><a name="l01684"></a><span class="lineno"> 1684</span>&#160;<span class="comment">//                 size_t numNodes = _layer.numNodes ();</span></div><div class="line"><a name="l01685"></a><span class="lineno"> 1685</span>&#160;<span class="comment">//                 size_t _numWeights = _layer.numWeights (_inputSize);</span></div><div class="line"><a name="l01686"></a><span class="lineno"> 1686</span>&#160;</div><div class="line"><a name="l01687"></a><span class="lineno"> 1687</span>&#160;<span class="comment">//                 // ------------------</span></div><div class="line"><a name="l01688"></a><span class="lineno"> 1688</span>&#160;<span class="comment">//                 DNN::Net preNet;</span></div><div class="line"><a name="l01689"></a><span class="lineno"> 1689</span>&#160;<span class="comment">//                 if (!originalDropFractions.empty ())</span></div><div class="line"><a name="l01690"></a><span class="lineno"> 1690</span>&#160;<span class="comment">//                 {</span></div><div class="line"><a name="l01691"></a><span class="lineno"> 1691</span>&#160;<span class="comment">//                     originalDropFractions.erase (originalDropFractions.begin ());</span></div><div class="line"><a name="l01692"></a><span class="lineno"> 1692</span>&#160;<span class="comment">//                     settings.setDropOut (originalDropFractions.begin (), originalDropFractions.end (), settings.dropRepetitions ());</span></div><div class="line"><a name="l01693"></a><span class="lineno"> 1693</span>&#160;<span class="comment">//                 }</span></div><div class="line"><a name="l01694"></a><span class="lineno"> 1694</span>&#160;<span class="comment">//                 std::vector&lt;double&gt; preWeights;</span></div><div class="line"><a name="l01695"></a><span class="lineno"> 1695</span>&#160;</div><div class="line"><a name="l01696"></a><span class="lineno"> 1696</span>&#160;<span class="comment">//                 // define the preNet (pretraining-net) for this layer</span></div><div class="line"><a name="l01697"></a><span class="lineno"> 1697</span>&#160;<span class="comment">//                 // outputSize == inputSize, because this is an autoencoder;</span></div><div class="line"><a name="l01698"></a><span class="lineno"> 1698</span>&#160;<span class="comment">//                 preNet.setInputSize (_inputSize);</span></div><div class="line"><a name="l01699"></a><span class="lineno"> 1699</span>&#160;<span class="comment">//                 preNet.addLayer (DNN::Layer (numNodes, _layer.activationFunctionType ()));</span></div><div class="line"><a name="l01700"></a><span class="lineno"> 1700</span>&#160;<span class="comment">//                 preNet.addLayer (DNN::Layer (_inputSize, DNN::EnumFunction::LINEAR, DNN::ModeOutputValues::DIRECT)); </span></div><div class="line"><a name="l01701"></a><span class="lineno"> 1701</span>&#160;<span class="comment">//                 preNet.setErrorFunction (DNN::ModeErrorFunction::SUMOFSQUARES);</span></div><div class="line"><a name="l01702"></a><span class="lineno"> 1702</span>&#160;<span class="comment">//                 preNet.setOutputSize (_inputSize); // outputSize is the inputSize (autoencoder)</span></div><div class="line"><a name="l01703"></a><span class="lineno"> 1703</span>&#160;</div><div class="line"><a name="l01704"></a><span class="lineno"> 1704</span>&#160;<span class="comment">//                 // initialize weights</span></div><div class="line"><a name="l01705"></a><span class="lineno"> 1705</span>&#160;<span class="comment">//                 preNet.initializeWeights (DNN::WeightInitializationStrategy::XAVIERUNIFORM, </span></div><div class="line"><a name="l01706"></a><span class="lineno"> 1706</span>&#160;<span class="comment">//                                           std::back_inserter (preWeights));</span></div><div class="line"><a name="l01707"></a><span class="lineno"> 1707</span>&#160;</div><div class="line"><a name="l01708"></a><span class="lineno"> 1708</span>&#160;<span class="comment">//                 // overwrite already existing weights from the &quot;general&quot; weights</span></div><div class="line"><a name="l01709"></a><span class="lineno"> 1709</span>&#160;<span class="comment">//                 std::copy (itWeightGeneral, itWeightGeneral+_numWeights, preWeights.begin ());</span></div><div class="line"><a name="l01710"></a><span class="lineno"> 1710</span>&#160;<span class="comment">//                 std::copy (itWeightGeneral, itWeightGeneral+_numWeights, preWeights.begin ()+_numWeights); // set identical weights for the temporary output layer</span></div><div class="line"><a name="l01711"></a><span class="lineno"> 1711</span>&#160;            </div><div class="line"><a name="l01712"></a><span class="lineno"> 1712</span>&#160;</div><div class="line"><a name="l01713"></a><span class="lineno"> 1713</span>&#160;<span class="comment">//                 // train the &quot;preNet&quot;</span></div><div class="line"><a name="l01714"></a><span class="lineno"> 1714</span>&#160;<span class="comment">//                 preNet.train (preWeights, prePatternTrain, prePatternTest, minimizer, settings);</span></div><div class="line"><a name="l01715"></a><span class="lineno"> 1715</span>&#160;</div><div class="line"><a name="l01716"></a><span class="lineno"> 1716</span>&#160;<span class="comment">//                 // fetch the pre-trained weights (without the output part of the autoencoder)</span></div><div class="line"><a name="l01717"></a><span class="lineno"> 1717</span>&#160;<span class="comment">//                 std::copy (std::begin (preWeights), std::begin (preWeights) + _numWeights, itWeightGeneral);</span></div><div class="line"><a name="l01718"></a><span class="lineno"> 1718</span>&#160;</div><div class="line"><a name="l01719"></a><span class="lineno"> 1719</span>&#160;<span class="comment">//                 // advance the iterator on the incoming weights</span></div><div class="line"><a name="l01720"></a><span class="lineno"> 1720</span>&#160;<span class="comment">//                 itWeightGeneral += _numWeights;</span></div><div class="line"><a name="l01721"></a><span class="lineno"> 1721</span>&#160;</div><div class="line"><a name="l01722"></a><span class="lineno"> 1722</span>&#160;<span class="comment">//                 // remove the weights of the output layer of the preNet</span></div><div class="line"><a name="l01723"></a><span class="lineno"> 1723</span>&#160;<span class="comment">//                 preWeights.erase (preWeights.begin () + _numWeights, preWeights.end ());</span></div><div class="line"><a name="l01724"></a><span class="lineno"> 1724</span>&#160;</div><div class="line"><a name="l01725"></a><span class="lineno"> 1725</span>&#160;<span class="comment">//                 // remove the outputLayer of the preNet</span></div><div class="line"><a name="l01726"></a><span class="lineno"> 1726</span>&#160;<span class="comment">//                 preNet.removeLayer ();</span></div><div class="line"><a name="l01727"></a><span class="lineno"> 1727</span>&#160;</div><div class="line"><a name="l01728"></a><span class="lineno"> 1728</span>&#160;<span class="comment">//                 // set the output size to the number of nodes in the new output layer (== last hidden layer)</span></div><div class="line"><a name="l01729"></a><span class="lineno"> 1729</span>&#160;<span class="comment">//                 preNet.setOutputSize (numNodes);</span></div><div class="line"><a name="l01730"></a><span class="lineno"> 1730</span>&#160;            </div><div class="line"><a name="l01731"></a><span class="lineno"> 1731</span>&#160;<span class="comment">//                 // transform pattern using the created preNet</span></div><div class="line"><a name="l01732"></a><span class="lineno"> 1732</span>&#160;<span class="comment">//                 auto proceedPattern = [&amp;](std::vector&lt;Pattern&gt;&amp; pttrn)</span></div><div class="line"><a name="l01733"></a><span class="lineno"> 1733</span>&#160;<span class="comment">//                     {</span></div><div class="line"><a name="l01734"></a><span class="lineno"> 1734</span>&#160;<span class="comment">//                         std::vector&lt;Pattern&gt; newPttrn;</span></div><div class="line"><a name="l01735"></a><span class="lineno"> 1735</span>&#160;<span class="comment">//                         std::for_each (std::begin (pttrn), std::end (pttrn),</span></div><div class="line"><a name="l01736"></a><span class="lineno"> 1736</span>&#160;<span class="comment">//                                        [&amp;preNet,&amp;preWeights,&amp;newPttrn](Pattern&amp; p)</span></div><div class="line"><a name="l01737"></a><span class="lineno"> 1737</span>&#160;<span class="comment">//                 {</span></div><div class="line"><a name="l01738"></a><span class="lineno"> 1738</span>&#160;<span class="comment">//                     std::vector&lt;double&gt; output = preNet.compute (p.input (), preWeights);</span></div><div class="line"><a name="l01739"></a><span class="lineno"> 1739</span>&#160;<span class="comment">//                     Pattern pat (output, output, p.weight ());</span></div><div class="line"><a name="l01740"></a><span class="lineno"> 1740</span>&#160;<span class="comment">//                     newPttrn.push_back (pat);</span></div><div class="line"><a name="l01741"></a><span class="lineno"> 1741</span>&#160;<span class="comment">// //                    p = pat;</span></div><div class="line"><a name="l01742"></a><span class="lineno"> 1742</span>&#160;<span class="comment">//                 });</span></div><div class="line"><a name="l01743"></a><span class="lineno"> 1743</span>&#160;<span class="comment">//                         return newPttrn;</span></div><div class="line"><a name="l01744"></a><span class="lineno"> 1744</span>&#160;<span class="comment">//                     };</span></div><div class="line"><a name="l01745"></a><span class="lineno"> 1745</span>&#160;</div><div class="line"><a name="l01746"></a><span class="lineno"> 1746</span>&#160;</div><div class="line"><a name="l01747"></a><span class="lineno"> 1747</span>&#160;<span class="comment">//                 prePatternTrain = proceedPattern (prePatternTrain);</span></div><div class="line"><a name="l01748"></a><span class="lineno"> 1748</span>&#160;<span class="comment">//                 prePatternTest = proceedPattern (prePatternTest);</span></div><div class="line"><a name="l01749"></a><span class="lineno"> 1749</span>&#160;</div><div class="line"><a name="l01750"></a><span class="lineno"> 1750</span>&#160;</div><div class="line"><a name="l01751"></a><span class="lineno"> 1751</span>&#160;<span class="comment">//                 // the new input size is the output size of the already reduced preNet</span></div><div class="line"><a name="l01752"></a><span class="lineno"> 1752</span>&#160;<span class="comment">//                 _inputSize = preNet.layers ().back ().numNodes ();</span></div><div class="line"><a name="l01753"></a><span class="lineno"> 1753</span>&#160;<span class="comment">//             }</span></div><div class="line"><a name="l01754"></a><span class="lineno"> 1754</span>&#160;<span class="comment">//         }</span></div><div class="line"><a name="l01755"></a><span class="lineno"> 1755</span>&#160;</div><div class="line"><a name="l01756"></a><span class="lineno"> 1756</span>&#160;</div><div class="line"><a name="l01757"></a><span class="lineno"> 1757</span>&#160;</div><div class="line"><a name="l01758"></a><span class="lineno"> 1758</span>&#160;</div><div class="line"><a name="l01759"></a><span class="lineno"> 1759</span>&#160;</div><div class="line"><a name="l01760"></a><span class="lineno"> 1760</span>&#160;</div><div class="line"><a name="l01761"></a><span class="lineno"> 1761</span>&#160;</div><div class="line"><a name="l01762"></a><span class="lineno"> 1762</span>&#160;</div><div class="line"><a name="l01763"></a><span class="lineno"> 1763</span>&#160;</div><div class="line"><a name="l01764"></a><span class="lineno"> 1764</span>&#160;</div><div class="line"><a name="l01765"></a><span class="lineno"> 1765</span>&#160;</div><div class="line"><a name="l01766"></a><span class="lineno"> 1766</span>&#160;</div><div class="line"><a name="l01767"></a><span class="lineno"> 1767</span>&#160;</div><div class="line"><a name="l01768"></a><span class="lineno"> 1768</span>&#160;</div><div class="line"><a name="l01769"></a><span class="lineno"> 1769</span>&#160;</div><div class="line"><a name="l01770"></a><span class="lineno"> 1770</span>&#160;</div><div class="line"><a name="l01771"></a><span class="lineno"> 1771</span>&#160;    } <span class="comment">// namespace DNN</span></div><div class="line"><a name="l01772"></a><span class="lineno"> 1772</span>&#160;} <span class="comment">// namespace TMVA</span></div><div class="line"><a name="l01773"></a><span class="lineno"> 1773</span>&#160;</div><div class="line"><a name="l01774"></a><span class="lineno"> 1774</span>&#160;<span class="preprocessor">#endif</span></div><div class="ttc" id="namespaceTMVA_1_1DNN_html_a4ec6c7bcfa2a903aa0eca9f9ba1c1c73"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a4ec6c7bcfa2a903aa0eca9f9ba1c1c73">TMVA::DNN::InvSoftSign</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvSoftSign</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00020">NeuralNet.cxx:20</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a950189f3903cf99be0ebd2bfe7a20e8e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a950189f3903cf99be0ebd2bfe7a20e8e">TMVA::DNN::Settings::addPoint</a></div><div class="ttdeci">void addPoint(std::string histoName, double x)</div><div class="ttdoc">for monitoring </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00828">NeuralNet.h:828</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_af238176d602b24f8ad98e2a27ecb600a"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#af238176d602b24f8ad98e2a27ecb600a">TMVA::DNN::InvSymmReLU</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvSymmReLU</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00021">NeuralNet.cxx:21</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a603069ca8a68e8f4b10f93ab5d8e19b2aea638c8589ccb3c053553c0f2242521e"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a603069ca8a68e8f4b10f93ab5d8e19b2aea638c8589ccb3c053553c0f2242521e">TMVA::DNN::ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a5d72c8746b3f8ee6284a09e5a4079ac7"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a5d72c8746b3f8ee6284a09e5a4079ac7">TMVA::DNN::InvGaussComplement</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvGaussComplement</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00015">NeuralNet.cxx:15</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_af0df1790cf8163734db09fa89182c8e9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#af0df1790cf8163734db09fa89182c8e9">TMVA::DNN::LayerData::inverseActivationFunction</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; inverseActivationFunction() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00612">NeuralNet.h:612</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_af0f3c3cad3baaff09a113304a1fac413"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#af0f3c3cad3baaff09a113304a1fac413">TMVA::DNN::Net::computeError</a></div><div class="ttdeci">std::tuple&lt; double, double &gt; computeError(const Settings &amp;settings, std::vector&lt; LayerData &gt; &amp;lastLayerData, Batch &amp;batch, ItWeight itWeightBegin, ItWeight itWeightEnd) const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01328">NeuralNet.icc:1328</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a2fe58f5bcff33ea6e0dc1a5ae8b1161aa1b5dc1b50bc6e304f044da1fdffe2578"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a2fe58f5bcff33ea6e0dc1a5ae8b1161aa1b5dc1b50bc6e304f044da1fdffe2578">TMVA::DNN::ModeOutput::FETCH</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a63369b32c79e532cbc1f9c73126ffcd7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a63369b32c79e532cbc1f9c73126ffcd7">TMVA::DNN::Net::m_eErrorFunction</a></div><div class="ttdeci">ModeErrorFunction m_eErrorFunction</div><div class="ttdoc">denotes the error function </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01276">NeuralNet.h:1276</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a798fe06bfbd4bc51183ea8b3e88bc7e1a033bd94b1168d7e4f0d644c3c95e35bf"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1a033bd94b1168d7e4f0d644c3c95e35bf">TMVA::DNN::WeightInitializationStrategy::TEST</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a12691199ebc2ef74717ad1da5fba87a4"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a12691199ebc2ef74717ad1da5fba87a4">TMVA::DNN::Settings::convergenceCount</a></div><div class="ttdeci">size_t convergenceCount() const</div><div class="ttdoc">returns the current convergence count </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00834">NeuralNet.h:834</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a0d19ad105e33c9a289a082cc199ee83f"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a0d19ad105e33c9a289a082cc199ee83f">TMVA::DNN::SymmReLU</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; SymmReLU</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00030">NeuralNet.cxx:30</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a55649ab61afefff55c73f01130068732"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a55649ab61afefff55c73f01130068732">TMVA::DNN::Settings::cycle</a></div><div class="ttdeci">virtual void cycle(double progress, TString text)</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00806">NeuralNet.h:806</a></div></div>
<div class="ttc" id="classTMVA_1_1IPythonInteractive_html_ae13888c9ca4d3bd97c36f38422c3364f"><div class="ttname"><a href="classTMVA_1_1IPythonInteractive.html#ae13888c9ca4d3bd97c36f38422c3364f">TMVA::IPythonInteractive::AddPoint</a></div><div class="ttdeci">void AddPoint(Double_t x, Double_t y1, Double_t y2)</div><div class="ttdoc">This function is used only in 2 TGraph case, and it will add new data points to graphs. </div><div class="ttdef"><b>Definition:</b> <a href="MethodBase_8cxx_source.html#l00212">MethodBase.cxx:212</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3aec1440295bd8b8731d79a44488acc4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3aec1440295bd8b8731d79a44488acc4">TMVA::DNN::SoftPlus</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; SoftPlus</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00027">NeuralNet.cxx:27</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a33a6d3e3d2179f667c7d3e7aed649ea2"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a33a6d3e3d2179f667c7d3e7aed649ea2">TMVA::DNN::Net::fIPyMaxIter</a></div><div class="ttdeci">UInt_t * fIPyMaxIter</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01285">NeuralNet.h:1285</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_ae1bb14a8b9c6de194c25e9c74c1615e5"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#ae1bb14a8b9c6de194c25e9c74c1615e5">TMVA::DNN::DropContainer</a></div><div class="ttdeci">std::vector&lt; char &gt; DropContainer</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00220">NeuralNet.h:220</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_a63b07f0b496b4c9162d7a19d19635cbe"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#a63b07f0b496b4c9162d7a19d19635cbe">TMVA::DNN::LayerData::deltasBegin</a></div><div class="ttdeci">iterator_type deltasBegin()</div><div class="ttdoc">returns iterator to the begin of the deltas (back-propagation) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00595">NeuralNet.h:595</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a5525640c6eea8d4e92aa42a8636daa9eab299f45b5de2a8f7c45192590290742b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a5525640c6eea8d4e92aa42a8636daa9eab299f45b5de2a8f7c45192590290742b">TMVA::DNN::EnumFunction::SIGMOID</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_ad616a47ab4724777de7ffd191aef3db0"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#ad616a47ab4724777de7ffd191aef3db0">TMVA::DNN::isFlagSet</a></div><div class="ttdeci">bool isFlagSet(T flag, T value)</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00213">NeuralNet.h:213</a></div></div>
<div class="ttc" id="namespaceROOT_1_1Math_1_1Chebyshev_html_ae8cd7615ee993748f2b39d07561f83ba"><div class="ttname"><a href="namespaceROOT_1_1Math_1_1Chebyshev.html#ae8cd7615ee993748f2b39d07561f83ba">ROOT::Math::Chebyshev::T</a></div><div class="ttdeci">double T(double x)</div><div class="ttdef"><b>Definition:</b> <a href="ChebyshevPol_8h_source.html#l00034">ChebyshevPol.h:34</a></div></div>
<div class="ttc" id="RSha256_8hxx_html_a9608045402267746965fa49d90bbada4"><div class="ttname"><a href="RSha256_8hxx.html#a9608045402267746965fa49d90bbada4">g</a></div><div class="ttdeci">#define g(i)</div><div class="ttdef"><b>Definition:</b> <a href="RSha256_8hxx_source.html#l00105">RSha256.hxx:105</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3b0759fc76ba1cd946231f05c309f195a7e6aa2d53f6ee2b1a34b017fa403cb76"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195a7e6aa2d53f6ee2b1a34b017fa403cb76">TMVA::DNN::EnumRegularization::L2</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a1753608a2adb76f250d720a82a78b57e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a1753608a2adb76f250d720a82a78b57e">TMVA::DNN::Net::forwardBatch</a></div><div class="ttdeci">void forwardBatch(const LayerContainer &amp;_layers, LayerPatternContainer &amp;layerPatternData, std::vector&lt; double &gt; &amp;valuesMean, std::vector&lt; double &gt; &amp;valuesStdDev, size_t trainFromLayer) const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01243">NeuralNet.icc:1243</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a820ce0367e972d467d4a854268e608b0"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a820ce0367e972d467d4a854268e608b0">TMVA::DNN::InvReLU</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvReLU</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00017">NeuralNet.cxx:17</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_ab95a90e7ede6423bf972b16de68cc174"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#ab95a90e7ede6423bf972b16de68cc174">TMVA::DNN::Settings::convergenceSteps</a></div><div class="ttdeci">size_t convergenceSteps() const</div><div class="ttdoc">how many steps until training is deemed to have converged </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00773">NeuralNet.h:773</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3b0759fc76ba1cd946231f05c309f195ab50339a10e1de285ac99d4c3990b8693"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195ab50339a10e1de285ac99d4c3990b8693">TMVA::DNN::EnumRegularization::NONE</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_afb9c3ed1294f3bcf3c17f1b9091e9889"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#afb9c3ed1294f3bcf3c17f1b9091e9889">TMVA::DNN::Net::forwardPattern</a></div><div class="ttdeci">void forwardPattern(const LayerContainer &amp;_layers, std::vector&lt; LayerData &gt; &amp;layerData) const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01223">NeuralNet.icc:1223</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a0e977b2ce282ee0ff9d7db323493d0f1"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a0e977b2ce282ee0ff9d7db323493d0f1">TMVA::DNN::TanhShift</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; TanhShift</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00031">NeuralNet.cxx:31</a></div></div>
<div class="ttc" id="classPattern_html_a38ce7794374830dcfaf90b78764be4cd"><div class="ttname"><a href="classPattern.html#a38ce7794374830dcfaf90b78764be4cd">Pattern::output</a></div><div class="ttdeci">std::vector&lt; double &gt; &amp; output()</div><div class="ttdef"><b>Definition:</b> <a href="Pattern_8h_source.html#l00084">Pattern.h:84</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a2f5fbbd7cdb0ab7d280d915b0517cf6e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a2f5fbbd7cdb0ab7d280d915b0517cf6e">TMVA::DNN::Settings::dropFractions</a></div><div class="ttdeci">const std::vector&lt; double &gt; &amp; dropFractions() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00769">NeuralNet.h:769</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a1e2e55b912c7f2266d2ef39a08cfea43"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a1e2e55b912c7f2266d2ef39a08cfea43">TMVA::DNN::applyFunctions</a></div><div class="ttdeci">void applyFunctions(ItValue itValue, ItValue itValueEnd, ItFunction itFunction)</div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3edd2f7dbfbebc56db5d4fcc42e2d2cf"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3edd2f7dbfbebc56db5d4fcc42e2d2cf">TMVA::DNN::backward</a></div><div class="ttdeci">void backward(LAYERDATA &amp;prevLayerData, LAYERDATA &amp;currLayerData)</div><div class="ttdoc">backward application of the weights (back-propagation of the error) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00570">NeuralNet.icc:570</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a51e2530bd97ea0344cbcb281e48569e9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a51e2530bd97ea0344cbcb281e48569e9">TMVA::DNN::Net::inputSize</a></div><div class="ttdeci">size_t inputSize() const</div><div class="ttdoc">input size of the DNN </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01105">NeuralNet.h:1105</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a0fa4b86e4b25221d0881db8c36646697"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a0fa4b86e4b25221d0881db8c36646697">TMVA::DNN::Settings::regularization</a></div><div class="ttdeci">EnumRegularization regularization() const</div><div class="ttdoc">some regularization of the DNN is turned on? </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00820">NeuralNet.h:820</a></div></div>
<div class="ttc" id="classTString_html"><div class="ttname"><a href="classTString.html">TString</a></div><div class="ttdoc">Basic string class. </div><div class="ttdef"><b>Definition:</b> <a href="TString_8h_source.html#l00131">TString.h:131</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a0d854a5073f42f43427379989fdf911e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a0d854a5073f42f43427379989fdf911e">TMVA::DNN::Settings::useMultithreading</a></div><div class="ttdeci">bool useMultithreading() const</div><div class="ttdoc">is multithreading turned on? </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00822">NeuralNet.h:822</a></div></div>
<div class="ttc" id="RSha256_8hxx_html_a357394e0f6f88c8a57bd893ab28dc8f8"><div class="ttname"><a href="RSha256_8hxx.html#a357394e0f6f88c8a57bd893ab28dc8f8">f</a></div><div class="ttdeci">#define f(i)</div><div class="ttdef"><b>Definition:</b> <a href="RSha256_8hxx_source.html#l00104">RSha256.hxx:104</a></div></div>
<div class="ttc" id="classPattern_html"><div class="ttname"><a href="classPattern.html">Pattern</a></div><div class="ttdef"><b>Definition:</b> <a href="Pattern_8h_source.html#l00007">Pattern.h:7</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_ac9e20e4ffd6fe02e32f118a9f99bde2d"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#ac9e20e4ffd6fe02e32f118a9f99bde2d">TMVA::DNN::Net::trainCycle</a></div><div class="ttdeci">double trainCycle(Minimizer &amp;minimizer, std::vector&lt; double &gt; &amp;weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &amp;settings, DropContainer &amp;dropContainer)</div><div class="ttdoc">executes one training cycle </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00939">NeuralNet.icc:939</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_aa6cbab9ba575a8055a11277bbad81aa7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#aa6cbab9ba575a8055a11277bbad81aa7">TMVA::DNN::Settings::plot</a></div><div class="ttdeci">void plot(std::string histoName, std::string options, int pad, EColor color)</div><div class="ttdoc">for monitoring </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00830">NeuralNet.h:830</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a798fe06bfbd4bc51183ea8b3e88bc7e1a196ea3a4149e7ad0f389d75950e0f160"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1a196ea3a4149e7ad0f389d75950e0f160">TMVA::DNN::WeightInitializationStrategy::XAVIERUNIFORM</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_ae04127a1e752e409036f8edea1f2b868"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#ae04127a1e752e409036f8edea1f2b868">TMVA::DNN::update</a></div><div class="ttdeci">void update(ItSource itSource, ItSource itSourceEnd, ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, ItTargetGradient itTargetGradientBegin, ItGradient itGradient)</div><div class="ttdoc">update the gradients </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00181">NeuralNet.icc:181</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a3baf93535d76f3346f06ab74e6c3df8b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a3baf93535d76f3346f06ab74e6c3df8b">TMVA::DNN::Settings::testIteration</a></div><div class="ttdeci">virtual void testIteration()</div><div class="ttdoc">callback for monitoring and loggging </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00813">NeuralNet.h:813</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_ac548aac0604377dcd2c357723697d21d"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#ac548aac0604377dcd2c357723697d21d">TMVA::DNN::ReLU</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; ReLU</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00025">NeuralNet.cxx:25</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_acc94d2d0eb781e8b20508ed3ac5331e4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#acc94d2d0eb781e8b20508ed3ac5331e4">TMVA::DNN::applyWeights</a></div><div class="ttdeci">void applyWeights(ItSource itSourceBegin, ItSource itSourceEnd, ItWeight itWeight, ItTarget itTargetBegin, ItTarget itTargetEnd)</div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_aaabb0a3d4c7440097e4911a9b0bdc90a"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#aaabb0a3d4c7440097e4911a9b0bdc90a">TMVA::DNN::SoftSign</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; SoftSign</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00032">NeuralNet.cxx:32</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a733fa12c77cf4deaff866bcfbb4c8886"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a733fa12c77cf4deaff866bcfbb4c8886">TMVA::DNN::Linear</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; Linear</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00024">NeuralNet.cxx:24</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_affa1a067ee41e6346b0d76f194244d9c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#affa1a067ee41e6346b0d76f194244d9c">TMVA::DNN::Settings::startTestCycle</a></div><div class="ttdeci">virtual void startTestCycle()</div><div class="ttdoc">callback for monitoring and loggging </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00811">NeuralNet.h:811</a></div></div>
<div class="ttc" id="TMath_8h_html_acdb55c1010a6c379a49db0201bf55d89"><div class="ttname"><a href="TMath_8h.html#acdb55c1010a6c379a49db0201bf55d89">sqrt</a></div><div class="ttdeci">double sqrt(double)</div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a603069ca8a68e8f4b10f93ab5d8e19b2a5e82cffcf0e5145d2be9ea45d87a1b1b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a603069ca8a68e8f4b10f93ab5d8e19b2a5e82cffcf0e5145d2be9ea45d87a1b1b">TMVA::DNN::ModeErrorFunction::CROSSENTROPY</a></div></div>
<div class="ttc" id="legend1_8C_html_a13c6713ae496caa8195647f76887f926"><div class="ttname"><a href="legend1_8C.html#a13c6713ae496caa8195647f76887f926">x</a></div><div class="ttdeci">Double_t x[n]</div><div class="ttdef"><b>Definition:</b> <a href="legend1_8C_source.html#l00017">legend1.C:17</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a492993d5217855869e20508313007305"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a492993d5217855869e20508313007305">TMVA::DNN::weightDecay</a></div><div class="ttdeci">double weightDecay(double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization)</div><div class="ttdoc">compute the weight decay for regularization (L1 or L2) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00496">NeuralNet.icc:496</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a2bbf684ab8d985a9ccfe32f84948fc6a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a2bbf684ab8d985a9ccfe32f84948fc6a">TMVA::DNN::Net::m_layers</a></div><div class="ttdeci">std::vector&lt; Layer &gt; m_layers</div><div class="ttdoc">layer-structure-data </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01279">NeuralNet.h:1279</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_a9b0f919dff3cfe96f4f1d0ad52ac8989"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#a9b0f919dff3cfe96f4f1d0ad52ac8989">TMVA::DNN::LayerData::outputMode</a></div><div class="ttdeci">ModeOutputValues outputMode() const</div><div class="ttdoc">returns the output mode </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00592">NeuralNet.h:592</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_a04d1a3ffa1783bed8019baafde0a7356"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#a04d1a3ffa1783bed8019baafde0a7356">TMVA::DNN::LayerData::activationFunction</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; activationFunction() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00611">NeuralNet.h:611</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Batch_html_a20d72553469a204881e81f7f7f77a98e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Batch.html#a20d72553469a204881e81f7f7f77a98e">TMVA::DNN::Batch::end</a></div><div class="ttdeci">const_iterator end() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00246">NeuralNet.h:246</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a720af9a9f89efda79f18e0ffe9a4b332"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a720af9a9f89efda79f18e0ffe9a4b332">TMVA::DNN::InvTanh</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvTanh</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00022">NeuralNet.cxx:22</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a5c512a56a1ebbfb2cee55d67404170f7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a5c512a56a1ebbfb2cee55d67404170f7">TMVA::DNN::Steepest::m_prevGradients</a></div><div class="ttdeci">std::vector&lt; double &gt; m_prevGradients</div><div class="ttdoc">vector remembers the gradients of the previous step </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00374">NeuralNet.h:374</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_adf951f491ff26d922eb9559581478d00"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#adf951f491ff26d922eb9559581478d00">TMVA::DNN::Settings::create</a></div><div class="ttdeci">void create(std::string histoName, int bins, double min, double max)</div><div class="ttdoc">for monitoring </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00826">NeuralNet.h:826</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a287a9e9a038386fa89fc29218489fbc6"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a287a9e9a038386fa89fc29218489fbc6">TMVA::DNN::uniformFromTo</a></div><div class="ttdeci">T uniformFromTo(T from, T to)</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00032">NeuralNet.icc:32</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_add342ccb8a72b10787090429a1353b5e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#add342ccb8a72b10787090429a1353b5e">TMVA::DNN::Net::dropOutWeightFactor</a></div><div class="ttdeci">void dropOutWeightFactor(WeightsType &amp;weights, const DropProbabilities &amp;drops, bool inverse=false)</div><div class="ttdoc">set the drop out configuration </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00650">NeuralNet.icc:650</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a1e13178948b917abdf6bb9f88aff8596"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a1e13178948b917abdf6bb9f88aff8596">TMVA::DNN::Settings::testRepetitions</a></div><div class="ttdeci">size_t testRepetitions() const</div><div class="ttdoc">how often is the test data tested </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00775">NeuralNet.h:775</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a4d9d6d18f63d8902b38c0118e523093b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a4d9d6d18f63d8902b38c0118e523093b">TMVA::DNN::Net::fetchOutput</a></div><div class="ttdeci">void fetchOutput(const LayerData &amp;lastLayerData, OutputContainer &amp;outputContainer) const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01298">NeuralNet.icc:1298</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a7e639acc1f9997436236bb3de7f2a2b9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a7e639acc1f9997436236bb3de7f2a2b9">TMVA::DNN::Net::initializeWeights</a></div><div class="ttdeci">void initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)</div><div class="ttdoc">initialize the weights with the given strategy </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01481">NeuralNet.icc:1481</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3b0759fc76ba1cd946231f05c309f195a9ec4c0afd450ceac7adb81c3bcfc9732"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195a9ec4c0afd450ceac7adb81c3bcfc9732">TMVA::DNN::EnumRegularization::L1</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_ac9eedb5ac24c3a0914533e93a0be361a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#ac9eedb5ac24c3a0914533e93a0be361a">TMVA::DNN::Net::fIPyCurrentIter</a></div><div class="ttdeci">UInt_t * fIPyCurrentIter</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01285">NeuralNet.h:1285</a></div></div>
<div class="ttc" id="namespaceROOT_1_1Math_html_a09dbf6c9318d826cd59ed8abb44dc4d0"><div class="ttname"><a href="namespaceROOT_1_1Math.html#a09dbf6c9318d826cd59ed8abb44dc4d0">ROOT::Math::fabs</a></div><div class="ttdeci">VecExpr&lt; UnaryOp&lt; Fabs&lt; T &gt;, VecExpr&lt; A, T, D &gt;, T &gt;, T, D &gt; fabs(const VecExpr&lt; A, T, D &gt; &amp;rhs)</div><div class="ttdef"><b>Definition:</b> <a href="UnaryOperators_8h_source.html#l00131">UnaryOperators.h:131</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_add7c38bf156c102943f56316f3925275"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#add7c38bf156c102943f56316f3925275">TMVA::DNN::Settings::dropRepetitions</a></div><div class="ttdeci">size_t dropRepetitions() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00768">NeuralNet.h:768</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_aee6aa1e3d008947a36bbd9479a352f21"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#aee6aa1e3d008947a36bbd9479a352f21">TMVA::DNN::LayerData::probabilities</a></div><div class="ttdeci">container_type probabilities() const</div><div class="ttdoc">computes the probabilities from the current node values and returns them </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00593">NeuralNet.h:593</a></div></div>
<div class="ttc" id="bindings_2r_2tests_2Functor_8C_html_a0c577f19f0476bcfd51080f86326db0f"><div class="ttname"><a href="bindings_2r_2tests_2Functor_8C.html#a0c577f19f0476bcfd51080f86326db0f">Function</a></div><div class="ttdeci">Double_t(* Function)(Double_t)</div><div class="ttdef"><b>Definition:</b> <a href="bindings_2r_2tests_2Functor_8C_source.html#l00004">Functor.C:4</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a95a7200fe9a64f6b9887bc2ff7e064e4"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a95a7200fe9a64f6b9887bc2ff7e064e4">TMVA::DNN::Net::layers</a></div><div class="ttdeci">const std::vector&lt; Layer &gt; &amp; layers() const</div><div class="ttdoc">returns the layers (structure) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01252">NeuralNet.h:1252</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_abe90b94087ad72335813101a562dbd3f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#abe90b94087ad72335813101a562dbd3f">TMVA::DNN::Settings::factorWeightDecay</a></div><div class="ttdeci">double factorWeightDecay() const</div><div class="ttdoc">get the weight-decay factor </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00776">NeuralNet.h:776</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a758301fff15727d14018c7442a9aedbc"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a758301fff15727d14018c7442a9aedbc">TMVA::DNN::Settings::endTrainCycle</a></div><div class="ttdeci">virtual void endTrainCycle(double)</div><div class="ttdoc">callback for monitoring and logging </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00795">NeuralNet.h:795</a></div></div>
<div class="ttc" id="namespaceRooFit_html_afac78d31d10b7e7396b999e4ea3af76c"><div class="ttname"><a href="namespaceRooFit.html#afac78d31d10b7e7396b999e4ea3af76c">RooFit::Minimizer</a></div><div class="ttdeci">RooCmdArg Minimizer(const char *type, const char *alg=0)</div><div class="ttdef"><b>Definition:</b> <a href="RooGlobalFunc_8cxx_source.html#l00207">RooGlobalFunc.cxx:207</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_ad60351d50e38b22256356e73be138133"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#ad60351d50e38b22256356e73be138133">TMVA::DNN::Net::operator()</a></div><div class="ttdeci">double operator()(PassThrough &amp;settingsAndBatch, const Weights &amp;weights) const</div><div class="ttdoc">execute computation of the DNN for one mini-batch (used by the minimizer); no computation of gradient...</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01070">NeuralNet.icc:1070</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a45506efcf9b231dde8e08a3c152434ce"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a45506efcf9b231dde8e08a3c152434ce">TMVA::DNN::ZeroFnc</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; ZeroFnc</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00028">NeuralNet.cxx:28</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a6deb480416293c92508bd8534275a1a4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a6deb480416293c92508bd8534275a1a4">TMVA::DNN::softMaxCrossEntropy</a></div><div class="ttdeci">double softMaxCrossEntropy(ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)</div><div class="ttdoc">soft-max-cross-entropy error function (for mutual exclusive cross-entropy) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00456">NeuralNet.icc:456</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_afadce78ec74a80216b114641306de48e"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#afadce78ec74a80216b114641306de48e">TMVA::DNN::InvLinear</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvLinear</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00016">NeuralNet.cxx:16</a></div></div>
<div class="ttc" id="TString_8h_html_acf18c5b91421ac53e91bd96ebc07dea7"><div class="ttname"><a href="TString_8h.html#acf18c5b91421ac53e91bd96ebc07dea7">Form</a></div><div class="ttdeci">char * Form(const char *fmt,...)</div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_adf27219d98b2f02ca36741f82ffd1c9d"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#adf27219d98b2f02ca36741f82ffd1c9d">TMVA::DNN::Net::fillDropContainer</a></div><div class="ttdeci">void fillDropContainer(DropContainer &amp;dropContainer, double dropFraction, size_t numNodes) const</div><div class="ttdoc">prepare the drop-out-container (select the nodes which are to be dropped out) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00575">NeuralNet.cxx:575</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a5df4065ab69e1d6a0018509927c38d55"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a5df4065ab69e1d6a0018509927c38d55">TMVA::DNN::regularization</a></div><div class="ttdeci">auto regularization(const typename Architecture_t::Matrix_t &amp;A, ERegularization R) -&gt; decltype(Architecture_t::L1Regularization(A))</div><div class="ttdoc">Evaluate the regularization functional for a given weight matrix. </div><div class="ttdef"><b>Definition:</b> <a href="tmva_2tmva_2inc_2TMVA_2DNN_2Functions_8h_source.html#l00216">Functions.h:216</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_ac9141fa0b81942df6b52c57650b8013f"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#ac9141fa0b81942df6b52c57650b8013f">TMVA::DNN::computeRegularization</a></div><div class="ttdeci">double computeRegularization(double weight, const double &amp;factorWeightDecay)</div><div class="ttdoc">compute the regularization (L1, L2) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00207">NeuralNet.icc:207</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a2fe58f5bcff33ea6e0dc1a5ae8b1161a"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a2fe58f5bcff33ea6e0dc1a5ae8b1161a">TMVA::DNN::ModeOutput</a></div><div class="ttdeci">ModeOutput</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01036">NeuralNet.h:1036</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a603069ca8a68e8f4b10f93ab5d8e19b2a82481d5e97d96d9cc385f34a4eb1555b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a603069ca8a68e8f4b10f93ab5d8e19b2a82481d5e97d96d9cc385f34a4eb1555b">TMVA::DNN::ModeErrorFunction::SUMOFSQUARES</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a850543a9454e8cd69c78279f5f9619cc"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a850543a9454e8cd69c78279f5f9619cc">TMVA::DNN::Net::errorFunction</a></div><div class="ttdeci">double errorFunction(LayerData &amp;layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) const</div><div class="ttdoc">computes the error of the DNN </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01590">NeuralNet.icc:1590</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_acac1fd6a3ebeec2aba7303e6a4d35319"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#acac1fd6a3ebeec2aba7303e6a4d35319">TMVA::DNN::Settings::pads</a></div><div class="ttdeci">void pads(int numPads)</div><div class="ttdoc">preparation for monitoring </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00825">NeuralNet.h:825</a></div></div>
<div class="ttc" id="classPattern_html_ab3e1728f0a8c0934a4e4c8d12c27a0fe"><div class="ttname"><a href="classPattern.html#ab3e1728f0a8c0934a4e4c8d12c27a0fe">Pattern::const_iterator</a></div><div class="ttdeci">std::vector&lt; double &gt;::const_iterator const_iterator</div><div class="ttdef"><b>Definition:</b> <a href="Pattern_8h_source.html#l00012">Pattern.h:12</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html">TMVA::DNN::Settings</a></div><div class="ttdoc">Settings for the training of the neural net. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00736">NeuralNet.h:736</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_aa7f231286a2f1df255a42a88afac2784"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#aa7f231286a2f1df255a42a88afac2784">TMVA::DNN::Settings::startTrainCycle</a></div><div class="ttdeci">virtual void startTrainCycle()</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00789">NeuralNet.h:789</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a798fe06bfbd4bc51183ea8b3e88bc7e1"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1">TMVA::DNN::WeightInitializationStrategy</a></div><div class="ttdeci">WeightInitializationStrategy</div><div class="ttdoc">weight initialization strategies to be chosen from </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01056">NeuralNet.h:1056</a></div></div>
<div class="ttc" id="namespaceTMath_html_a8a8fbe07e94608dbed9e9260283a442f"><div class="ttname"><a href="namespaceTMath.html#a8a8fbe07e94608dbed9e9260283a442f">TMath::E</a></div><div class="ttdeci">constexpr Double_t E()</div><div class="ttdoc">Base of natural log: . </div><div class="ttdef"><b>Definition:</b> <a href="TMath_8h_source.html#l00097">TMath.h:97</a></div></div>
<div class="ttc" id="Util_8h_html"><div class="ttname"><a href="Util_8h.html">Util.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a4534f487bb321b870a163bbbcc93133f"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a4534f487bb321b870a163bbbcc93133f">TMVA::DNN::Steepest::m_localGradients</a></div><div class="ttdeci">std::vector&lt; double &gt; m_localGradients</div><div class="ttdoc">local gradients for reuse in thread. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00377">NeuralNet.h:377</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_af0cd4d8dcbdd5c6f5acfac8e9cadf9d4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#af0cd4d8dcbdd5c6f5acfac8e9cadf9d4">TMVA::DNN::applyWeightsBackwards</a></div><div class="ttdeci">void applyWeightsBackwards(ItSource itCurrBegin, ItSource itCurrEnd, ItWeight itWeight, ItPrev itPrevBegin, ItPrev itPrevEnd)</div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_aea9c06caef41621ed569678d6ad50d1c"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#aea9c06caef41621ed569678d6ad50d1c">TMVA::DNN::Net::numWeights</a></div><div class="ttdeci">size_t numWeights(size_t trainingStartLayer=0) const</div><div class="ttdoc">returns the number of weights in this net </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00543">NeuralNet.cxx:543</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a0e9c3469fbae7cf3f216e6d9af423be7"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a0e9c3469fbae7cf3f216e6d9af423be7">TMVA::DNN::Tanh</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; Tanh</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00029">NeuralNet.cxx:29</a></div></div>
<div class="ttc" id="classPattern_html_a3ed111744fc0641dffebd2e9b3b79452"><div class="ttname"><a href="classPattern.html#a3ed111744fc0641dffebd2e9b3b79452">Pattern::weight</a></div><div class="ttdeci">double weight() const</div><div class="ttdef"><b>Definition:</b> <a href="Pattern_8h_source.html#l00074">Pattern.h:74</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_a08a1450b225d1df574935b2f5fb66ca5"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#a08a1450b225d1df574935b2f5fb66ca5">TMVA::DNN::LayerData::valuesEnd</a></div><div class="ttdeci">const_iterator_type valuesEnd() const</div><div class="ttdoc">returns iterator to the end of the (node) values </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00587">NeuralNet.h:587</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a1a62255a51643289090bb72884018f4d"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a1a62255a51643289090bb72884018f4d">TMVA::DNN::Net::fExitFromTraining</a></div><div class="ttdeci">bool * fExitFromTraining</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01284">NeuralNet.h:1284</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_aeb408087bfd3dba1614b5d8f291c12f8"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#aeb408087bfd3dba1614b5d8f291c12f8">TMVA::DNN::Net::fInteractive</a></div><div class="ttdeci">IPythonInteractive * fInteractive</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01283">NeuralNet.h:1283</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_aaa9effe30f4886bb8033f7e414e26738"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738">TMVA::DNN::ModeOutputValues</a></div><div class="ttdeci">ModeOutputValues</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00179">NeuralNet.h:179</a></div></div>
<div class="ttc" id="Pattern_8h_html"><div class="ttname"><a href="Pattern_8h.html">Pattern.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a77bcd2e07ff2c98832ffa70f4a415828"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a77bcd2e07ff2c98832ffa70f4a415828">TMVA::DNN::Net::prepareLayerData</a></div><div class="ttdeci">std::vector&lt; std::vector&lt; LayerData &gt; &gt; prepareLayerData(LayerContainer &amp;layers, Batch &amp;batch, const DropContainer &amp;dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &amp;totalNumWeights) const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01111">NeuralNet.icc:1111</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a2a75add87ac1f2bdf58c98b29ad83061"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a2a75add87ac1f2bdf58c98b29ad83061">TMVA::DNN::Steepest::m_repetitions</a></div><div class="ttdeci">size_t m_repetitions</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00338">NeuralNet.h:338</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a950e579aacb6827a2704dc698d90852d"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a950e579aacb6827a2704dc698d90852d">TMVA::DNN::gaussDouble</a></div><div class="ttdeci">double gaussDouble(double mean, double sigma)</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00035">NeuralNet.cxx:35</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Batch_html"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Batch.html">TMVA::DNN::Batch</a></div><div class="ttdoc">The Batch class encapsulates one mini-batch. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00235">NeuralNet.h:235</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a3fa66ca13e04cd2d7a994210c2dc9885"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a3fa66ca13e04cd2d7a994210c2dc9885">TMVA::DNN::Net::compute</a></div><div class="ttdeci">std::vector&lt; double &gt; compute(const std::vector&lt; double &gt; &amp;input, const Weights &amp;weights) const</div><div class="ttdoc">compute the net with the given input and the given weights </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01037">NeuralNet.icc:1037</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a3394b8036ca48698ad7a46c8da2998fc"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a3394b8036ca48698ad7a46c8da2998fc">TMVA::DNN::Steepest::m_beta</a></div><div class="ttdeci">double m_beta</div><div class="ttdoc">internal parameter (momentum) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00373">NeuralNet.h:373</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a1c0c6e0e3ec7f8b0bb7f1110bb0556a4"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a1c0c6e0e3ec7f8b0bb7f1110bb0556a4">TMVA::DNN::InvSigmoid</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvSigmoid</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00018">NeuralNet.cxx:18</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a6cd34fe7c9b4873728cb1ff37dc90e47"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a6cd34fe7c9b4873728cb1ff37dc90e47">TMVA::DNN::Net::train</a></div><div class="ttdeci">double train(std::vector&lt; double &gt; &amp;weights, std::vector&lt; Pattern &gt; &amp;trainPattern, const std::vector&lt; Pattern &gt; &amp;testPattern, Minimizer &amp;minimizer, Settings &amp;settings)</div><div class="ttdoc">start the training </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00710">NeuralNet.icc:710</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_ac5e78898db77521fdfd51e205098f870"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#ac5e78898db77521fdfd51e205098f870">TMVA::DNN::Settings::maxConvergenceCount</a></div><div class="ttdeci">size_t maxConvergenceCount() const</div><div class="ttdoc">returns the max convergence count so far </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00835">NeuralNet.h:835</a></div></div>
<div class="ttc" id="RooMathCoreReg_8cxx_html_a9ade5aa78cf41af74bbde701922393a6"><div class="ttname"><a href="RooMathCoreReg_8cxx.html#a9ade5aa78cf41af74bbde701922393a6">dummy</a></div><div class="ttdeci">static RooMathCoreReg dummy</div><div class="ttdef"><b>Definition:</b> <a href="RooMathCoreReg_8cxx_source.html#l00027">RooMathCoreReg.cxx:27</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a1c5ba59d5d3a4d5acba28e4a6a772994"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a1c5ba59d5d3a4d5acba28e4a6a772994">TMVA::DNN::forward</a></div><div class="ttdeci">void forward(const LAYERDATA &amp;prevLayerData, LAYERDATA &amp;currLayerData)</div><div class="ttdoc">apply the weights (and functions) in forward direction of the DNN </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00544">NeuralNet.icc:544</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a798fe06bfbd4bc51183ea8b3e88bc7e1afcf586bdbf33622592d7fa01b7a559d2"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1afcf586bdbf33622592d7fa01b7a559d2">TMVA::DNN::WeightInitializationStrategy::LAYERSIZE</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a0a3ba2e5a24d8d3926f97996f272f17b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a0a3ba2e5a24d8d3926f97996f272f17b">TMVA::DNN::uniformDouble</a></div><div class="ttdeci">double uniformDouble(double minValue, double maxValue)</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00043">NeuralNet.cxx:43</a></div></div>
<div class="ttc" id="Rtypes_8h_html_ac31db05c6cb5891c704eae374f6926a8a951e8c9c29427097fd137e19a3300e03"><div class="ttname"><a href="Rtypes_8h.html#ac31db05c6cb5891c704eae374f6926a8a951e8c9c29427097fd137e19a3300e03">kMagenta</a></div><div class="ttdef"><b>Definition:</b> <a href="Rtypes_8h_source.html#l00064">Rtypes.h:64</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_aaa9effe30f4886bb8033f7e414e26738a4c5d06b02c97731aaa976179c62dcf76"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738a4c5d06b02c97731aaa976179c62dcf76">TMVA::DNN::ModeOutputValues::DIRECT</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a798fe06bfbd4bc51183ea8b3e88bc7e1a8086fb8fd14889fa45664c844ed9780b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a798fe06bfbd4bc51183ea8b3e88bc7e1a8086fb8fd14889fa45664c844ed9780b">TMVA::DNN::WeightInitializationStrategy::XAVIER</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a787ad72a6f8892e98ed68f00332255d7"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a787ad72a6f8892e98ed68f00332255d7">TMVA::DNN::Steepest::operator()</a></div><div class="ttdeci">double operator()(Function &amp;fitnessFunction, Weights &amp;weights, PassThrough &amp;passThrough)</div><div class="ttdoc">operator to call the steepest gradient descent algorithm </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00269">NeuralNet.icc:269</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_aba4807516c013acf168eaa8c6757f2c3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#aba4807516c013acf168eaa8c6757f2c3">TMVA::DNN::LayerData::deltasEnd</a></div><div class="ttdeci">iterator_type deltasEnd()</div><div class="ttdoc">returns iterator to the end of the deltas (back-propagation) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00596">NeuralNet.h:596</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_abe48507f3532940d85b67db6c08ead47"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#abe48507f3532940d85b67db6c08ead47">TMVA::DNN::InvSoftPlus</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvSoftPlus</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00019">NeuralNet.cxx:19</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a849b4ea12faeb3e858c29ed5444f3c2b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a849b4ea12faeb3e858c29ed5444f3c2b">TMVA::DNN::GaussComplement</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; GaussComplement</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00013">NeuralNet.cxx:13</a></div></div>
<div class="ttc" id="namespaceTMVA_html"><div class="ttname"><a href="namespaceTMVA.html">TMVA</a></div><div class="ttdoc">create variable transformations </div><div class="ttdef"><b>Definition:</b> <a href="GeneticMinimizer_8h_source.html#l00021">GeneticMinimizer.h:21</a></div></div>
<div class="ttc" id="Util_8h_html_addc4ff313880673f5f81049d16e837da"><div class="ttname"><a href="Util_8h.html#addc4ff313880673f5f81049d16e837da">MATH_UNUSED</a></div><div class="ttdeci">#define MATH_UNUSED(var)</div><div class="ttdef"><b>Definition:</b> <a href="Util_8h_source.html#l00033">Util.h:33</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a042311ead1df58db2448f9617e502351"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a042311ead1df58db2448f9617e502351">TMVA::DNN::InvGauss</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvGauss</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00014">NeuralNet.cxx:14</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a87e95e1fb20e2d77c7d5b725f8c6fa91"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a87e95e1fb20e2d77c7d5b725f8c6fa91">TMVA::DNN::Net::forward_backward</a></div><div class="ttdeci">double forward_backward(LayerContainer &amp;layers, PassThrough &amp;settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &amp;outputContainer, bool fetchOutput) const</div><div class="ttdoc">main NN computation function </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01416">NeuralNet.icc:1416</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_adf11e852a174d69f35a5080c2f785355"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#adf11e852a174d69f35a5080c2f785355">TMVA::DNN::InvTanhShift</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; InvTanhShift</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00023">NeuralNet.cxx:23</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Batch_html_a93d8ed91fddf52d36362fad809125e0a"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Batch.html#a93d8ed91fddf52d36362fad809125e0a">TMVA::DNN::Batch::size</a></div><div class="ttdeci">size_t size() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00248">NeuralNet.h:248</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_acf69c56affd5b534ddafd2e6ecc45336"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#acf69c56affd5b534ddafd2e6ecc45336">TMVA::DNN::Settings::batchSize</a></div><div class="ttdeci">size_t batchSize() const</div><div class="ttdoc">mini-batch size </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00774">NeuralNet.h:774</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_aaa9effe30f4886bb8033f7e414e26738a1d993169621e0855bad00d71c005cf1b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#aaa9effe30f4886bb8033f7e414e26738a1d993169621e0855bad00d71c005cf1b">TMVA::DNN::ModeOutputValues::SOFTMAX</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a31b2996a3b88156a828ff7c0bc929b95"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a31b2996a3b88156a828ff7c0bc929b95">TMVA::DNN::Settings::endTestCycle</a></div><div class="ttdeci">virtual void endTestCycle()</div><div class="ttdoc">callback for monitoring and loggging </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00812">NeuralNet.h:812</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a92bced0322f6ee9c19ff2385872cfb75"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a92bced0322f6ee9c19ff2385872cfb75">TMVA::DNN::Sigmoid</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; Sigmoid</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00026">NeuralNet.cxx:26</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a748c8e8570ce7eabe68bfdfef6b654be"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a748c8e8570ce7eabe68bfdfef6b654be">TMVA::DNN::Steepest::m_localWeights</a></div><div class="ttdeci">std::vector&lt; double &gt; m_localWeights</div><div class="ttdoc">local weights for reuse in thread. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00376">NeuralNet.h:376</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_a3c5afad7c1a30b14d87436b0df39375b"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#a3c5afad7c1a30b14d87436b0df39375b">TMVA::DNN::LayerData::valueGradientsBegin</a></div><div class="ttdeci">iterator_type valueGradientsBegin()</div><div class="ttdoc">returns iterator to the begin of the gradients of the node values </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00601">NeuralNet.h:601</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a6f8505127caaa2ff0832e521b56b633e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a6f8505127caaa2ff0832e521b56b633e">TMVA::DNN::Net::backPropagate</a></div><div class="ttdeci">void backPropagate(std::vector&lt; std::vector&lt; LayerData &gt;&gt; &amp;layerPatternData, const Settings &amp;settings, size_t trainFromLayer, size_t totalNumWeights) const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l01365">NeuralNet.icc:1365</a></div></div>
<div class="ttc" id="Rtypes_8h_html_ac31db05c6cb5891c704eae374f6926a8aab48c32302f7159d81e081c41dc2d3d2"><div class="ttname"><a href="Rtypes_8h.html#ac31db05c6cb5891c704eae374f6926a8aab48c32302f7159d81e081c41dc2d3d2">kBlue</a></div><div class="ttdef"><b>Definition:</b> <a href="Rtypes_8h_source.html#l00064">Rtypes.h:64</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_ad2ede1e2183a37e0c768df40a59581a6"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#ad2ede1e2183a37e0c768df40a59581a6">TMVA::DNN::Settings::computeResult</a></div><div class="ttdeci">virtual void computeResult(const Net &amp;, std::vector&lt; double &gt; &amp;)</div><div class="ttdoc">callback for monitoring and loggging </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00816">NeuralNet.h:816</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a8c836f41af6a7a0798e60ddd1262f074"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a8c836f41af6a7a0798e60ddd1262f074">TMVA::DNN::Gauss</a></div><div class="ttdeci">std::shared_ptr&lt; std::function&lt; double(double)&gt; &gt; Gauss</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00012">NeuralNet.cxx:12</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Batch_html_a1f1c71bd2af68e6ea1105d38b1e26e3e"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Batch.html#a1f1c71bd2af68e6ea1105d38b1e26e3e">TMVA::DNN::Batch::begin</a></div><div class="ttdeci">const_iterator begin() const</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00245">NeuralNet.h:245</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_afbb04013581dbe91bfddbd2243559ec3"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#afbb04013581dbe91bfddbd2243559ec3">TMVA::DNN::LayerData::const_dropout_iterator</a></div><div class="ttdeci">DropContainer::const_iterator const_dropout_iterator</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00449">NeuralNet.h:449</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Steepest_html_a677db9c1dba0e4e3a26fb4a9323627a9"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Steepest.html#a677db9c1dba0e4e3a26fb4a9323627a9">TMVA::DNN::Steepest::m_alpha</a></div><div class="ttdeci">double m_alpha</div><div class="ttdoc">internal parameter (learningRate) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00372">NeuralNet.h:372</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3b0759fc76ba1cd946231f05c309f195"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3b0759fc76ba1cd946231f05c309f195">TMVA::DNN::EnumRegularization</a></div><div class="ttdeci">EnumRegularization</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00173">NeuralNet.h:173</a></div></div>
<div class="ttc" id="win32gdk_2src_2gifencode_8c_html_a606a386e5db616c66c8c8d932d23dc39"><div class="ttname"><a href="win32gdk_2src_2gifencode_8c.html#a606a386e5db616c66c8c8d932d23dc39">output</a></div><div class="ttdeci">static void output(int code)</div><div class="ttdef"><b>Definition:</b> <a href="win32gdk_2src_2gifencode_8c_source.html#l00226">gifencode.c:226</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html_afbb661b4ea410c550dc914f71bce11c2"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html#afbb661b4ea410c550dc914f71bce11c2">TMVA::DNN::LayerData::valuesBegin</a></div><div class="ttdeci">const_iterator_type valuesBegin() const</div><div class="ttdoc">returns const iterator to the begin of the (node) values </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00586">NeuralNet.h:586</a></div></div>
<div class="ttc" id="MethodBase_8h_html"><div class="ttname"><a href="MethodBase_8h.html">MethodBase.h</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Net_html_a7fd8f63f29343d003d876a2f590c32ba"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Net.html#a7fd8f63f29343d003d876a2f590c32ba">TMVA::DNN::Net::outputSize</a></div><div class="ttdeci">size_t outputSize() const</div><div class="ttdoc">output size of the DNN </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01106">NeuralNet.h:1106</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a06dbb6605302256fcadab7b7f6a1178b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a06dbb6605302256fcadab7b7f6a1178b">TMVA::DNN::sumOfSquares</a></div><div class="ttdeci">double sumOfSquares(ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)</div></div>
<div class="ttc" id="legend1_8C_html_a16daaa7b596941b23915a1ac1be5b42c"><div class="ttname"><a href="legend1_8C.html#a16daaa7b596941b23915a1ac1be5b42c">n</a></div><div class="ttdeci">const Int_t n</div><div class="ttdef"><b>Definition:</b> <a href="legend1_8C_source.html#l00016">legend1.C:16</a></div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_a3dafd45dcc339aced1c2ff418d084efa"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#a3dafd45dcc339aced1c2ff418d084efa">TMVA::DNN::crossEntropy</a></div><div class="ttdeci">double crossEntropy(ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)</div><div class="ttdoc">cross entropy error function </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8icc_source.html#l00410">NeuralNet.icc:410</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_a4ed999b56834e118be62b4dfd20d2edc"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#a4ed999b56834e118be62b4dfd20d2edc">TMVA::DNN::Settings::hasConverged</a></div><div class="ttdeci">virtual bool hasConverged(double testError)</div><div class="ttdoc">has this training converged already? </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8cxx_source.html#l00488">NeuralNet.cxx:488</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1LayerData_html"><div class="ttname"><a href="classTMVA_1_1DNN_1_1LayerData.html">TMVA::DNN::LayerData</a></div><div class="ttdoc">LayerData holds the data of one layer. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00437">NeuralNet.h:437</a></div></div>
<div class="ttc" id="classTMVA_1_1DNN_1_1Settings_html_aa3640ef5280a6f067100bbf236d7c4ba"><div class="ttname"><a href="classTMVA_1_1DNN_1_1Settings.html#aa3640ef5280a6f067100bbf236d7c4ba">TMVA::DNN::Settings::testSample</a></div><div class="ttdeci">virtual void testSample(double, double, double, double)</div><div class="ttdoc">virtual function to be used for monitoring (callback) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l00788">NeuralNet.h:788</a></div></div>
<div class="ttc" id="TMath_8h_html_afa752f47ff073d8639c631f079670788"><div class="ttname"><a href="TMath_8h.html#afa752f47ff073d8639c631f079670788">log</a></div><div class="ttdeci">double log(double)</div></div>
<div class="ttc" id="namespaceTMVA_1_1DNN_html_acd7081b3481c72ec441fbd77e624613b"><div class="ttname"><a href="namespaceTMVA_1_1DNN.html#acd7081b3481c72ec441fbd77e624613b">TMVA::DNN::pass_through_type</a></div><div class="ttdeci">std::tuple&lt; Settings &amp;, Batch &amp;, DropContainer &amp; &gt; pass_through_type</div><div class="ttdef"><b>Definition:</b> <a href="NeuralNet_8h_source.html#l01301">NeuralNet.h:1301</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:09:45 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
