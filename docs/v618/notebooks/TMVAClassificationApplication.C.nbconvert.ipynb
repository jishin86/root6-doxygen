{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  T M V A Classification Application\n",
    "This macro provides a simple example on how to use the trained classifiers\n",
    "within an analysis module\n",
    "- Project   : TMVA - a Root-integrated toolkit for multivariate data analysis\n",
    "- Package   : TMVA\n",
    "- Exectuable: TMVAClassificationApplication\n",
    "\n",
    "\n",
    "\n",
    "**Author:** Andreas Hoecker  \n",
    "<i><small>This notebook tutorial was automatically generated with <a href= \"https://github.com/root-project/root/blob/master/documentation/doxygen/converttonotebook.py\">ROOTBOOK-izer</a> from the macro found in the ROOT repository  on Thursday, August 29, 2019 at 03:45 AM.</small></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cpp -d\n",
    "#include <cstdlib>\n",
    "#include <vector>\n",
    "#include <iostream>\n",
    "#include <map>\n",
    "#include <string>\n",
    "\n",
    "#include \"TFile.h\"\n",
    "#include \"TTree.h\"\n",
    "#include \"TString.h\"\n",
    "#include \"TSystem.h\"\n",
    "#include \"TROOT.h\"\n",
    "#include \"TStopwatch.h\"\n",
    "\n",
    "#include \"TMVA/Tools.h\"\n",
    "#include \"TMVA/Reader.h\"\n",
    "#include \"TMVA/MethodCuts.h\"\n",
    "\n",
    "using namespace TMVA;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Arguments are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TString myMethodList = \"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    " This loads the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default mva methods to be trained + tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::map<std::string,int> Use;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"Cuts\"]            = 1;\n",
    "Use[\"CutsD\"]           = 1;\n",
    "Use[\"CutsPCA\"]         = 0;\n",
    "Use[\"CutsGA\"]          = 0;\n",
    "Use[\"CutsSA\"]          = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1-dimensional likelihood (\"naive Bayes estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"Likelihood\"]      = 1;\n",
    "Use[\"LikelihoodD\"]     = 0; // the \"D\" extension indicates decorrelated input variables (see option strings)\n",
    "Use[\"LikelihoodPCA\"]   = 1; // the \"PCA\" extension indicates PCA-transformed input variables (see option strings)\n",
    "Use[\"LikelihoodKDE\"]   = 0;\n",
    "Use[\"LikelihoodMIX\"]   = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Mutidimensional likelihood and Nearest-Neighbour methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"PDERS\"]           = 1;\n",
    "Use[\"PDERSD\"]          = 0;\n",
    "Use[\"PDERSPCA\"]        = 0;\n",
    "Use[\"PDEFoam\"]         = 1;\n",
    "Use[\"PDEFoamBoost\"]    = 0; // uses generalised MVA method boosting\n",
    "Use[\"KNN\"]             = 1; // k-nearest neighbour method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"LD\"]              = 1; // Linear Discriminant identical to Fisher\n",
    "Use[\"Fisher\"]          = 0;\n",
    "Use[\"FisherG\"]         = 0;\n",
    "Use[\"BoostedFisher\"]   = 0; // uses generalised MVA method boosting\n",
    "Use[\"HMatrix\"]         = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function Discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"FDA_GA\"]          = 1; // minimisation of user-defined function using Genetics Algorithm\n",
    "Use[\"FDA_SA\"]          = 0;\n",
    "Use[\"FDA_MC\"]          = 0;\n",
    "Use[\"FDA_MT\"]          = 0;\n",
    "Use[\"FDA_GAMT\"]        = 0;\n",
    "Use[\"FDA_MCMT\"]        = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Neural Networks (all are feed-forward Multilayer Perceptrons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"MLP\"]             = 0; // Recommended ANN\n",
    "Use[\"MLPBFGS\"]         = 0; // Recommended ANN with optional training method\n",
    "Use[\"MLPBNN\"]          = 1; // Recommended ANN with BFGS training method and bayesian regulator\n",
    "Use[\"CFMlpANN\"]        = 0; // Depreciated ANN from ALEPH\n",
    "Use[\"TMlpANN\"]         = 0; // ROOT's own ANN\n",
    "Use[\"DNN_CPU\"] = 0;         // CUDA-accelerated DNN training.\n",
    "Use[\"DNN_GPU\"] = 0;         // Multi-core accelerated DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"SVM\"]             = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"BDT\"]             = 1; // uses Adaptive Boost\n",
    "Use[\"BDTG\"]            = 0; // uses Gradient Boost\n",
    "Use[\"BDTB\"]            = 0; // uses Bagging\n",
    "Use[\"BDTD\"]            = 0; // decorrelation + Adaptive Boost\n",
    "Use[\"BDTF\"]            = 0; // allow usage of fisher discriminant for node splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Friedman's RuleFit method, ie, an optimised series of cuts (\"rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"RuleFit\"]         = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Start TMVAClassificationApplication\n"
     ]
    }
   ],
   "source": [
    "Use[\"Plugin\"]          = 0;\n",
    "Use[\"Category\"]        = 0;\n",
    "Use[\"SVM_Gauss\"]       = 0;\n",
    "Use[\"SVM_Poly\"]        = 0;\n",
    "Use[\"SVM_Lin\"]         = 0;\n",
    "\n",
    "std::cout << std::endl;\n",
    "std::cout << \"==> Start TMVAClassificationApplication\" << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select methods (don't look at this code - not of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (myMethodList != \"\") {\n",
    "   for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) it->second = 0;\n",
    "\n",
    "   std::vector<TString> mlist = gTools().SplitString( myMethodList, ',' );\n",
    "   for (UInt_t i=0; i<mlist.size(); i++) {\n",
    "      std::string regMethod(mlist[i]);\n",
    "\n",
    "      if (Use.find(regMethod) == Use.end()) {\n",
    "         std::cout << \"Method \\\"\" << regMethod\n",
    "                   << \"\\\" not known in TMVA under this name. Choose among the following:\" << std::endl;\n",
    "         for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) {\n",
    "            std::cout << it->first << \" \";\n",
    "         }\n",
    "         std::cout << std::endl;\n",
    "         return;\n",
    "      }\n",
    "      Use[regMethod] = 1;\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the reader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMVA::Reader *reader = new TMVA::Reader( \"!Color:!Silent\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of variables and declare them to the reader\n",
    " - the variable names MUST corresponds in name and type to those given in the weight file(s) used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Float_t var1, var2;\n",
    "Float_t var3, var4;\n",
    "reader->AddVariable( \"myvar1 := var1+var2\", &var1 );\n",
    "reader->AddVariable( \"myvar2 := var1-var2\", &var2 );\n",
    "reader->AddVariable( \"var3\",                &var3 );\n",
    "reader->AddVariable( \"var4\",                &var4 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectator variables declared in the training have to be added to the reader, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Float_t spec1,spec2;\n",
    "reader->AddSpectator( \"spec1 := var1*2\",   &spec1 );\n",
    "reader->AddSpectator( \"spec2 := var1*3\",   &spec2 );\n",
    "\n",
    "Float_t Category_cat1, Category_cat2, Category_cat3;\n",
    "if (Use[\"Category\"]){\n",
    "   // Add artificial spectators for distinguishing categories\n",
    "   reader->AddSpectator( \"Category_cat1 := var3<=0\",             &Category_cat1 );\n",
    "   reader->AddSpectator( \"Category_cat2 := (var3>0)&&(var4<0)\",  &Category_cat2 );\n",
    "   reader->AddSpectator( \"Category_cat3 := (var3>0)&&(var4>=0)\", &Category_cat3 );\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book the mva methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TString dir    = \"dataset/weights/\";\n",
    "TString prefix = \"TMVAClassification\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book method(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FATAL>                          : <BookMVA> fatal error: unable to open input weight file: dataset/weights/TMVAClassification_BDT.weights.xml\n",
      "***> abort program execution\n"
     ]
    }
   ],
   "source": [
    "for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) {\n",
    "   if (it->second) {\n",
    "      TString methodName = TString(it->first) + TString(\" method\");\n",
    "      TString weightfile = dir + prefix + TString(\"_\") + TString(it->first) + TString(\".weights.xml\");\n",
    "      reader->BookMVA( methodName, weightfile );\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book output histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UInt_t nbin = 100;\n",
    "TH1F *histLk(0);\n",
    "TH1F *histLkD(0);\n",
    "TH1F *histLkPCA(0);\n",
    "TH1F *histLkKDE(0);\n",
    "TH1F *histLkMIX(0);\n",
    "TH1F *histPD(0);\n",
    "TH1F *histPDD(0);\n",
    "TH1F *histPDPCA(0);\n",
    "TH1F *histPDEFoam(0);\n",
    "TH1F *histPDEFoamErr(0);\n",
    "TH1F *histPDEFoamSig(0);\n",
    "TH1F *histKNN(0);\n",
    "TH1F *histHm(0);\n",
    "TH1F *histFi(0);\n",
    "TH1F *histFiG(0);\n",
    "TH1F *histFiB(0);\n",
    "TH1F *histLD(0);\n",
    "TH1F *histNn(0);\n",
    "TH1F *histNnbfgs(0);\n",
    "TH1F *histNnbnn(0);\n",
    "TH1F *histNnC(0);\n",
    "TH1F *histNnT(0);\n",
    "TH1F *histBdt(0);\n",
    "TH1F *histBdtG(0);\n",
    "TH1F *histBdtB(0);\n",
    "TH1F *histBdtD(0);\n",
    "TH1F *histBdtF(0);\n",
    "TH1F *histRf(0);\n",
    "TH1F *histSVMG(0);\n",
    "TH1F *histSVMP(0);\n",
    "TH1F *histSVML(0);\n",
    "TH1F *histFDAMT(0);\n",
    "TH1F *histFDAGA(0);\n",
    "TH1F *histCat(0);\n",
    "TH1F *histPBdt(0);\n",
    "TH1F *histDnnGpu(0);\n",
    "TH1F *histDnnCpu(0);\n",
    "\n",
    "if (Use[\"Likelihood\"])    histLk      = new TH1F( \"MVA_Likelihood\",    \"MVA_Likelihood\",    nbin, -1, 1 );\n",
    "if (Use[\"LikelihoodD\"])   histLkD     = new TH1F( \"MVA_LikelihoodD\",   \"MVA_LikelihoodD\",   nbin, -1, 0.9999 );\n",
    "if (Use[\"LikelihoodPCA\"]) histLkPCA   = new TH1F( \"MVA_LikelihoodPCA\", \"MVA_LikelihoodPCA\", nbin, -1, 1 );\n",
    "if (Use[\"LikelihoodKDE\"]) histLkKDE   = new TH1F( \"MVA_LikelihoodKDE\", \"MVA_LikelihoodKDE\", nbin,  -0.00001, 0.99999 );\n",
    "if (Use[\"LikelihoodMIX\"]) histLkMIX   = new TH1F( \"MVA_LikelihoodMIX\", \"MVA_LikelihoodMIX\", nbin,  0, 1 );\n",
    "if (Use[\"PDERS\"])         histPD      = new TH1F( \"MVA_PDERS\",         \"MVA_PDERS\",         nbin,  0, 1 );\n",
    "if (Use[\"PDERSD\"])        histPDD     = new TH1F( \"MVA_PDERSD\",        \"MVA_PDERSD\",        nbin,  0, 1 );\n",
    "if (Use[\"PDERSPCA\"])      histPDPCA   = new TH1F( \"MVA_PDERSPCA\",      \"MVA_PDERSPCA\",      nbin,  0, 1 );\n",
    "if (Use[\"KNN\"])           histKNN     = new TH1F( \"MVA_KNN\",           \"MVA_KNN\",           nbin,  0, 1 );\n",
    "if (Use[\"HMatrix\"])       histHm      = new TH1F( \"MVA_HMatrix\",       \"MVA_HMatrix\",       nbin, -0.95, 1.55 );\n",
    "if (Use[\"Fisher\"])        histFi      = new TH1F( \"MVA_Fisher\",        \"MVA_Fisher\",        nbin, -4, 4 );\n",
    "if (Use[\"FisherG\"])       histFiG     = new TH1F( \"MVA_FisherG\",       \"MVA_FisherG\",       nbin, -1, 1 );\n",
    "if (Use[\"BoostedFisher\"]) histFiB     = new TH1F( \"MVA_BoostedFisher\", \"MVA_BoostedFisher\", nbin, -2, 2 );\n",
    "if (Use[\"LD\"])            histLD      = new TH1F( \"MVA_LD\",            \"MVA_LD\",            nbin, -2, 2 );\n",
    "if (Use[\"MLP\"])           histNn      = new TH1F( \"MVA_MLP\",           \"MVA_MLP\",           nbin, -1.25, 1.5 );\n",
    "if (Use[\"MLPBFGS\"])       histNnbfgs  = new TH1F( \"MVA_MLPBFGS\",       \"MVA_MLPBFGS\",       nbin, -1.25, 1.5 );\n",
    "if (Use[\"MLPBNN\"])        histNnbnn   = new TH1F( \"MVA_MLPBNN\",        \"MVA_MLPBNN\",        nbin, -1.25, 1.5 );\n",
    "if (Use[\"CFMlpANN\"])      histNnC     = new TH1F( \"MVA_CFMlpANN\",      \"MVA_CFMlpANN\",      nbin,  0, 1 );\n",
    "if (Use[\"TMlpANN\"])       histNnT     = new TH1F( \"MVA_TMlpANN\",       \"MVA_TMlpANN\",       nbin, -1.3, 1.3 );\n",
    "if (Use[\"DNN_GPU\"]) histDnnGpu = new TH1F(\"MVA_DNN_GPU\", \"MVA_DNN_GPU\", nbin, -0.1, 1.1);\n",
    "if (Use[\"DNN_CPU\"]) histDnnCpu = new TH1F(\"MVA_DNN_CPU\", \"MVA_DNN_CPU\", nbin, -0.1, 1.1);\n",
    "if (Use[\"BDT\"])           histBdt     = new TH1F( \"MVA_BDT\",           \"MVA_BDT\",           nbin, -0.8, 0.8 );\n",
    "if (Use[\"BDTG\"])          histBdtG    = new TH1F( \"MVA_BDTG\",          \"MVA_BDTG\",          nbin, -1.0, 1.0 );\n",
    "if (Use[\"BDTB\"])          histBdtB    = new TH1F( \"MVA_BDTB\",          \"MVA_BDTB\",          nbin, -1.0, 1.0 );\n",
    "if (Use[\"BDTD\"])          histBdtD    = new TH1F( \"MVA_BDTD\",          \"MVA_BDTD\",          nbin, -0.8, 0.8 );\n",
    "if (Use[\"BDTF\"])          histBdtF    = new TH1F( \"MVA_BDTF\",          \"MVA_BDTF\",          nbin, -1.0, 1.0 );\n",
    "if (Use[\"RuleFit\"])       histRf      = new TH1F( \"MVA_RuleFit\",       \"MVA_RuleFit\",       nbin, -2.0, 2.0 );\n",
    "if (Use[\"SVM_Gauss\"])     histSVMG    = new TH1F( \"MVA_SVM_Gauss\",     \"MVA_SVM_Gauss\",     nbin,  0.0, 1.0 );\n",
    "if (Use[\"SVM_Poly\"])      histSVMP    = new TH1F( \"MVA_SVM_Poly\",      \"MVA_SVM_Poly\",      nbin,  0.0, 1.0 );\n",
    "if (Use[\"SVM_Lin\"])       histSVML    = new TH1F( \"MVA_SVM_Lin\",       \"MVA_SVM_Lin\",       nbin,  0.0, 1.0 );\n",
    "if (Use[\"FDA_MT\"])        histFDAMT   = new TH1F( \"MVA_FDA_MT\",        \"MVA_FDA_MT\",        nbin, -2.0, 3.0 );\n",
    "if (Use[\"FDA_GA\"])        histFDAGA   = new TH1F( \"MVA_FDA_GA\",        \"MVA_FDA_GA\",        nbin, -2.0, 3.0 );\n",
    "if (Use[\"Category\"])      histCat     = new TH1F( \"MVA_Category\",      \"MVA_Category\",      nbin, -2., 2. );\n",
    "if (Use[\"Plugin\"])        histPBdt    = new TH1F( \"MVA_PBDT\",          \"MVA_BDT\",           nbin, -0.8, 0.8 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pdefoam also returns per-event error, fill in histogram, and also fill significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Use[\"PDEFoam\"]) {\n",
    "   histPDEFoam    = new TH1F( \"MVA_PDEFoam\",       \"MVA_PDEFoam\",              nbin,  0, 1 );\n",
    "   histPDEFoamErr = new TH1F( \"MVA_PDEFoamErr\",    \"MVA_PDEFoam error\",        nbin,  0, 1 );\n",
    "   histPDEFoamSig = new TH1F( \"MVA_PDEFoamSig\",    \"MVA_PDEFoam significance\", nbin,  0, 10 );\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book example histogram for probability (the other methods are done similarly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TH1F *probHistFi(0), *rarityHistFi(0);\n",
    "if (Use[\"Fisher\"]) {\n",
    "   probHistFi   = new TH1F( \"MVA_Fisher_Proba\",  \"MVA_Fisher_Proba\",  nbin, 0, 1 );\n",
    "   rarityHistFi = new TH1F( \"MVA_Fisher_Rarity\", \"MVA_Fisher_Rarity\", nbin, 0, 1 );\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input tree (this must be replaced by your data source)\n",
    " in this example, there is a toy tree with signal and one with background events\n",
    " we'll later on use only the \"signal\" events for the test in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TMVAClassificationApp    : Using input file: ./files/tmva_class_example.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TFile::OpenFromCache>: using local cache copy of http://root.cern.ch/files/tmva_class_example.root [./files/tmva_class_example.root]\n"
     ]
    }
   ],
   "source": [
    "TFile *input(0);\n",
    "TString fname = \"./tmva_class_example.root\";\n",
    "if (!gSystem->AccessPathName( fname )) {\n",
    "   input = TFile::Open( fname ); // check if file in local directory exists\n",
    "}\n",
    "else {\n",
    "   TFile::SetCacheFileDir(\".\");\n",
    "   input = TFile::Open(\"http://root.cern.ch/files/tmva_class_example.root\", \"CACHEREAD\"); // if not: download from ROOT server\n",
    "}\n",
    "if (!input) {\n",
    "   std::cout << \"ERROR: could not open data file\" << std::endl;\n",
    "   exit(1);\n",
    "}\n",
    "std::cout << \"--- TMVAClassificationApp    : Using input file: \" << input->GetName() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the event tree\n",
    " - Here the variable names have to corresponds to your tree\n",
    " - You can use the same variables as above which is slightly faster,\n",
    "   but of course you can use different ones and copy the values inside the event loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Select signal sample\n"
     ]
    }
   ],
   "source": [
    "std::cout << \"--- Select signal sample\" << std::endl;\n",
    "TTree* theTree = (TTree*)input->Get(\"TreeS\");\n",
    "Float_t userVar1, userVar2;\n",
    "theTree->SetBranchAddress( \"var1\", &userVar1 );\n",
    "theTree->SetBranchAddress( \"var2\", &userVar2 );\n",
    "theTree->SetBranchAddress( \"var3\", &var3 );\n",
    "theTree->SetBranchAddress( \"var4\", &var4 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency calculator for cut method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing: 6000 events\n",
      "--- ... Processing event: 0\n",
      "                         : <BookMVA> fatal error: unable to open input weight file: dataset/weights/TMVAClassification_BDT.weights.xml<EvaluateMVA> unknown classifier in map; you looked for \"Likelihood method\" within available methods: \n",
      "<FATAL>                          : Check calling string\n",
      "***> abort program execution\n"
     ]
    }
   ],
   "source": [
    "Int_t    nSelCutsGA = 0;\n",
    "Double_t effS       = 0.7;\n",
    "\n",
    "std::vector<Float_t> vecVar(4); // vector for EvaluateMVA tests\n",
    "\n",
    "std::cout << \"--- Processing: \" << theTree->GetEntries() << \" events\" << std::endl;\n",
    "TStopwatch sw;\n",
    "sw.Start();\n",
    "for (Long64_t ievt=0; ievt<theTree->GetEntries();ievt++) {\n",
    "\n",
    "   if (ievt%1000 == 0) std::cout << \"--- ... Processing event: \" << ievt << std::endl;\n",
    "\n",
    "   theTree->GetEntry(ievt);\n",
    "\n",
    "   var1 = userVar1 + userVar2;\n",
    "   var2 = userVar1 - userVar2;\n",
    "\n",
    "   // Return the MVA outputs and fill into histograms\n",
    "\n",
    "   if (Use[\"CutsGA\"]) {\n",
    "      // Cuts is a special case: give the desired signal efficienciy\n",
    "      Bool_t passed = reader->EvaluateMVA( \"CutsGA method\", effS );\n",
    "      if (passed) nSelCutsGA++;\n",
    "   }\n",
    "\n",
    "   if (Use[\"Likelihood\"   ])   histLk     ->Fill( reader->EvaluateMVA( \"Likelihood method\"    ) );\n",
    "   if (Use[\"LikelihoodD\"  ])   histLkD    ->Fill( reader->EvaluateMVA( \"LikelihoodD method\"   ) );\n",
    "   if (Use[\"LikelihoodPCA\"])   histLkPCA  ->Fill( reader->EvaluateMVA( \"LikelihoodPCA method\" ) );\n",
    "   if (Use[\"LikelihoodKDE\"])   histLkKDE  ->Fill( reader->EvaluateMVA( \"LikelihoodKDE method\" ) );\n",
    "   if (Use[\"LikelihoodMIX\"])   histLkMIX  ->Fill( reader->EvaluateMVA( \"LikelihoodMIX method\" ) );\n",
    "   if (Use[\"PDERS\"        ])   histPD     ->Fill( reader->EvaluateMVA( \"PDERS method\"         ) );\n",
    "   if (Use[\"PDERSD\"       ])   histPDD    ->Fill( reader->EvaluateMVA( \"PDERSD method\"        ) );\n",
    "   if (Use[\"PDERSPCA\"     ])   histPDPCA  ->Fill( reader->EvaluateMVA( \"PDERSPCA method\"      ) );\n",
    "   if (Use[\"KNN\"          ])   histKNN    ->Fill( reader->EvaluateMVA( \"KNN method\"           ) );\n",
    "   if (Use[\"HMatrix\"      ])   histHm     ->Fill( reader->EvaluateMVA( \"HMatrix method\"       ) );\n",
    "   if (Use[\"Fisher\"       ])   histFi     ->Fill( reader->EvaluateMVA( \"Fisher method\"        ) );\n",
    "   if (Use[\"FisherG\"      ])   histFiG    ->Fill( reader->EvaluateMVA( \"FisherG method\"       ) );\n",
    "   if (Use[\"BoostedFisher\"])   histFiB    ->Fill( reader->EvaluateMVA( \"BoostedFisher method\" ) );\n",
    "   if (Use[\"LD\"           ])   histLD     ->Fill( reader->EvaluateMVA( \"LD method\"            ) );\n",
    "   if (Use[\"MLP\"          ])   histNn     ->Fill( reader->EvaluateMVA( \"MLP method\"           ) );\n",
    "   if (Use[\"MLPBFGS\"      ])   histNnbfgs ->Fill( reader->EvaluateMVA( \"MLPBFGS method\"       ) );\n",
    "   if (Use[\"MLPBNN\"       ])   histNnbnn  ->Fill( reader->EvaluateMVA( \"MLPBNN method\"        ) );\n",
    "   if (Use[\"CFMlpANN\"     ])   histNnC    ->Fill( reader->EvaluateMVA( \"CFMlpANN method\"      ) );\n",
    "   if (Use[\"TMlpANN\"      ])   histNnT    ->Fill( reader->EvaluateMVA( \"TMlpANN method\"       ) );\n",
    "   if (Use[\"DNN_GPU\"]) histDnnGpu->Fill(reader->EvaluateMVA(\"DNN_GPU method\"));\n",
    "   if (Use[\"DNN_CPU\"]) histDnnCpu->Fill(reader->EvaluateMVA(\"DNN_CPU method\"));\n",
    "   if (Use[\"BDT\"          ])   histBdt    ->Fill( reader->EvaluateMVA( \"BDT method\"           ) );\n",
    "   if (Use[\"BDTG\"         ])   histBdtG   ->Fill( reader->EvaluateMVA( \"BDTG method\"          ) );\n",
    "   if (Use[\"BDTB\"         ])   histBdtB   ->Fill( reader->EvaluateMVA( \"BDTB method\"          ) );\n",
    "   if (Use[\"BDTD\"         ])   histBdtD   ->Fill( reader->EvaluateMVA( \"BDTD method\"          ) );\n",
    "   if (Use[\"BDTF\"         ])   histBdtF   ->Fill( reader->EvaluateMVA( \"BDTF method\"          ) );\n",
    "   if (Use[\"RuleFit\"      ])   histRf     ->Fill( reader->EvaluateMVA( \"RuleFit method\"       ) );\n",
    "   if (Use[\"SVM_Gauss\"    ])   histSVMG   ->Fill( reader->EvaluateMVA( \"SVM_Gauss method\"     ) );\n",
    "   if (Use[\"SVM_Poly\"     ])   histSVMP   ->Fill( reader->EvaluateMVA( \"SVM_Poly method\"      ) );\n",
    "   if (Use[\"SVM_Lin\"      ])   histSVML   ->Fill( reader->EvaluateMVA( \"SVM_Lin method\"       ) );\n",
    "   if (Use[\"FDA_MT\"       ])   histFDAMT  ->Fill( reader->EvaluateMVA( \"FDA_MT method\"        ) );\n",
    "   if (Use[\"FDA_GA\"       ])   histFDAGA  ->Fill( reader->EvaluateMVA( \"FDA_GA method\"        ) );\n",
    "   if (Use[\"Category\"     ])   histCat    ->Fill( reader->EvaluateMVA( \"Category method\"      ) );\n",
    "   if (Use[\"Plugin\"       ])   histPBdt   ->Fill( reader->EvaluateMVA( \"P_BDT method\"         ) );\n",
    "\n",
    "   // Retrieve also per-event error\n",
    "   if (Use[\"PDEFoam\"]) {\n",
    "      Double_t val = reader->EvaluateMVA( \"PDEFoam method\" );\n",
    "      Double_t err = reader->GetMVAError();\n",
    "      histPDEFoam   ->Fill( val );\n",
    "      histPDEFoamErr->Fill( err );\n",
    "      if (err>1.e-50) histPDEFoamSig->Fill( val/err );\n",
    "   }\n",
    "\n",
    "   // Retrieve probability instead of MVA output\n",
    "   if (Use[\"Fisher\"])   {\n",
    "      probHistFi  ->Fill( reader->GetProba ( \"Fisher method\" ) );\n",
    "      rarityHistFi->Fill( reader->GetRarity( \"Fisher method\" ) );\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- End of event loop: Real time 0:00:00, CP time 0.020\n"
     ]
    }
   ],
   "source": [
    "sw.Stop();\n",
    "std::cout << \"--- End of event loop: \"; sw.Print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get efficiency for cuts classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Use[\"CutsGA\"]) std::cout << \"--- Efficiency for CutsGA method: \" << double(nSelCutsGA)/theTree->GetEntries()\n",
    "                             << \" (for a required signal efficiency of \" << effS << \")\" << std::endl;\n",
    "\n",
    "if (Use[\"CutsGA\"]) {\n",
    "\n",
    "   // test: retrieve cuts for particular signal efficiency\n",
    "   // CINT ignores dynamic_casts so we have to use a cuts-secific Reader function to acces the pointer\n",
    "   TMVA::MethodCuts* mcuts = reader->FindCutsMVA( \"CutsGA method\" ) ;\n",
    "\n",
    "   if (mcuts) {\n",
    "      std::vector<Double_t> cutsMin;\n",
    "      std::vector<Double_t> cutsMax;\n",
    "      mcuts->GetCuts( 0.7, cutsMin, cutsMax );\n",
    "      std::cout << \"--- -------------------------------------------------------------\" << std::endl;\n",
    "      std::cout << \"--- Retrieve cut values for signal efficiency of 0.7 from Reader\" << std::endl;\n",
    "      for (UInt_t ivar=0; ivar<cutsMin.size(); ivar++) {\n",
    "         std::cout << \"... Cut: \"\n",
    "                   << cutsMin[ivar]\n",
    "                   << \" < \\\"\"\n",
    "                   << mcuts->GetInputVar(ivar)\n",
    "                   << \"\\\" <= \"\n",
    "                   << cutsMax[ivar] << std::endl;\n",
    "      }\n",
    "      std::cout << \"--- -------------------------------------------------------------\" << std::endl;\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TFile *target  = new TFile( \"TMVApp.root\",\"RECREATE\" );\n",
    "if (Use[\"Likelihood\"   ])   histLk     ->Write();\n",
    "if (Use[\"LikelihoodD\"  ])   histLkD    ->Write();\n",
    "if (Use[\"LikelihoodPCA\"])   histLkPCA  ->Write();\n",
    "if (Use[\"LikelihoodKDE\"])   histLkKDE  ->Write();\n",
    "if (Use[\"LikelihoodMIX\"])   histLkMIX  ->Write();\n",
    "if (Use[\"PDERS\"        ])   histPD     ->Write();\n",
    "if (Use[\"PDERSD\"       ])   histPDD    ->Write();\n",
    "if (Use[\"PDERSPCA\"     ])   histPDPCA  ->Write();\n",
    "if (Use[\"KNN\"          ])   histKNN    ->Write();\n",
    "if (Use[\"HMatrix\"      ])   histHm     ->Write();\n",
    "if (Use[\"Fisher\"       ])   histFi     ->Write();\n",
    "if (Use[\"FisherG\"      ])   histFiG    ->Write();\n",
    "if (Use[\"BoostedFisher\"])   histFiB    ->Write();\n",
    "if (Use[\"LD\"           ])   histLD     ->Write();\n",
    "if (Use[\"MLP\"          ])   histNn     ->Write();\n",
    "if (Use[\"MLPBFGS\"      ])   histNnbfgs ->Write();\n",
    "if (Use[\"MLPBNN\"       ])   histNnbnn  ->Write();\n",
    "if (Use[\"CFMlpANN\"     ])   histNnC    ->Write();\n",
    "if (Use[\"TMlpANN\"      ])   histNnT    ->Write();\n",
    "if (Use[\"DNN_GPU\"]) histDnnGpu->Write();\n",
    "if (Use[\"DNN_CPU\"]) histDnnCpu->Write();\n",
    "if (Use[\"BDT\"          ])   histBdt    ->Write();\n",
    "if (Use[\"BDTG\"         ])   histBdtG   ->Write();\n",
    "if (Use[\"BDTB\"         ])   histBdtB   ->Write();\n",
    "if (Use[\"BDTD\"         ])   histBdtD   ->Write();\n",
    "if (Use[\"BDTF\"         ])   histBdtF   ->Write();\n",
    "if (Use[\"RuleFit\"      ])   histRf     ->Write();\n",
    "if (Use[\"SVM_Gauss\"    ])   histSVMG   ->Write();\n",
    "if (Use[\"SVM_Poly\"     ])   histSVMP   ->Write();\n",
    "if (Use[\"SVM_Lin\"      ])   histSVML   ->Write();\n",
    "if (Use[\"FDA_MT\"       ])   histFDAMT  ->Write();\n",
    "if (Use[\"FDA_GA\"       ])   histFDAGA  ->Write();\n",
    "if (Use[\"Category\"     ])   histCat    ->Write();\n",
    "if (Use[\"Plugin\"       ])   histPBdt   ->Write();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write also error and significance histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Use[\"PDEFoam\"]) { histPDEFoam->Write(); histPDEFoamErr->Write(); histPDEFoamSig->Write(); }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write also probability hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Created root file: \"TMVApp.root\" containing the MVA output histograms\n",
      "==> TMVAClassificationApplication is done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"Fisher\"]) { if (probHistFi != 0) probHistFi->Write(); if (rarityHistFi != 0) rarityHistFi->Write(); }\n",
    "target->Close();\n",
    "\n",
    "std::cout << \"--- Created root file: \\\"TMVApp.root\\\" containing the MVA output histograms\" << std::endl;\n",
    "\n",
    "delete reader;\n",
    "\n",
    "std::cout << \"==> TMVAClassificationApplication is done!\" << std::endl << std::endl;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
