{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  T M V A Regression\n",
    "This macro provides examples for the training and testing of the\n",
    "TMVA classifiers.\n",
    "\n",
    "As input data is used a toy-MC sample consisting of four Gaussian-distributed\n",
    "and linearly correlated input variables.\n",
    "\n",
    "The methods to be used can be switched on and off by means of booleans, or\n",
    "via the prompt command, for example:\n",
    "\n",
    "    root -l TMVARegression.C\\(\\\"LD,MLP\\\"\\)\n",
    "\n",
    "(note that the backslashes are mandatory)\n",
    "If no method given, a default set is used.\n",
    "\n",
    "The output file \"TMVAReg.root\" can be analysed with the use of dedicated\n",
    "macros (simply say: root -l <macro.C>), which can be conveniently\n",
    "invoked through a GUI that will appear at the end of the run of this macro.\n",
    "- Project   : TMVA - a Root-integrated toolkit for multivariate data analysis\n",
    "- Package   : TMVA\n",
    "- Root Macro: TMVARegression\n",
    "\n",
    "\n",
    "\n",
    "**Author:** Andreas Hoecker  \n",
    "<i><small>This notebook tutorial was automatically generated with <a href= \"https://github.com/root-project/root/blob/master/documentation/doxygen/converttonotebook.py\">ROOTBOOK-izer</a> from the macro found in the ROOT repository  on Thursday, August 29, 2019 at 03:51 AM.</small></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cpp -d\n",
    "#include <cstdlib>\n",
    "#include <iostream>\n",
    "#include <map>\n",
    "#include <string>\n",
    "\n",
    "#include \"TChain.h\"\n",
    "#include \"TFile.h\"\n",
    "#include \"TTree.h\"\n",
    "#include \"TString.h\"\n",
    "#include \"TObjString.h\"\n",
    "#include \"TSystem.h\"\n",
    "#include \"TROOT.h\"\n",
    "\n",
    "#include \"TMVA/Tools.h\"\n",
    "#include \"TMVA/Factory.h\"\n",
    "#include \"TMVA/DataLoader.h\"\n",
    "#include \"TMVA/TMVARegGui.h\"\n",
    "\n",
    "\n",
    "using namespace TMVA;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Arguments are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TString myMethodList = \"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explicit loading of the shared libtmva is done in tmvalogon.c, defined in .rootrc\n",
    " if you use your private .rootrc, or run from a different directory, please copy the\n",
    " corresponding lines from .rootrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to be processed can be given as an argument; use format:\n",
    "\n",
    "     mylinux~> root -l TMVARegression.C\\(\\\"myMethod1,myMethod2,myMethod3\\\"\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    " This loads the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default mva methods to be trained + tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std::map<std::string,int> Use;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutidimensional likelihood and nearest-neighbour methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"PDERS\"]           = 0;\n",
    "Use[\"PDEFoam\"]         = 1;\n",
    "Use[\"KNN\"]             = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"LD\"]\t\t        = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Function Discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"FDA_GA\"]          = 0;\n",
    "Use[\"FDA_MC\"]          = 0;\n",
    "Use[\"FDA_MT\"]          = 0;\n",
    "Use[\"FDA_GAMT\"]        = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"MLP\"]             = 0;\n",
    "#ifdef R__HAS_TMVACPU\n",
    "Use[\"DNN_CPU\"] = 1;\n",
    "#else\n",
    "Use[\"DNN_CPU\"] = 0;\n",
    "#endif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"SVM\"]             = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Use[\"BDT\"]             = 0;\n",
    "Use[\"BDTG\"]            = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Start TMVARegression\n"
     ]
    }
   ],
   "source": [
    "std::cout << std::endl;\n",
    "std::cout << \"==> Start TMVARegression\" << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select methods (don't look at this code - not of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (myMethodList != \"\") {\n",
    "   for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) it->second = 0;\n",
    "\n",
    "   std::vector<TString> mlist = gTools().SplitString( myMethodList, ',' );\n",
    "   for (UInt_t i=0; i<mlist.size(); i++) {\n",
    "      std::string regMethod(mlist[i].Data());\n",
    "\n",
    "      if (Use.find(regMethod) == Use.end()) {\n",
    "         std::cout << \"Method \\\"\" << regMethod << \"\\\" not known in TMVA under this name. Choose among the following:\" << std::endl;\n",
    "         for (std::map<std::string,int>::iterator it = Use.begin(); it != Use.end(); it++) std::cout << it->first << \" \";\n",
    "         std::cout << std::endl;\n",
    "         return;\n",
    "      }\n",
    "      Use[regMethod] = 1;\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the preparation phase begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new root output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TString outfileName( \"TMVAReg.root\" );\n",
    "TFile* outputFile = TFile::Open( outfileName, \"RECREATE\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the factory object. later you can choose the methods\n",
    " whose performance you'd like to investigate. The factory will\n",
    " then run the performance analysis for you.\n",
    "\n",
    " The first argument is the base of the name of all the\n",
    " weightfiles in the directory weight/\n",
    "\n",
    " The second argument is the output file for the training results\n",
    " All TMVA output can be suppressed by removing the \"!\" (not) in\n",
    " front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TMVA::Factory *factory = new TMVA::Factory( \"TMVARegression\", outputFile,\n",
    "                                            \"!V:!Silent:Color:!DrawProgressBar:AnalysisType=Regression\" );\n",
    "\n",
    "\n",
    "TMVA::DataLoader *dataloader=new TMVA::DataLoader(\"dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to modify default settings\n",
    " (please check \"src/Config.h\" to see all available global options)\n",
    "\n",
    "     (TMVA::gConfig().GetVariablePlotting()).fTimesRMS = 8.0;\n",
    "     (TMVA::gConfig().GetIONames()).fWeightFileDir = \"myWeightDirectory\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the input variables that shall be used for the mva training\n",
    " note that you may also use variable expressions, such as: \"3*var1/var2*abs(var3)\"\n",
    " [all types of expressions that can also be parsed by TTree::Draw( \"expression\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader->AddVariable( \"var1\", \"Variable 1\", \"units\", 'F' );\n",
    "dataloader->AddVariable( \"var2\", \"Variable 2\", \"units\", 'F' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add so-called \"spectator variables\", which are not used in the mva training,\n",
    " but will appear in the final \"TestTree\" produced by TMVA. This TestTree will contain the\n",
    " input variables, the response values of all trained MVAs, and the spectator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader->AddSpectator( \"spec1:=var1*2\",  \"Spectator 1\", \"units\", 'F' );\n",
    "dataloader->AddSpectator( \"spec2:=var1*3\",  \"Spectator 2\", \"units\", 'F' );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the variable carrying the regression target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader->AddTarget( \"fvalue\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to declare additional targets for multi-dimensional regression, ie:\n",
    "     factory->AddTarget( \"fvalue2\" );\n",
    " BUT: this is currently ONLY implemented for MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read training and test data (see tmvaclassification for reading ascii files)\n",
    " load the signal and background event samples from ROOT trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TMVARegression           : Using input file: ./files/tmva_reg_example.root\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TFile::OpenFromCache>: using local cache copy of http://root.cern.ch/files/tmva_reg_example.root [./files/tmva_reg_example.root]\n"
     ]
    }
   ],
   "source": [
    "TFile *input(0);\n",
    "TString fname = \"./tmva_reg_example.root\";\n",
    "if (!gSystem->AccessPathName( fname )) {\n",
    "   input = TFile::Open( fname ); // check if file in local directory exists\n",
    "}\n",
    "else {\n",
    "   TFile::SetCacheFileDir(\".\");\n",
    "   input = TFile::Open(\"http://root.cern.ch/files/tmva_reg_example.root\", \"CACHEREAD\"); // if not: download from ROOT server\n",
    "}\n",
    "if (!input) {\n",
    "   std::cout << \"ERROR: could not open data file\" << std::endl;\n",
    "   exit(1);\n",
    "}\n",
    "std::cout << \"--- TMVARegression           : Using input file: \" << input->GetName() << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TTree *regTree = (TTree*)input->Get(\"TreeR\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global event weights per tree (see below for setting event-wise weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Double_t regWeight  = 1.0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add an arbitrary number of regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Regression\"\n",
      "                         : Add Tree TreeR of type Regression with 10000 events\n"
     ]
    }
   ],
   "source": [
    "dataloader->AddRegressionTree( regTree, regWeight );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would set individual event weights (the variables defined in the\n",
    " expression need to exist in the original TTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader->SetWeightExpression( \"var1\", \"Regression\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply additional cuts on the signal and background samples (can be different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TCut mycut = \"\"; // for example: TCut mycut = \"abs(var1)<0.5 && abs(var2-0.5)<1\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell the dataloader to use all remaining events in the trees after training for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : Dataset[dataset] : Class index : 0  name : Regression\n"
     ]
    }
   ],
   "source": [
    "dataloader->PrepareTrainingAndTestTree( mycut,\n",
    "                                      \"nTrain_Regression=1000:nTest_Regression=0:SplitMode=Random:NormMode=NumEvents:!V\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     dataloader->PrepareTrainingAndTestTree( mycut,\n",
    "            \"nTrain_Regression=0:nTest_Regression=0:SplitMode=Random:NormMode=NumEvents:!V\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no numbers of events are given, half of the events in the tree are used\n",
    " for training, and the other half for testing:\n",
    "\n",
    "     dataloader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book mva methods\n",
    "\n",
    " Please lookup the various method configuration options in the corresponding cxx files, eg:\n",
    " src/MethoCuts.cxx, etc, or here: http://tmva.sourceforge.net/optionRef.html\n",
    " it is possible to preset ranges in the option string in which the cut optimisation should be done:\n",
    " \"...:CutRangeMin[2]=-1:CutRangeMax[2]=1\"...\", where [2] is the third input variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pde - rs method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Use[\"PDERS\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kPDERS, \"PDERS\",\n",
    "                        \"!H:!V:NormTree=T:VolumeRangeMode=Adaptive:KernelEstimator=Gauss:GaussSigma=0.3:NEventsMin=40:NEventsMax=60:VarTransform=None\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the options strings for the minmax and rms methods, respectively:\n",
    "\n",
    "      \"!H:!V:VolumeRangeMode=MinMax:DeltaFrac=0.2:KernelEstimator=Gauss:GaussSigma=0.3\" );\n",
    "      \"!H:!V:VolumeRangeMode=RMS:DeltaFrac=3:KernelEstimator=Gauss:GaussSigma=0.3\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mPDEFoam\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Regression -- training events            : 1000\n",
      "                         : Regression -- testing events             : 9000\n",
      "                         : Regression -- training and testing events: 10000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Regression):\n",
      "                         : ------------------------\n",
      "                         :             var1    var2\n",
      "                         :    var1:  +1.000  +0.006\n",
      "                         :    var2:  +0.006  +1.000\n",
      "                         : ------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"PDEFoam\"])\n",
    "    factory->BookMethod( dataloader,  TMVA::Types::kPDEFoam, \"PDEFoam\",\n",
    "\t\t\t    \"!H:!V:MultiTargetRegression=F:TargetSelection=Mpv:TailCut=0.001:VolFrac=0.0666:nActiveCells=500:nSampl=2000:nBin=5:Compress=T:Kernel=None:Nmin=10:VarTransform=None\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbour classifier (knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mKNN\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"KNN\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kKNN, \"KNN\",\n",
    "                        \"nkNN=20:ScaleFrac=0.8:SigmaFact=1.0:Kernel=Gaus:UseKernel=F:UseWeight=T:!Trim\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLD\u001b[0m\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "if (Use[\"LD\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kLD, \"LD\",\n",
    "                        \"!H:!V:VarTransform=None\" );\n",
    "\n",
    "\t// Function discrimination analysis (FDA) -- test of various fitters - the recommended one is Minuit (or GA or SA)\n",
    "if (Use[\"FDA_MC\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kFDA, \"FDA_MC\",\n",
    "                       \"!H:!V:Formula=(0)+(1)*x0+(2)*x1:ParRanges=(-100,100);(-100,100);(-100,100):FitMethod=MC:SampleSize=100000:Sigma=0.1:VarTransform=D\" );\n",
    "\n",
    "if (Use[\"FDA_GA\"]) // can also use Simulated Annealing (SA) algorithm (see Cuts_SA options) .. the formula of this example is good for parabolas\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kFDA, \"FDA_GA\",\n",
    "                        \"!H:!V:Formula=(0)+(1)*x0+(2)*x1:ParRanges=(-100,100);(-100,100);(-100,100):FitMethod=GA:PopSize=100:Cycles=3:Steps=30:Trim=True:SaveBestGen=1:VarTransform=Norm\" );\n",
    "\n",
    "if (Use[\"FDA_MT\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kFDA, \"FDA_MT\",\n",
    "                        \"!H:!V:Formula=(0)+(1)*x0+(2)*x1:ParRanges=(-100,100);(-100,100);(-100,100);(-10,10):FitMethod=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=2:UseImprove:UseMinos:SetBatch\" );\n",
    "\n",
    "if (Use[\"FDA_GAMT\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kFDA, \"FDA_GAMT\",\n",
    "                        \"!H:!V:Formula=(0)+(1)*x0+(2)*x1:ParRanges=(-100,100);(-100,100);(-100,100):FitMethod=GA:Converger=MINUIT:ErrorLevel=1:PrintLevel=-1:FitStrategy=0:!UseImprove:!UseMinos:SetBatch:Cycles=1:PopSize=5:Steps=5:Trim\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network (mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDNN_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=SUMOFSQUARES:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Architecture=CPU:Layout=TANH|50,Layout=TANH|50,Layout=TANH|50,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=10,WeightDecay=0.01,Regularization=NONE,DropConfig=0.2+0.2+0.2+0.,DropRepetitions=2|LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=L2,DropConfig=0.1+0.1+0.1,DropRepetitions=1|LearningRate=1e-4,Momentum=0.3,Repetitions=1,ConvergenceSteps=10,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=NONE\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=SUMOFSQUARES:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Architecture=CPU:Layout=TANH|50,Layout=TANH|50,Layout=TANH|50,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=10,WeightDecay=0.01,Regularization=NONE,DropConfig=0.2+0.2+0.2+0.,DropRepetitions=2|LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=L2,DropConfig=0.1+0.1+0.1,DropRepetitions=1|LearningRate=1e-4,Momentum=0.3,Repetitions=1,ConvergenceSteps=10,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=NONE\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     Layout: \"TANH|50,Layout=TANH|50,Layout=TANH|50,LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"SUMOFSQUARES\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=10,WeightDecay=0.01,Regularization=NONE,DropConfig=0.2+0.2+0.2+0.,DropRepetitions=2|LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=L2,DropConfig=0.1+0.1+0.1,DropRepetitions=1|LearningRate=1e-4,Momentum=0.3,Repetitions=1,ConvergenceSteps=10,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=NONE\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "DNN_CPU                  : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:   0.012586     1.0260   [    -3.3377     5.7307 ]\n",
      "                         :     var2:  0.0043504     1.0383   [    -4.5564     5.7307 ]\n",
      "                         :   fvalue:     165.93     84.643   [     2.0973     391.01 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Parsed Training DNN string LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=10,WeightDecay=0.01,Regularization=NONE,DropConfig=0.2+0.2+0.2+0.,DropRepetitions=2|LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=L2,DropConfig=0.1+0.1+0.1,DropRepetitions=1|LearningRate=1e-4,Momentum=0.3,Repetitions=1,ConvergenceSteps=10,BatchSize=50,TestRepetitions=5,WeightDecay=0.01,Regularization=NONE\n",
      "STring has size 3\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"MLP\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kMLP, \"MLP\", \"!H:!V:VarTransform=Norm:NeuronType=tanh:NCycles=20000:HiddenLayers=N+20:TestRate=6:TrainingMethod=BFGS:Sampling=0.3:SamplingEpoch=0.8:ConvergenceImprove=1e-6:ConvergenceTests=15:!UseRegulator\" );\n",
    "\n",
    "if (Use[\"DNN_CPU\"]) {\n",
    "   /*\n",
    "       TString layoutString (\"Layout=TANH|(N+100)*2,LINEAR\");\n",
    "       TString layoutString (\"Layout=SOFTSIGN|100,SOFTSIGN|50,SOFTSIGN|20,LINEAR\");\n",
    "       TString layoutString (\"Layout=RELU|300,RELU|100,RELU|30,RELU|10,LINEAR\");\n",
    "       TString layoutString (\"Layout=SOFTSIGN|50,SOFTSIGN|30,SOFTSIGN|20,SOFTSIGN|10,LINEAR\");\n",
    "       TString layoutString (\"Layout=TANH|50,TANH|30,TANH|20,TANH|10,LINEAR\");\n",
    "       TString layoutString (\"Layout=SOFTSIGN|50,SOFTSIGN|20,LINEAR\");\n",
    "       TString layoutString (\"Layout=TANH|100,TANH|30,LINEAR\");\n",
    "    */\n",
    "   TString layoutString(\"Layout=TANH|50,Layout=TANH|50,Layout=TANH|50,LINEAR\");\n",
    "\n",
    "   TString training0(\"LearningRate=1e-2,Momentum=0.5,Repetitions=1,ConvergenceSteps=20,BatchSize=50,\"\n",
    "                     \"TestRepetitions=10,WeightDecay=0.01,Regularization=NONE,DropConfig=0.2+0.2+0.2+0.,\"\n",
    "                     \"DropRepetitions=2\");\n",
    "   TString training1(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=50,\"\n",
    "                     \"TestRepetitions=5,WeightDecay=0.01,Regularization=L2,DropConfig=0.1+0.1+0.1,DropRepetitions=\"\n",
    "                     \"1\");\n",
    "   TString training2(\"LearningRate=1e-4,Momentum=0.3,Repetitions=1,ConvergenceSteps=10,BatchSize=50,\"\n",
    "                     \"TestRepetitions=5,WeightDecay=0.01,Regularization=NONE\");\n",
    "\n",
    "   TString trainingStrategyString(\"TrainingStrategy=\");\n",
    "   trainingStrategyString += training0 + \"|\" + training1 + \"|\" + training2;\n",
    "\n",
    "   //       TString trainingStrategyString\n",
    "   //       (\"TrainingStrategy=LearningRate=1e-1,Momentum=0.3,Repetitions=3,ConvergenceSteps=20,BatchSize=30,TestRepetitions=7,WeightDecay=0.0,L1=false,DropFraction=0.0,DropRepetitions=5\");\n",
    "\n",
    "   TString nnOptions(\n",
    "      \"!H:V:ErrorStrategy=SUMOFSQUARES:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Architecture=CPU\");\n",
    "   //       TString nnOptions (\"!H:V:VarTransform=Normalize:ErrorStrategy=CHECKGRADIENTS\");\n",
    "   nnOptions.Append(\":\");\n",
    "   nnOptions.Append(layoutString);\n",
    "   nnOptions.Append(\":\");\n",
    "   nnOptions.Append(trainingStrategyString);\n",
    "\n",
    "   factory->BookMethod(dataloader, TMVA::Types::kDNN, \"DNN_CPU\", nnOptions); // NN\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Use[\"SVM\"])\n",
    "   factory->BookMethod( dataloader,  TMVA::Types::kSVM, \"SVM\", \"Gamma=0.25:Tol=0.001:VarTransform=Norm\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosted decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDTG\u001b[0m\n",
      "                         : \n",
      "<WARNING>                : Value for option maxdepth was previously set to 3\n",
      "                         : the option NegWeightTreatment=InverseBoostNegWeights does not exist for BoostType=Grad\n",
      "                         : --> change to new default NegWeightTreatment=Pray\n"
     ]
    }
   ],
   "source": [
    "if (Use[\"BDT\"])\n",
    "  factory->BookMethod( dataloader,  TMVA::Types::kBDT, \"BDT\",\n",
    "                        \"!H:!V:NTrees=100:MinNodeSize=1.0%:BoostType=AdaBoostR2:SeparationType=RegressionVariance:nCuts=20:PruneMethod=CostComplexity:PruneStrength=30\" );\n",
    "\n",
    "if (Use[\"BDTG\"])\n",
    "  factory->BookMethod( dataloader,  TMVA::Types::kBDT, \"BDTG\",\n",
    "                        \"!H:!V:NTrees=2000::BoostType=Grad:Shrinkage=0.1:UseBaggedBoost:BaggedSampleFraction=0.5:nCuts=20:MaxDepth=3:MaxDepth=4\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can tell the factory to train, test, and evaluate the mvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train mvas using the set of training events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:     3.3759     1.1674   [  0.0058046     4.9975 ]\n",
      "                         :     var2:     2.4823     1.4587   [  0.0032142     4.9971 ]\n",
      "                         :   fvalue:     165.93     84.643   [     2.0973     391.01 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : --------------------------------------------\n",
      "                         : Rank : Variable  : |Correlation with target|\n",
      "                         : --------------------------------------------\n",
      "                         :    1 : var2      : 7.636e-01\n",
      "                         :    2 : var1      : 5.936e-01\n",
      "                         : --------------------------------------------\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Mutual information\n",
      "                         : -------------------------------------\n",
      "                         :    1 : var2      : 2.315e+00\n",
      "                         :    2 : var1      : 1.882e+00\n",
      "                         : -------------------------------------\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ------------------------------------\n",
      "                         : Rank : Variable  : Correlation Ratio\n",
      "                         : ------------------------------------\n",
      "                         :    1 : var1      : 6.545e+00\n",
      "                         :    2 : var2      : 2.414e+00\n",
      "                         : ------------------------------------\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ----------------------------------------\n",
      "                         : Rank : Variable  : Correlation Ratio (T)\n",
      "                         : ----------------------------------------\n",
      "                         :    1 : var2      : 8.189e-01\n",
      "                         :    2 : var1      : 3.128e-01\n",
      "                         : ----------------------------------------\n",
      "Factory                  : Train method: PDEFoam for Regression\n",
      "                         : \n",
      "                         : Build mono target regression foam\n",
      "                         : Elapsed time: 0.589 sec                                 \n",
      "                         : Elapsed time for training with 1000 events: 0.596 sec         \n",
      "                         : Dataset[dataset] : Create results for training\n",
      "                         : Dataset[dataset] : Evaluation of PDEFoam on training sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 1000 events: 0.0041 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVARegression_PDEFoam.weights.xml\u001b[0m\n",
      "                         : writing foam MonoTargetRegressionFoam to file\n",
      "                         : Foams written to file: \u001b[0;36mdataset/weights/TMVARegression_PDEFoam.weights_foams.root\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: KNN for Regression\n",
      "                         : \n",
      "KNN                      : <Train> start...\n",
      "                         : Reading 1000 events\n",
      "                         : Number of signal events 1000\n",
      "                         : Number of background events 0\n",
      "                         : Creating kd-tree with 1000 events\n",
      "                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)\n",
      "ModulekNN                : Optimizing tree for 2 variables with 1000 values\n",
      "                         : <Fill> Class 1 has     1000 events\n",
      "                         : Elapsed time for training with 1000 events: 0.00166 sec         \n",
      "                         : Dataset[dataset] : Create results for training\n",
      "                         : Dataset[dataset] : Evaluation of KNN on training sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 1000 events: 0.0078 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVARegression_KNN.weights.xml\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: LD for Regression\n",
      "                         : \n",
      "LD                       : Results for LD coefficients:\n",
      "                         : -----------------------\n",
      "                         : Variable:  Coefficient:\n",
      "                         : -----------------------\n",
      "                         :     var1:      +42.509\n",
      "                         :     var2:      +44.738\n",
      "                         : (offset):      -88.627\n",
      "                         : -----------------------\n",
      "                         : Elapsed time for training with 1000 events: 0.000371 sec         \n",
      "                         : Dataset[dataset] : Create results for training\n",
      "                         : Dataset[dataset] : Evaluation of LD on training sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 1000 events: 0.00029 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVARegression_LD.weights.xml\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DNN_CPU for Regression\n",
      "                         : \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:   0.012586     1.0260   [    -3.3377     5.7307 ]\n",
      "                         :     var2:  0.0043504     1.0383   [    -4.5564     5.7307 ]\n",
      "                         :   fvalue:     165.93     84.643   [     2.0973     391.01 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Start of neural network training on CPU.\n",
      "                         : \n",
      "                         : Training phase 1 of 3:\n",
      "                         :      Epoch |   Train Err.  Test  Err.     GFLOP/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :         10 |       1852.8     1318.08     7.92271           0\n",
      "                         :         20 |      2237.36     1903.97      8.5522          10\n",
      "                         :         30 |      1266.38     1716.13     8.64622          20\n",
      "                         : \n",
      "                         : Training phase 2 of 3:\n",
      "                         :      Epoch |   Train Err.  Test  Err.     GFLOP/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          5 |      4616.79     1322.98     8.88183           0\n",
      "                         :         10 |      5482.98     1362.98     8.86084           5\n",
      "                         :         15 |      4339.24     950.572     8.81139           0\n",
      "                         :         20 |      4064.82     732.863     8.29869           0\n",
      "                         :         25 |      4186.87     946.752     8.78876           5\n",
      "                         :         30 |      3904.96     644.659     8.99931           0\n",
      "                         :         35 |      3940.94     638.022     8.73119           0\n",
      "                         :         40 |      3838.33     750.872     8.92484           5\n",
      "                         :         45 |      3833.79     605.421      9.4566           0\n",
      "                         :         50 |      3677.92     563.868     9.70466           0\n",
      "                         :         55 |      4054.49     856.212     9.16469           5\n",
      "                         :         60 |       3798.7     595.662     9.51314          10\n",
      "                         :         65 |      3863.18     709.034      9.4949          15\n",
      "                         :         70 |      4464.92     1111.08     9.20454          20\n",
      "                         : \n",
      "                         : Training phase 3 of 3:\n",
      "                         :      Epoch |   Train Err.  Test  Err.     GFLOP/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          5 |      1332.08     1040.62     13.4353           0\n",
      "                         :         10 |      1324.73     1012.16      12.976           0\n",
      "                         :         15 |      1298.53      983.33     14.0941           0\n",
      "                         :         20 |      1290.45       971.5     13.6189           0\n",
      "                         :         25 |      1289.43     970.429     12.5931           0\n",
      "                         :         30 |      1286.07     970.603     12.6193           5\n",
      "                         :         35 |      1285.56     970.631     12.6199          10\n",
      "                         : \n",
      "                         : Elapsed time for training with 1000 events: 0.375 sec         \n",
      "                         : Dataset[dataset] : Create results for training\n",
      "                         : Dataset[dataset] : Evaluation of DNN_CPU on training sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 1000 events: 0.021 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVARegression_DNN_CPU.weights.xml\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: BDTG for Regression\n",
      "                         : \n",
      "                         : Regression Loss Function: Huber\n",
      "                         : Training 2000 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 1000 events: 1.78 sec         \n",
      "                         : Dataset[dataset] : Create results for training\n",
      "                         : Dataset[dataset] : Evaluation of BDTG on training sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 1000 events: 0.275 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVARegression_BDTG.weights.xml\u001b[0m\n",
      "                         : TMVAReg.root:/dataset/Method_BDT/BDTG\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVARegression_PDEFoam.weights.xml\u001b[0m\n",
      "                         : Read foams from file: \u001b[0;36mdataset/weights/TMVARegression_PDEFoam.weights_foams.root\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVARegression_KNN.weights.xml\u001b[0m\n",
      "                         : Creating kd-tree with 1000 events\n",
      "                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)\n",
      "ModulekNN                : Optimizing tree for 2 variables with 1000 values\n",
      "                         : <Fill> Class 1 has     1000 events\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVARegression_LD.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVARegression_DNN_CPU.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVARegression_BDTG.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory->TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all mvas using the set of test events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: PDEFoam for Regression performance\n",
      "                         : \n",
      "                         : Dataset[dataset] : Create results for testing\n",
      "                         : Dataset[dataset] : Evaluation of PDEFoam on testing sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 9000 events: 0.0448 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "Factory                  : Test method: KNN for Regression performance\n",
      "                         : \n",
      "                         : Dataset[dataset] : Create results for testing\n",
      "                         : Dataset[dataset] : Evaluation of KNN on testing sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 9000 events: 0.0881 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "Factory                  : Test method: LD for Regression performance\n",
      "                         : \n",
      "                         : Dataset[dataset] : Create results for testing\n",
      "                         : Dataset[dataset] : Evaluation of LD on testing sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 9000 events: 0.00267 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "Factory                  : Test method: DNN_CPU for Regression performance\n",
      "                         : \n",
      "                         : Dataset[dataset] : Create results for testing\n",
      "                         : Dataset[dataset] : Evaluation of DNN_CPU on testing sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 9000 events: 0.188 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n",
      "Factory                  : Test method: BDTG for Regression performance\n",
      "                         : \n",
      "                         : Dataset[dataset] : Create results for testing\n",
      "                         : Dataset[dataset] : Evaluation of BDTG on testing sample\n",
      "                         : Dataset[dataset] : Elapsed time for evaluation of 9000 events: 1.81 sec       \n",
      "                         : Create variable histograms\n",
      "                         : Create regression target histograms\n",
      "                         : Create regression average deviation\n",
      "                         : Results created\n"
     ]
    }
   ],
   "source": [
    "factory->TestAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and compare performance of all configured mvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "                         : Evaluate regression method: PDEFoam\n",
      "                         : TestRegression (testing)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 9000 events: 0.0415 sec       \n",
      "                         : TestRegression (training)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 1000 events: 0.00492 sec       \n",
      "TFHandler_PDEFoam        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:     3.3352     1.1893   [ 0.00020069     5.0000 ]\n",
      "                         :     var2:     2.4860     1.4342   [ 0.00071490     5.0000 ]\n",
      "                         :   fvalue:     163.91     83.651   [     1.6186     394.84 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Evaluate regression method: KNN\n",
      "                         : TestRegression (testing)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 9000 events: 0.0892 sec       \n",
      "                         : TestRegression (training)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 1000 events: 0.00876 sec       \n",
      "TFHandler_KNN            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:     3.3352     1.1893   [ 0.00020069     5.0000 ]\n",
      "                         :     var2:     2.4860     1.4342   [ 0.00071490     5.0000 ]\n",
      "                         :   fvalue:     163.91     83.651   [     1.6186     394.84 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Evaluate regression method: LD\n",
      "                         : TestRegression (testing)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 9000 events: 0.00414 sec       \n",
      "                         : TestRegression (training)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 1000 events: 0.000457 sec       \n",
      "TFHandler_LD             : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:     3.3352     1.1893   [ 0.00020069     5.0000 ]\n",
      "                         :     var2:     2.4860     1.4342   [ 0.00071490     5.0000 ]\n",
      "                         :   fvalue:     163.91     83.651   [     1.6186     394.84 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Evaluate regression method: DNN_CPU\n",
      "                         : TestRegression (testing)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 9000 events: 0.173 sec       \n",
      "                         : TestRegression (training)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 1000 events: 0.0179 sec       \n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:  -0.027278     1.0264   [    -3.3694     5.7307 ]\n",
      "                         :     var2:  0.0056047    0.98632   [    -5.7307     5.7307 ]\n",
      "                         :   fvalue:     163.91     83.651   [     1.6186     394.84 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:  -0.027278     1.0264   [    -3.3694     5.7307 ]\n",
      "                         :     var2:  0.0056047    0.98632   [    -5.7307     5.7307 ]\n",
      "                         :   fvalue:     163.91     83.651   [     1.6186     394.84 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Evaluate regression method: BDTG\n",
      "                         : TestRegression (testing)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 9000 events: 1.82 sec       \n",
      "                         : TestRegression (training)\n",
      "                         : Calculate regression for all events\n",
      "                         : Elapsed time for evaluation of 1000 events: 0.204 sec       \n",
      "TFHandler_BDTG           : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var1:     3.3352     1.1893   [ 0.00020069     5.0000 ]\n",
      "                         :     var2:     2.4860     1.4342   [ 0.00071490     5.0000 ]\n",
      "                         :   fvalue:     163.91     83.651   [     1.6186     394.84 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by smallest RMS on test sample:\n",
      "                         : (\"Bias\" quotes the mean deviation of the regression from true target.\n",
      "                         :  \"MutInf\" is the \"Mutual Information\" between regression and target.\n",
      "                         :  Indicated by \"_T\" are the corresponding \"truncated\" quantities ob-\n",
      "                         :  tained when removing events deviating more than 2sigma from average.)\n",
      "                         : --------------------------------------------------------------------------------------------------\n",
      "                         : --------------------------------------------------------------------------------------------------\n",
      "                         : dataset              BDTG           :   0.0707    0.102     2.45     1.95  |  3.100  3.175\n",
      "                         : dataset              KNN            :   -0.237    0.578     5.17     3.44  |  2.898  2.939\n",
      "                         : dataset              PDEFoam        :    0.106  -0.0677     9.22     7.74  |  2.283  2.375\n",
      "                         : dataset              LD             :    0.461     2.22     19.6     17.6  |  1.985  1.979\n",
      "                         : dataset              DNN_CPU        :     1.96     5.89     34.7     27.9  |  1.326  1.380\n",
      "                         : --------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by smallest RMS on training sample:\n",
      "                         : (overtraining check)\n",
      "                         : --------------------------------------------------------------------------------------------------\n",
      "                         : DataSet Name:         MVA Method:        <Bias>   <Bias_T>    RMS    RMS_T  |  MutInf MutInf_T\n",
      "                         : --------------------------------------------------------------------------------------------------\n",
      "                         : dataset              BDTG           :   0.0597   0.0107    0.566    0.293  |  3.441  3.466\n",
      "                         : dataset              KNN            :   -0.425    0.423     5.19     3.54  |  3.006  3.034\n",
      "                         : dataset              PDEFoam        : 8.35e-07    0.106     8.04     6.57  |  2.488  2.579\n",
      "                         : dataset              LD             :-1.03e-06     1.54     20.1     18.5  |  2.134  2.153\n",
      "                         : dataset              DNN_CPU        :    0.989     5.63     35.0     27.8  |  1.381  1.420\n",
      "                         : --------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 9000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 1000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory->EvaluateAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Wrote root file: TMVAReg.root\n",
      "==> TMVARegression is done!\n"
     ]
    }
   ],
   "source": [
    "outputFile->Close();\n",
    "\n",
    "std::cout << \"==> Wrote root file: \" << outputFile->GetName() << std::endl;\n",
    "std::cout << \"==> TMVARegression is done!\" << std::endl;\n",
    "\n",
    "delete factory;\n",
    "delete dataloader;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the gui for the root macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (!gROOT->IsBatch()) TMVA::TMVARegGui( outfileName );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
