<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>ROOT: TMVA::DNN::TAdagrad&lt; Architecture_t, Layer_t, DeepNet_t &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="./mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ROOT.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table bgcolor="#346295" cellspacing="0" cellpadding="0">
  <tr>
    <td> <img style="height:90px" alt="Logo" src="rootlogo.gif"/> </td>
    <td valign="middle" style="color: #FFFFFF" nowrap="nowrap"><font size="6">ROOT</font> &#160; 6.18/03 <br> Reference Guide </td>
    <td style="width:100%"> </td>
  </tr>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceTMVA.html">TMVA</a></li><li class="navelem"><a class="el" href="namespaceTMVA_1_1DNN.html">DNN</a></li><li class="navelem"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TAdagrad</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="classTMVA_1_1DNN_1_1TAdagrad-members.html">List of all members</a> &#124;
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classTMVA_1_1DNN_1_1TAdagrad-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">TMVA::DNN::TAdagrad&lt; Architecture_t, Layer_t, DeepNet_t &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader"> </h2>
<div class="textblock"><h3>template&lt;typename Architecture_t, typename Layer_t = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt;<br />
class TMVA::DNN::TAdagrad&lt; Architecture_t, Layer_t, DeepNet_t &gt;</h3>

<p>Adagrad Optimizer class. </p>
<p>This class represents the Adagrad Optimizer. </p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00044">44</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>
</div><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a66360d470ec94f7c2ffde94b92b413f2"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> = typename Architecture_t::Matrix_t</td></tr>
<tr class="separator:a66360d470ec94f7c2ffde94b92b413f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a690a25c9359430be27144af355e65c30"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a> = typename Architecture_t::Scalar_t</td></tr>
<tr class="separator:a690a25c9359430be27144af355e65c30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_classTMVA_1_1DNN_1_1VOptimizer"><td colspan="2" onclick="javascript:toggleInherit('pub_types_classTMVA_1_1DNN_1_1VOptimizer')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html">TMVA::DNN::VOptimizer&lt; Architecture_t, Layer_t, DeepNet_t &gt;</a></td></tr>
<tr class="memitem:aed55b7e7c5e6f39825dd80aab63af30d inherit pub_types_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#aed55b7e7c5e6f39825dd80aab63af30d">Matrix_t</a> = typename Architecture_t::Matrix_t</td></tr>
<tr class="separator:aed55b7e7c5e6f39825dd80aab63af30d inherit pub_types_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab191675d4d7b96fa1ed943f58046fc6b inherit pub_types_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#ab191675d4d7b96fa1ed943f58046fc6b">Scalar_t</a> = typename Architecture_t::Scalar_t</td></tr>
<tr class="separator:ab191675d4d7b96fa1ed943f58046fc6b inherit pub_types_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a5a0153c4e30b3b6c99b78fc624614a04"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a5a0153c4e30b3b6c99b78fc624614a04">TAdagrad</a> (DeepNet_t &amp;deepNet, <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a> learningRate=0.01, <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a> <a class="el" href="triangle_8c.html#a92508a9fbb1db78d0bbedbf68cf93d1b">epsilon</a>=1e-8)</td></tr>
<tr class="memdesc:a5a0153c4e30b3b6c99b78fc624614a04"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="#a5a0153c4e30b3b6c99b78fc624614a04">More...</a><br /></td></tr>
<tr class="separator:a5a0153c4e30b3b6c99b78fc624614a04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6a3f83ac95acd4c148c47c1ab9c5c61"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#ad6a3f83ac95acd4c148c47c1ab9c5c61">~TAdagrad</a> ()=default</td></tr>
<tr class="memdesc:ad6a3f83ac95acd4c148c47c1ab9c5c61"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="#ad6a3f83ac95acd4c148c47c1ab9c5c61">More...</a><br /></td></tr>
<tr class="separator:ad6a3f83ac95acd4c148c47c1ab9c5c61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a428996d1fd34970fac6e4c7d3bc4357c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a428996d1fd34970fac6e4c7d3bc4357c">GetEpsilon</a> () const</td></tr>
<tr class="memdesc:a428996d1fd34970fac6e4c7d3bc4357c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Getters.  <a href="#a428996d1fd34970fac6e4c7d3bc4357c">More...</a><br /></td></tr>
<tr class="separator:a428996d1fd34970fac6e4c7d3bc4357c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1ea31869f71247b33ae840387c7d883"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#ab1ea31869f71247b33ae840387c7d883">GetPastSquaredBiasGradients</a> ()</td></tr>
<tr class="separator:ab1ea31869f71247b33ae840387c7d883"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3748d2958e9729385b5524006683f7d3"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a3748d2958e9729385b5524006683f7d3">GetPastSquaredBiasGradientsAt</a> (size_t i)</td></tr>
<tr class="separator:a3748d2958e9729385b5524006683f7d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab72c4b72159a98531c0c11b142b263d1"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#ab72c4b72159a98531c0c11b142b263d1">GetPastSquaredWeightGradients</a> ()</td></tr>
<tr class="separator:ab72c4b72159a98531c0c11b142b263d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa93751d0e89bcdf2e85ead11ecd58205"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#aa93751d0e89bcdf2e85ead11ecd58205">GetPastSquaredWeightGradientsAt</a> (size_t i)</td></tr>
<tr class="separator:aa93751d0e89bcdf2e85ead11ecd58205"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classTMVA_1_1DNN_1_1VOptimizer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html">TMVA::DNN::VOptimizer&lt; Architecture_t, Layer_t, DeepNet_t &gt;</a></td></tr>
<tr class="memitem:ae3576ab2a2e83919abd1f9d248491c3d inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#ae3576ab2a2e83919abd1f9d248491c3d">VOptimizer</a> (<a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#ab191675d4d7b96fa1ed943f58046fc6b">Scalar_t</a> learningRate, DeepNet_t &amp;deepNet)</td></tr>
<tr class="memdesc:ae3576ab2a2e83919abd1f9d248491c3d inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#ae3576ab2a2e83919abd1f9d248491c3d">More...</a><br /></td></tr>
<tr class="separator:ae3576ab2a2e83919abd1f9d248491c3d inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ccdaccb843851be81538b8dfc403993 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a2ccdaccb843851be81538b8dfc403993">~VOptimizer</a> ()=default</td></tr>
<tr class="memdesc:a2ccdaccb843851be81538b8dfc403993 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Virtual Destructor.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#a2ccdaccb843851be81538b8dfc403993">More...</a><br /></td></tr>
<tr class="separator:a2ccdaccb843851be81538b8dfc403993 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe0451eaea6251953d6f8b1c8fbde152 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#abe0451eaea6251953d6f8b1c8fbde152">GetGlobalStep</a> () const</td></tr>
<tr class="separator:abe0451eaea6251953d6f8b1c8fbde152 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac79c4fb2cd950b85f5e4db2d7b90cda7 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">Layer_t *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#ac79c4fb2cd950b85f5e4db2d7b90cda7">GetLayerAt</a> (size_t i)</td></tr>
<tr class="separator:ac79c4fb2cd950b85f5e4db2d7b90cda7 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1844f8007b2484467987ecac972facfe inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">std::vector&lt; Layer_t * &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a1844f8007b2484467987ecac972facfe">GetLayers</a> ()</td></tr>
<tr class="separator:a1844f8007b2484467987ecac972facfe inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56088e00c19d7faf8d26e4ee988cedef inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#ab191675d4d7b96fa1ed943f58046fc6b">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a56088e00c19d7faf8d26e4ee988cedef">GetLearningRate</a> () const</td></tr>
<tr class="memdesc:a56088e00c19d7faf8d26e4ee988cedef inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Getters.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#a56088e00c19d7faf8d26e4ee988cedef">More...</a><br /></td></tr>
<tr class="separator:a56088e00c19d7faf8d26e4ee988cedef inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a490f4997c9814688e056d010036d6a inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a2a490f4997c9814688e056d010036d6a">IncrementGlobalStep</a> ()</td></tr>
<tr class="memdesc:a2a490f4997c9814688e056d010036d6a inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Increments the global step.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#a2a490f4997c9814688e056d010036d6a">More...</a><br /></td></tr>
<tr class="separator:a2a490f4997c9814688e056d010036d6a inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c338022f7aae7fcf25d7c3dd2a3e177 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a4c338022f7aae7fcf25d7c3dd2a3e177">SetLearningRate</a> (size_t learningRate)</td></tr>
<tr class="memdesc:a4c338022f7aae7fcf25d7c3dd2a3e177 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Setters.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#a4c338022f7aae7fcf25d7c3dd2a3e177">More...</a><br /></td></tr>
<tr class="separator:a4c338022f7aae7fcf25d7c3dd2a3e177 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a594cec7c150b5933d03e0aef79ed1467 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a594cec7c150b5933d03e0aef79ed1467">Step</a> ()</td></tr>
<tr class="memdesc:a594cec7c150b5933d03e0aef79ed1467 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs one step of optimization.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#a594cec7c150b5933d03e0aef79ed1467">More...</a><br /></td></tr>
<tr class="separator:a594cec7c150b5933d03e0aef79ed1467 inherit pub_methods_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a0f1f8697c51db6c0b943b79aaabeec37"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a0f1f8697c51db6c0b943b79aaabeec37">UpdateBiases</a> (size_t layerIndex, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;biases, const std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;biasGradients)</td></tr>
<tr class="memdesc:a0f1f8697c51db6c0b943b79aaabeec37"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update the biases, given the current bias gradients.  <a href="#a0f1f8697c51db6c0b943b79aaabeec37">More...</a><br /></td></tr>
<tr class="separator:a0f1f8697c51db6c0b943b79aaabeec37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00d475503701a0bc9c4513192a8090b0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="TSystem_8h.html#a48a4b7a430b095306ef0a70bcbdaa63b">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a00d475503701a0bc9c4513192a8090b0">UpdateWeights</a> (size_t layerIndex, std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;weights, const std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;weightGradients)</td></tr>
<tr class="memdesc:a00d475503701a0bc9c4513192a8090b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update the weights, given the current weight gradients.  <a href="#a00d475503701a0bc9c4513192a8090b0">More...</a><br /></td></tr>
<tr class="separator:a00d475503701a0bc9c4513192a8090b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a788836a51436f5053679d8ed9cc62dd7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a788836a51436f5053679d8ed9cc62dd7">fEpsilon</a></td></tr>
<tr class="memdesc:a788836a51436f5053679d8ed9cc62dd7"><td class="mdescLeft">&#160;</td><td class="mdescRight">The Smoothing term used to avoid division by zero.  <a href="#a788836a51436f5053679d8ed9cc62dd7">More...</a><br /></td></tr>
<tr class="separator:a788836a51436f5053679d8ed9cc62dd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f6165bb138f56e206d75b66d85fef27"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a3f6165bb138f56e206d75b66d85fef27">fPastSquaredBiasGradients</a></td></tr>
<tr class="memdesc:a3f6165bb138f56e206d75b66d85fef27"><td class="mdescLeft">&#160;</td><td class="mdescRight">The sum of the square of the past bias gradients associated with the deep net.  <a href="#a3f6165bb138f56e206d75b66d85fef27">More...</a><br /></td></tr>
<tr class="separator:a3f6165bb138f56e206d75b66d85fef27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a617df932c378f5cafd1a0b8a63292104"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a617df932c378f5cafd1a0b8a63292104">fPastSquaredWeightGradients</a></td></tr>
<tr class="memdesc:a617df932c378f5cafd1a0b8a63292104"><td class="mdescLeft">&#160;</td><td class="mdescRight">The sum of the square of the past weight gradients associated with the deep net.  <a href="#a617df932c378f5cafd1a0b8a63292104">More...</a><br /></td></tr>
<tr class="separator:a617df932c378f5cafd1a0b8a63292104"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_classTMVA_1_1DNN_1_1VOptimizer')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html">TMVA::DNN::VOptimizer&lt; Architecture_t, Layer_t, DeepNet_t &gt;</a></td></tr>
<tr class="memitem:abfe7915f8eae9fa4bba7fbf5db58994c inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">DeepNet_t &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#abfe7915f8eae9fa4bba7fbf5db58994c">fDeepNet</a></td></tr>
<tr class="memdesc:abfe7915f8eae9fa4bba7fbf5db58994c inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">The reference to the deep net.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#abfe7915f8eae9fa4bba7fbf5db58994c">More...</a><br /></td></tr>
<tr class="separator:abfe7915f8eae9fa4bba7fbf5db58994c inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a067cd41306fb6e1a35fda16b7b698fcf inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a067cd41306fb6e1a35fda16b7b698fcf">fGlobalStep</a></td></tr>
<tr class="memdesc:a067cd41306fb6e1a35fda16b7b698fcf inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">The current global step count during training.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#a067cd41306fb6e1a35fda16b7b698fcf">More...</a><br /></td></tr>
<tr class="separator:a067cd41306fb6e1a35fda16b7b698fcf inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa057a73e1966923e9cdce6e62e9263b4 inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#ab191675d4d7b96fa1ed943f58046fc6b">Scalar_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#aa057a73e1966923e9cdce6e62e9263b4">fLearningRate</a></td></tr>
<tr class="memdesc:aa057a73e1966923e9cdce6e62e9263b4 inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">The learning rate used for training.  <a href="classTMVA_1_1DNN_1_1VOptimizer.html#aa057a73e1966923e9cdce6e62e9263b4">More...</a><br /></td></tr>
<tr class="separator:aa057a73e1966923e9cdce6e62e9263b4 inherit pro_attribs_classTMVA_1_1DNN_1_1VOptimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>

<p><code>#include &lt;<a class="el" href="Adagrad_8h_source.html">TMVA/DNN/Adagrad.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for TMVA::DNN::TAdagrad&lt; Architecture_t, Layer_t, DeepNet_t &gt;:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classTMVA_1_1DNN_1_1TAdagrad__inherit__graph.svg" width="188" height="171"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<h2 class="groupheader">Member Typedef Documentation</h2>
<a id="a66360d470ec94f7c2ffde94b92b413f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66360d470ec94f7c2ffde94b92b413f2">&#9670;&nbsp;</a></span>Matrix_t</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> =  typename Architecture_t::Matrix_t</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00046">46</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="a690a25c9359430be27144af355e65c30"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a690a25c9359430be27144af355e65c30">&#9670;&nbsp;</a></span>Scalar_t</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a> =  typename Architecture_t::Scalar_t</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00047">47</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a5a0153c4e30b3b6c99b78fc624614a04"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a0153c4e30b3b6c99b78fc624614a04">&#9670;&nbsp;</a></span>TAdagrad()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t , typename DeepNet_t &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TAdagrad</a> </td>
          <td>(</td>
          <td class="paramtype">DeepNet_t &amp;&#160;</td>
          <td class="paramname"><em>deepNet</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>learningRate</em> = <code>0.01</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a>&#160;</td>
          <td class="paramname"><em>epsilon</em> = <code>1e-8</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00085">85</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="ad6a3f83ac95acd4c148c47c1ab9c5c61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6a3f83ac95acd4c148c47c1ab9c5c61">&#9670;&nbsp;</a></span>~TAdagrad()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::~<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TAdagrad</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Destructor. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a428996d1fd34970fac6e4c7d3bc4357c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a428996d1fd34970fac6e4c7d3bc4357c">&#9670;&nbsp;</a></span>GetEpsilon()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a> <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::GetEpsilon </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Getters. </p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00071">71</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="ab1ea31869f71247b33ae840387c7d883"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1ea31869f71247b33ae840387c7d883">&#9670;&nbsp;</a></span>GetPastSquaredBiasGradients()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a>&gt; &gt;&amp; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::GetPastSquaredBiasGradients </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00076">76</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="a3748d2958e9729385b5524006683f7d3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3748d2958e9729385b5524006683f7d3">&#9670;&nbsp;</a></span>GetPastSquaredBiasGradientsAt()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a>&gt;&amp; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::GetPastSquaredBiasGradientsAt </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>i</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00077">77</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="ab72c4b72159a98531c0c11b142b263d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab72c4b72159a98531c0c11b142b263d1">&#9670;&nbsp;</a></span>GetPastSquaredWeightGradients()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a>&gt; &gt;&amp; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::GetPastSquaredWeightGradients </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00073">73</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="aa93751d0e89bcdf2e85ead11ecd58205"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa93751d0e89bcdf2e85ead11ecd58205">&#9670;&nbsp;</a></span>GetPastSquaredWeightGradientsAt()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a>&gt;&amp; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::GetPastSquaredWeightGradientsAt </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>i</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00074">74</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="a0f1f8697c51db6c0b943b79aaabeec37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f1f8697c51db6c0b943b79aaabeec37">&#9670;&nbsp;</a></span>UpdateBiases()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t , typename DeepNet_t &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::UpdateBiases </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>layerIndex</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>biasGradients</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Update the biases, given the current bias gradients. </p>

<p>Implements <a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a345ec3ce4757cd89e1c53ccc3c092a8c">TMVA::DNN::VOptimizer&lt; Architecture_t, Layer_t, DeepNet_t &gt;</a>.</p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00149">149</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="a00d475503701a0bc9c4513192a8090b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00d475503701a0bc9c4513192a8090b0">&#9670;&nbsp;</a></span>UpdateWeights()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t , typename DeepNet_t &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::UpdateWeights </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>layerIndex</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>weightGradients</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Update the weights, given the current weight gradients. </p>

<p>Implements <a class="el" href="classTMVA_1_1DNN_1_1VOptimizer.html#a497f67aaa05f332dd9bf0735f2b4dde2">TMVA::DNN::VOptimizer&lt; Architecture_t, Layer_t, DeepNet_t &gt;</a>.</p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00120">120</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a788836a51436f5053679d8ed9cc62dd7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a788836a51436f5053679d8ed9cc62dd7">&#9670;&nbsp;</a></span>fEpsilon</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a690a25c9359430be27144af355e65c30">Scalar_t</a> <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::fEpsilon</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The Smoothing term used to avoid division by zero. </p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00050">50</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="a3f6165bb138f56e206d75b66d85fef27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f6165bb138f56e206d75b66d85fef27">&#9670;&nbsp;</a></span>fPastSquaredBiasGradients</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a>&gt; &gt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::fPastSquaredBiasGradients</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The sum of the square of the past bias gradients associated with the deep net. </p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00055">55</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<a id="a617df932c378f5cafd1a0b8a63292104"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a617df932c378f5cafd1a0b8a63292104">&#9670;&nbsp;</a></span>fPastSquaredWeightGradients</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Architecture_t , typename Layer_t  = VGeneralLayer&lt;Architecture_t&gt;, typename DeepNet_t  = TDeepNet&lt;Architecture_t, Layer_t&gt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;<a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html#a66360d470ec94f7c2ffde94b92b413f2">Matrix_t</a>&gt; &gt; <a class="el" href="classTMVA_1_1DNN_1_1TAdagrad.html">TMVA::DNN::TAdagrad</a>&lt; Architecture_t, Layer_t, DeepNet_t &gt;::fPastSquaredWeightGradients</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The sum of the square of the past weight gradients associated with the deep net. </p>

<p class="definition">Definition at line <a class="el" href="Adagrad_8h_source.html#l00053">53</a> of file <a class="el" href="Adagrad_8h_source.html">Adagrad.h</a>.</p>

</div>
</div>
<div class="dynheader">
</div>
<div class="dyncontent">
</div><hr/>The documentation for this class was generated from the following file:<ul>
<li>tmva/tmva/inc/TMVA/DNN/<a class="el" href="Adagrad_8h_source.html">Adagrad.h</a></li>
</ul>
</div><!-- contents -->
<html>
<body>
<div id="footer" style="background-color:#E5EBF3;">
<small>
<img class="footer" src="rootlogo_s.gif" alt="root"/></a>
ROOT 6.18/03 - Reference Guide Generated on Thu Aug 29 2019 04:12:02 (GVA Time) using Doxygen 1.8.14.
</small>
</div>
</body>
</html>
